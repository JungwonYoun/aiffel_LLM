{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d542f8d9",
   "metadata": {},
   "source": [
    "# ÌîÑÎ°úÏ†ùÌä∏: KoChatGPT ÏóÖÍ∑∏Î†àÏù¥Îìú ÌïòÍ∏∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1688069b",
   "metadata": {},
   "source": [
    "### Ï†ïÎüâÏ†Å Î∂ÑÏÑùÏùÑ ÏúÑÌïú bleu ÌèâÍ∞Ä Ìï®Ïàò ÎßåÎì§Í∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d309960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17755cdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38a186a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1194a97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162/3884723172.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"sacrebleu\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "# Load the BLEU metric\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e9540b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize a sentence\n",
    "def tokenize_sentence(sentence):\n",
    "    # Implement tokenization using your tokenizer\n",
    "    # Return a list of tokens\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "875953d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate BLEU score\n",
    "def calculate_bleu_score(model_outputs, target_sentences):\n",
    "    # Tokenize model outputs and target sentences\n",
    "    tokenized_outputs = [tokenize_sentence(output) for output in model_outputs]\n",
    "    tokenized_targets = [tokenize_sentence(target) for target in target_sentences]\n",
    "    \n",
    "    # Calculate BLEU score\n",
    "    bleu_score = metric.compute(predictions=tokenized_outputs, references=tokenized_targets)\n",
    "    \n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4714aa34",
   "metadata": {},
   "source": [
    "### ÌèâÍ∞ÄÎ•º ÏúÑÌïú Îç∞Ïù¥ÌÑ∞ÏÖã ÎßåÎì§Í∏∞ (Ìö®Ïú®ÏùÑ ÏúÑÌï¥ Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¨Í∏∞ Ï§ÑÏù¥Í∏∞ : 100Í∞ú)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72f2a609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'ÌîåÎû´ ÌôîÏù¥Ìä∏Í∞Ä Î≠îÍ∞ÄÏöî?',\n",
       "  'completion': '\\'\"ÌîåÎû´ ÌôîÏù¥Ìä∏\"Îäî ÏùºÎ∞òÏ†ÅÏúºÎ°ú Ìù∞ÏÉâ Î∞∞Í≤ΩÏóê ÎßåÌôîÎÇò ÏùºÎü¨Ïä§Ìä∏ Îì±ÏùÑ Îã¥ÏùÄ ÎîîÏûêÏù∏ÏùÑ ÏùòÎØ∏Ìï©ÎãàÎã§. Ï£ºÎ°ú ÏõπÌà∞, Í≤åÏûÑ, Ïï†ÎãàÎ©îÏù¥ÏÖò, ÏòÅÌôî Îì±ÏóêÏÑú ÏÇ¨Ïö©ÎêòÎ©∞, ÌèâÎ©¥Ï†ÅÏúºÎ°ú ÌëúÌòÑÎêú Í∑∏ÎûòÌîΩ ÎîîÏûêÏù∏Ïùò Ïä§ÌÉÄÏùºÏùÑ ÎßêÌï©ÎãàÎã§.',\n",
       "  'tokens': 127},\n",
       " {'prompt': 'Ïñ¥ÎîîÏóê ÍπÄÏòÅÏÇºÏùò ÏÑúÏö∏ÎåÄÌïôÍµê ÏûÖÌïô Î∞è Ï°∏ÏóÖ Ï¶ùÎ™ÖÏÑúÍ∞Ä Ï†ÑÏãúÎêòÏñ¥ ÏûàÎäîÍ∞Ä?',\n",
       "  'completion': \"'ÍπÄÏòÅÏÇºÏùò ÏÑúÏö∏ÎåÄÌïôÍµê ÏûÖÌïô Î∞è Ï°∏ÏóÖ Ï¶ùÎ™ÖÏÑúÎäî ÏÑúÏö∏ÎåÄÌïôÍµê ÎØ∏Ïà†Í¥ÄÏóê Ï†ÑÏãúÎêòÏñ¥ ÏûàÏäµÎãàÎã§.\",\n",
       "  'tokens': 105},\n",
       " {'prompt': 'Ï†úÍ∞Ä ÏßÄÍ∏à Í∞ïÎÇ®Ïó≠Ïù∏Îç∞, Ïó¨Í∏∞ÏÑú Ïò§Îûò Í±∏Î¶¥ÍπåÏöî?',\n",
       "  'completion': \"'Ï†ÄÎäî Ïù∏Í≥µÏßÄÎä• Ï±óÎ¥áÏù¥ÎØÄÎ°ú ÌòÑÏû¨Ïùò ÍµêÌÜµ ÏÉÅÌô©Í≥º Ïó¨Ìñâ Í±∞Î¶¨, Ïù¥Îèô Î∞©Î≤ï Îì±Í≥º Í∞ôÏùÄ Ï†ïÎ≥¥Î•º Î≥¥Ïú†ÌïòÍ≥† ÏûàÏßÄ ÏïäÏäµÎãàÎã§. ÌïòÏßÄÎßå, ÏùºÎ∞òÏ†ÅÏúºÎ°ú Í∞ïÎÇ®Ïó≠ÏùÄ ÍµêÌÜµÏù¥ ÍµâÏû•Ìûà Î≥µÏû°ÌïòÍ≥† ÌòºÏû°ÌïòÍ∏∞ ÎïåÎ¨∏Ïóê ÏãúÍ∞ÑÏù¥ Í±∏Î¶¥ Ïàò ÏûàÏäµÎãàÎã§. ÎßåÏïΩ Ïù¥ÎèôÌïòÏã§ ÏúÑÏπòÍ∞Ä Ïñ¥ÎîîÏù∏ÏßÄ ÏïåÎ†§Ï£ºÏã†Îã§Î©¥, Î≥¥Îã§ Îçî Ï†ïÌôïÌïú ÎãµÎ≥ÄÏùÑ ÎìúÎ¶¥ Ïàò ÏûàÏùÑ Í≤ÉÏûÖÎãàÎã§.\",\n",
       "  'tokens': 195}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_1_SFT = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl' \n",
    "with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file_SFT:\n",
    "    list_data_dict_SFT = json.load(json_file_SFT)[11900:]\n",
    "\n",
    "print(len(list_data_dict_SFT))\n",
    "list_data_dict_SFT[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b478f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt = []\n",
    "for i in list_data_dict_SFT:\n",
    "    input_prompt.append(i['prompt'])\n",
    "    \n",
    "labeled_completion = []\n",
    "for i in list_data_dict_SFT:\n",
    "    labeled_completion.append(i['completion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0832ef1",
   "metadata": {},
   "source": [
    "# 2. SFT Î™®Îç∏Í≥º RM Î™®Îç∏ Í≤∞Í≥º Î∂ÑÏÑù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1badf869",
   "metadata": {},
   "source": [
    "## RM Ï†ÅÏö© Î™®Îç∏ Í≤∞Í≥º Î∞è ÌèâÍ∞Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a84c937",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import modules\n",
    "import os\n",
    "import json\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.trainer import RewardModelTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoConfig\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2b0d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None,\n",
    "                 config: Optional[GPT2Config] = None,\n",
    "                 checkpoint: bool = False,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none',\n",
    "                 tokenizer=None) -> None:\n",
    "        if pretrained is not None:\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None:\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b746b5",
   "metadata": {},
   "source": [
    "### ÏÇ¨Ïö©Ìï† Î™®Îç∏Í≥º ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†ÄÎ•º Î∂àÎü¨Ïò§Í∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfd209e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=128,\n",
    ")\n",
    "\n",
    "with NaiveStrategy().model_init_context():\n",
    "    model = GPTRM_custom(pretrained='skt/kogpt2-base-v2', lora_rank=0, tokenizer=tokenizer).cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d0f26",
   "metadata": {},
   "source": [
    "### RMÏùÑ ÌõàÎ†®ÏãúÌÇ¨ Îïå ÏÇ¨Ïö©Ìï† ranking datasetÏùÑ ÎßåÎì§Í∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1e56682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data num: 10220\n",
      "after  data num: 30660\n",
      "data example: \n",
      "{'prompt': 'Ïï†ÌîåÏùÄ Î¶¨ÏÇ¨Î•º Ïñ¥ÎñªÍ≤å Ï≤òÎ¶¨ÌñàÏñ¥', 'chosen': 'Ïï†ÌîåÏù¥ ÎàÑÍµ¨Ïù∏ÏßÄ Î™ÖÌôïÌûà Ïïå Ïàò ÏóÜÏñ¥ÏÑú, Î¶¨ÏÇ¨Í∞Ä ÎàÑÍµ¨Ïù∏ÏßÄÏôÄ Ïñ¥Îñ§ ÏÉÅÌô©ÏóêÏÑú Ï≤òÎ¶¨ÎêòÏóàÎäîÏßÄÏóê ÎåÄÌïú Ï∂îÍ∞ÄÏ†ÅÏù∏ Ï†ïÎ≥¥Í∞Ä ÌïÑÏöîÌï©ÎãàÎã§. Îî∞ÎùºÏÑú, Î≥¥Îã§ Ï†ïÌôïÌïú ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌï† Ïàò ÏóÜÏäµÎãàÎã§.', 'rejected': 'Ïï†ÌîåÏùÄ Î¶¨ÏÇ¨Î•º ÏúÑÌï¥ Í≥†Í∞ù ÏÑúÎπÑÏä§ Î∂ÄÏÑúÏóêÏÑú Í≥†Í∞ù Îã§ÏñëÌïú Ïª¥Ìì®ÌÑ∞ Í¥ÄÎ†® Î¨∏Ï†úÏóê ÎåÄÌï¥ ÏùëÎãµÌïòÎäî Îç∞ ÌïÑÏöîÌïú Î™®Îì† ÏßÄÏõêÏùÑ Ï†úÍ≥µÌñàÏäµÎãàÎã§. ÏÇ¨Ïö©ÏûêÍ∞Ä ÌïòÎìúÏõ®Ïñ¥ Î¨∏Ï†úÎ•º Í≤ΩÌóòÌï† Îïå, Ï†ÑÎ¨∏Í∞ÄÎì§ÏùÄ ÌïÑÏöîÌïú ÏàòÎ¶¨(ÏàòÎ¶¨, Ï∂îÍ∞Ä Î∂ÄÌíà Ï†úÍ≥µ, ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ ÏóÖÍ∑∏Î†àÏù¥Îìú Îì±)ÏùÑ Ï†úÍ≥µÌï¥ ÎìúÎ¶¥ Ïàò ÏûàÏäµÎãàÎã§. ÎòêÌïú, ÏÇ¨Ïö©ÏûêÍ∞Ä ÏÇ¨Ïö© Î∞©Î≤ï Î¨∏Ï†úÎÇò Í∏∞ÌÉÄ Î¨∏Ï†úÎ•º Í≤ΩÌóòÌï† Îïå, ÎåÄÌôî ÏÉÅÎåÄÎ°ú ÏÇ¨Ïö©ÏûêÎ•º ÏßÄÏõêÌï† Ïàò ÏûàÎäî Ï†ÑÎ¨∏ Í≥†Í∞ù ÏÑúÎπÑÏä§ ÏßÅÏõêÎì§Ïù¥ ÏÇ¨Ïö©ÏûêÏóêÍ≤å ÏÉÅÎã¥ÌïòÍ≥† ÎèÑÏõÄÏùÑ Ï£ºÎäî Îç∞ ÎèÑÏõÄÏù¥ Îê† Ïàò ÏûàÎäî Ï†ïÎ≥¥Î•º Ï†úÍ≥µÌï©ÎãàÎã§. ÎòêÌïú, Ïù∏ÌÑ∞ÎÑ∑ÏóêÏÑú Ï†úÍ≥µÎêòÎäî Ï†ïÎ≥¥Î•º ÌÜµÌï¥ Î¨∏Ï†úÎ•º Ìï¥Í≤∞ÌïòÍ±∞ÎÇò Í≥†Í∞ù ÏÑúÎπÑÏä§ Ïõπ ÏÇ¨Ïù¥Ìä∏Î•º ÌÜµÌï¥ ÏûêÏã†Ïùò Î¨∏Ï†úÎ•º ÏßÑÎã®Ìï† Ïàò ÏûàÎèÑÎ°ù ÌïòÎäî Îì± Îã§ÏñëÌïú Î∞©Î≤ïÏúºÎ°ú Î¶¨ÏÇ¨Î•º Ï≤òÎ¶¨Ìï¥ ÏôîÏäµÎãàÎã§.'}\n"
     ]
    }
   ],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f285328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_ranking2chosen = []\n",
    "\n",
    "for tmp in list_data_dict:\n",
    "     prompt = tmp['prompt']\n",
    "     ranking = tmp['ranking']\n",
    "\n",
    "     for index in range(1, len(ranking)):\n",
    "         n = ranking[0]\n",
    "         m = ranking[index]\n",
    "\n",
    "\n",
    "         data = {\n",
    "             'prompt': prompt,\n",
    "             'chosen': tmp['completion_{}'.format(n)],\n",
    "             'rejected': tmp['completion_{}'.format(m)]\n",
    "         }\n",
    "\n",
    "         total_data_ranking2chosen.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e1b7a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'ÏΩúÎùº ÎßàÏãúÍ≥† Î¶¨ÌïÑ ÎèºÏöî?', 'chosen': 'Ï†ÄÎäî AI Ïñ¥ÏãúÏä§ÌÑ¥Ìä∏Î°ú ÎßàÏãúÎäî ÏùåÎ£åÎÇò ÏùåÏãùÏùÑ Î®πÏßÄ ÏïäÍ∏∞ ÎïåÎ¨∏Ïóê Ï†ïÌôïÌïú ÎãµÎ≥ÄÏùÑ ÎìúÎ¶¥ Ïàò ÏóÜÏäµÎãàÎã§. ÌïòÏßÄÎßå ÎåÄÏ≤¥Î°ú Îß•ÎèÑÎÇ†ÎìúÎÇò ÏùåÏãùÏ†ê Îì±ÏóêÏÑúÎäî ÏΩúÎùºÏùò Î¶¨ÌïÑÏù¥ Í∞ÄÎä•Ìïú Í≤ΩÏö∞Í∞Ä ÏûàÏäµÎãàÎã§. Îî∞ÎùºÏÑú Îß§Ïû•Ïóê Îî∞Îùº Îã§Î•º Ïàò ÏûàÏúºÎãà, Ï∞∏Í≥†ÌïòÏãúÍ∏∞ Î∞îÎûçÎãàÎã§.', 'rejected': 'Îã§ÌïúÍµ≠Ïùò Íµ≠Ï†úÎ•º ÎßåÎìúÎäî ÎúªÏù¥Îã§. ÌïúÍµ≠ÏóêÏÑú Íµ≠Ï†úÎäî Í±∞Ïùò Íµ≠Ïú† Íµ≠Êèõ„ÅÑ‰∏≠„Çí ÌïúÍµ≠ÏóêÏÑú Íµ≠Ï†úÎ•º Ïù¥Ïñ¥ÎÇòÍ≤å ÌïòÎäî Í∞úÎÖêÏù¥ Íµ≠Ï†úÎì§Ïù¥ ÏùºÏñ¥ÎØÄÎäî  ÎØøÏùÑ Í∞úÏù¥ \\n\\nÌïúÍµ≠Ïù¥ ÎàáÍµ≠Ìè∞ Íµ≠Ï†úÎ•º ÌÉúÎäî ÏïÑÎπÑ Íµ≠ÎèôÎì§Ïùò Íµ≠'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(12)\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0222ae33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|‚ñà‚ñç        | 144/1000 [00:00<00:00, 1424.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|‚ñà‚ñà‚ñà       | 307/1000 [00:00<00:00, 1543.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 463/1000 [00:00<00:00, 1548.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 629/1000 [00:00<00:00, 1591.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 801/1000 [00:00<00:00, 1636.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 1596.40it/s][A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 1659.83it/s]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(eval_data))\n",
    "\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 128)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a366402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################\n",
      "## prompt ##\n",
      "ÎÇ¥Ïùº Ï§ëÏöîÌïú ÏùºÏù¥ ÏûàÎäîÎç∞ Ïò∑ Ï∂îÏ≤úÌï¥Ï£ºÏã§ Ïàò ÏûàÎÇòÏöî?\n",
      "######################################################################\n",
      "## chosen ##\n",
      "Ï†úÍ∞Ä AI Ï±óÎ¥áÏù¥Í∏∞ ÎïåÎ¨∏Ïóê Ïò∑ Ï∂îÏ≤úÎèÑ Í∞ÄÎä•Ìï©ÎãàÎã§! \\n\\nÏñ¥Îäê Ï†ïÎèÑÏùò Ìè¨Î©ÄÌï®Ïù∏ÏßÄ, ÌòπÏùÄ Ïñ¥Îñ§ ÏÉâÏÉÅÏùÑ ÏÑ†Ìò∏ÌïòÎäîÏßÄ Îì± ÏÑ∏Î∂ÄÏ†ÅÏù∏ ÏöîÍµ¨ÏÇ¨Ìï≠Ïù¥ ÏûàÏúºÎ©¥ Îçî Ï†ïÌôïÌïú Ï∂îÏ≤úÏù¥ Í∞ÄÎä•Ìï¥ÏßëÎãàÎã§. \\n\\nÍ∑∏Îü¨ÎÇò ÏùºÎ∞òÏ†ÅÏúºÎ°ú Ï§ëÏöîÌïú ÏùºÏù¥ÎùºÎ©¥ Ìè¨Î©ÄÌïú Î≤îÏúÑÏóêÏÑú ÏÑ†ÌÉùÌïòÍ∏∞Î•º Í∂åÌï¥ÎìúÎ¶¨Î©∞, Ïñ¥Îäê Ï†ïÎèÑ ÏïàÏ†ïÍ∞êÏùÑ Ï£ºÎäî ÏÉâÏÉÅ (ex. Í≤ÄÏ†ï, ÌöåÏÉâ, ÎÑ§Ïù¥ÎπÑ Îì±)Ïùò Ïò∑ÏùÑ Ï∂îÏ≤úÌï¥ÎìúÎ¶ΩÎãàÎã§. \\n\\nÎ¨¥ÎÇúÌïòÏßÄÎßå ÏÑ∏Î†®Îêú ÎäêÎÇåÏùÑ Ï£ºÎäî Ïò∑ÏùÑ ÏÑ†ÌÉùÌïòÏãúÎäî Í≤ÉÏù¥ Ï¢ãÏäµÎãàÎã§. ÌñâÏö¥ÏùÑ ÎπåÏñ¥ÎìúÎ¶ΩÎãàÎã§!\n",
      "######################################################################\n",
      "## rejected ##\n",
      "Ï£ÑÏÜ°Ìï©ÎãàÎã§. Ïò∑ Ï∂îÏ≤úÏùÄ ÎãµÎ≥ÄÌï¥ ÎìúÎ¶¥ Ïàò ÏóÜÏäµÎãàÎã§. Í∞úÏù∏Ïùò Ï∑®Ìñ•Í≥º Ïä§ÌÉÄÏùºÏóê Îî∞Îùº Îã§Î•¥Í∏∞ ÎïåÎ¨∏Ïóê Ï†ÅÌï©Ìïú Ïò∑ÏùÑ Ï∂îÏ≤úÌïòÍ∏∞ Ïñ¥Î†µÏäµÎãàÎã§. ÌïòÏßÄÎßå Îã§ÏùåÍ≥º Í∞ôÏùÄ Ï°∞Ïñ∏ÏùÑ ÎìúÎ¶¥ Ïàò ÏûàÏäµÎãàÎã§. \n",
      "\n",
      "1. ÏûêÏã†Ïùò Ïä§ÌÉÄÏùºÍ≥º Ï∑®Ìñ•ÏùÑ Í≥†Î†§ÌïòÏó¨ Ïò∑ÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî. \n",
      "2. ÏûêÏã†Ïùò ÏÉâÏÉÅÍ≥º Í∞ÄÏû• Ïûò Ïñ¥Ïö∏Î¶¨\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print('#'*70)\n",
    "print('## prompt ##')\n",
    "print(train_data[idx]['prompt'])\n",
    "print('#'*70)\n",
    "print('## chosen ##')\n",
    "print(train_data[idx]['chosen'])\n",
    "print('#'*70)\n",
    "print('## rejected ##')\n",
    "print(train_data[idx]['rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158863cd",
   "metadata": {},
   "source": [
    "### RM ÌïôÏäµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "817eafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=3,\n",
    "                             max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "106b018f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Train step of epoch 0:   0%|          | 0/334 [00:00<?, ?it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/334 [00:00<03:29,  1.59it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/334 [00:00<03:29,  1.59it/s, loss=0.837]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/334 [00:00<02:04,  2.66it/s, loss=0.837]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/334 [00:00<02:04,  2.66it/s, loss=0.428]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/334 [00:01<01:37,  3.38it/s, loss=0.428]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/334 [00:01<01:37,  3.38it/s, loss=1.44] \u001b[A\n",
      "Train step of epoch 0:   1%|          | 4/334 [00:01<01:24,  3.90it/s, loss=1.44]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 4/334 [00:01<01:24,  3.90it/s, loss=0.288]\u001b[A\n",
      "Train step of epoch 0:   1%|‚ñè         | 5/334 [00:01<01:17,  4.26it/s, loss=0.288]\u001b[A\n",
      "Train step of epoch 0:   1%|‚ñè         | 5/334 [00:01<01:17,  4.26it/s, loss=0.209]\u001b[A\n",
      "Train step of epoch 0:   2%|‚ñè         | 6/334 [00:01<01:13,  4.49it/s, loss=0.209]\u001b[A\n",
      "Train step of epoch 0:   2%|‚ñè         | 6/334 [00:01<01:13,  4.49it/s, loss=0.162]\u001b[A\n",
      "Train step of epoch 0:   2%|‚ñè         | 7/334 [00:01<01:09,  4.67it/s, loss=0.162]\u001b[A\n",
      "Train step of epoch 0:   2%|‚ñè         | 7/334 [00:01<01:09,  4.67it/s, loss=0.338]\u001b[A\n",
      "Train step of epoch 0:   2%|‚ñè         | 8/334 [00:02<01:06,  4.87it/s, loss=0.338]\u001b[A\n",
      "Train step of epoch 0:   2%|‚ñè         | 8/334 [00:02<01:06,  4.87it/s, loss=0.222]\u001b[A\n",
      "Train step of epoch 0:   3%|‚ñé         | 9/334 [00:02<01:06,  4.90it/s, loss=0.222]\u001b[A\n",
      "Train step of epoch 0:   3%|‚ñé         | 9/334 [00:02<01:06,  4.90it/s, loss=0.096]\u001b[A\n",
      "Train step of epoch 0:   3%|‚ñé         | 10/334 [00:02<01:05,  4.94it/s, loss=0.096]\u001b[A\n",
      "Train step of epoch 0:   3%|‚ñé         | 10/334 [00:02<01:05,  4.94it/s, loss=0.00322]\u001b[A\n",
      "Train step of epoch 0:   3%|‚ñé         | 11/334 [00:02<01:05,  4.96it/s, loss=0.00322]\u001b[A\n",
      "Train step of epoch 0:   3%|‚ñé         | 11/334 [00:02<01:05,  4.96it/s, loss=0.329]  \u001b[A\n",
      "Train step of epoch 0:   4%|‚ñé         | 12/334 [00:02<01:04,  4.97it/s, loss=0.329]\u001b[A\n",
      "Train step of epoch 0:   4%|‚ñé         | 12/334 [00:02<01:04,  4.97it/s, loss=0.00382]\u001b[A\n",
      "Train step of epoch 0:   4%|‚ñç         | 13/334 [00:03<01:04,  5.00it/s, loss=0.00382]\u001b[A\n",
      "Train step of epoch 0:   4%|‚ñç         | 13/334 [00:03<01:04,  5.00it/s, loss=0.000228]\u001b[A\n",
      "Train step of epoch 0:   4%|‚ñç         | 14/334 [00:03<01:04,  4.99it/s, loss=0.000228]\u001b[A\n",
      "Train step of epoch 0:   4%|‚ñç         | 14/334 [00:03<01:04,  4.99it/s, loss=0.00532] \u001b[A\n",
      "Train step of epoch 0:   4%|‚ñç         | 15/334 [00:03<01:03,  4.99it/s, loss=0.00532]\u001b[A\n",
      "Train step of epoch 0:   4%|‚ñç         | 15/334 [00:03<01:03,  4.99it/s, loss=0.0441] \u001b[A\n",
      "Train step of epoch 0:   5%|‚ñç         | 16/334 [00:03<01:03,  5.02it/s, loss=0.0441]\u001b[A\n",
      "Train step of epoch 0:   5%|‚ñç         | 16/334 [00:03<01:03,  5.02it/s, loss=0.357] \u001b[A\n",
      "Train step of epoch 0:   5%|‚ñå         | 17/334 [00:03<01:03,  5.00it/s, loss=0.357]\u001b[A\n",
      "Train step of epoch 0:   5%|‚ñå         | 17/334 [00:03<01:03,  5.00it/s, loss=0.105]\u001b[A\n",
      "Train step of epoch 0:   5%|‚ñå         | 18/334 [00:03<01:03,  5.01it/s, loss=0.105]\u001b[A\n",
      "Train step of epoch 0:   5%|‚ñå         | 18/334 [00:04<01:03,  5.01it/s, loss=0.00578]\u001b[A\n",
      "Train step of epoch 0:   6%|‚ñå         | 19/334 [00:04<01:02,  5.04it/s, loss=0.00578]\u001b[A\n",
      "Train step of epoch 0:   6%|‚ñå         | 19/334 [00:04<01:02,  5.04it/s, loss=0.488]  \u001b[A\n",
      "Train step of epoch 0:   6%|‚ñå         | 20/334 [00:04<01:02,  5.04it/s, loss=0.488]\u001b[A\n",
      "Train step of epoch 0:   6%|‚ñå         | 20/334 [00:04<01:02,  5.04it/s, loss=8.69e-5]\u001b[A\n",
      "Train step of epoch 0:   6%|‚ñã         | 21/334 [00:04<01:02,  5.02it/s, loss=8.69e-5]\u001b[A\n",
      "Train step of epoch 0:   6%|‚ñã         | 21/334 [00:04<01:02,  5.02it/s, loss=0.144]  \u001b[A\n",
      "Train step of epoch 0:   7%|‚ñã         | 22/334 [00:04<01:02,  5.02it/s, loss=0.144]\u001b[A\n",
      "Train step of epoch 0:   7%|‚ñã         | 22/334 [00:04<01:02,  5.02it/s, loss=0.0688]\u001b[A\n",
      "Train step of epoch 0:   7%|‚ñã         | 23/334 [00:04<01:01,  5.04it/s, loss=0.0688]\u001b[A\n",
      "Train step of epoch 0:   7%|‚ñã         | 23/334 [00:05<01:01,  5.04it/s, loss=0.0247]\u001b[A\n",
      "Train step of epoch 0:   7%|‚ñã         | 24/334 [00:05<01:01,  5.05it/s, loss=0.0247]\u001b[A\n",
      "Train step of epoch 0:   7%|‚ñã         | 24/334 [00:05<01:01,  5.05it/s, loss=0.741] \u001b[A\n",
      "Train step of epoch 0:   7%|‚ñã         | 25/334 [00:05<01:01,  5.04it/s, loss=0.741]\u001b[A\n",
      "Train step of epoch 0:   7%|‚ñã         | 25/334 [00:05<01:01,  5.04it/s, loss=0.0151]\u001b[A\n",
      "Train step of epoch 0:   8%|‚ñä         | 26/334 [00:05<01:01,  5.03it/s, loss=0.0151]\u001b[A\n",
      "Train step of epoch 0:   8%|‚ñä         | 26/334 [00:05<01:01,  5.03it/s, loss=0.157] \u001b[A\n",
      "Train step of epoch 0:   8%|‚ñä         | 27/334 [00:05<01:01,  5.03it/s, loss=0.157]\u001b[A\n",
      "Train step of epoch 0:   8%|‚ñä         | 27/334 [00:05<01:01,  5.03it/s, loss=0.224]\u001b[A\n",
      "Train step of epoch 0:   8%|‚ñä         | 28/334 [00:05<01:00,  5.02it/s, loss=0.224]\u001b[A\n",
      "Train step of epoch 0:   8%|‚ñä         | 28/334 [00:06<01:00,  5.02it/s, loss=1.01] \u001b[A\n",
      "Train step of epoch 0:   9%|‚ñä         | 29/334 [00:06<01:00,  5.02it/s, loss=1.01]\u001b[A\n",
      "Train step of epoch 0:   9%|‚ñä         | 29/334 [00:06<01:00,  5.02it/s, loss=0.217]\u001b[A\n",
      "Train step of epoch 0:   9%|‚ñâ         | 30/334 [00:06<01:00,  5.02it/s, loss=0.217]\u001b[A\n",
      "Train step of epoch 0:   9%|‚ñâ         | 30/334 [00:06<01:00,  5.02it/s, loss=0.401]\u001b[A\n",
      "Train step of epoch 0:   9%|‚ñâ         | 31/334 [00:06<01:00,  5.02it/s, loss=0.401]\u001b[A\n",
      "Train step of epoch 0:   9%|‚ñâ         | 31/334 [00:06<01:00,  5.02it/s, loss=0.277]\u001b[A\n",
      "Train step of epoch 0:  10%|‚ñâ         | 32/334 [00:06<00:59,  5.03it/s, loss=0.277]\u001b[A\n",
      "Train step of epoch 0:  10%|‚ñâ         | 32/334 [00:06<00:59,  5.03it/s, loss=0.37] \u001b[A\n",
      "Train step of epoch 0:  10%|‚ñâ         | 33/334 [00:06<00:59,  5.03it/s, loss=0.37]\u001b[A\n",
      "Train step of epoch 0:  10%|‚ñâ         | 33/334 [00:07<00:59,  5.03it/s, loss=0.0771]\u001b[A\n",
      "Train step of epoch 0:  10%|‚ñà         | 34/334 [00:07<00:59,  5.01it/s, loss=0.0771]\u001b[A\n",
      "Train step of epoch 0:  10%|‚ñà         | 34/334 [00:07<00:59,  5.01it/s, loss=1.69]  \u001b[A\n",
      "Train step of epoch 0:  10%|‚ñà         | 35/334 [00:07<00:59,  5.00it/s, loss=1.69]\u001b[A\n",
      "Train step of epoch 0:  10%|‚ñà         | 35/334 [00:07<00:59,  5.00it/s, loss=0.0912]\u001b[A\n",
      "Train step of epoch 0:  11%|‚ñà         | 36/334 [00:07<00:59,  5.01it/s, loss=0.0912]\u001b[A\n",
      "Train step of epoch 0:  11%|‚ñà         | 36/334 [00:07<00:59,  5.01it/s, loss=0.361] \u001b[A\n",
      "Train step of epoch 0:  11%|‚ñà         | 37/334 [00:07<00:59,  5.01it/s, loss=0.361]\u001b[A\n",
      "Train step of epoch 0:  11%|‚ñà         | 37/334 [00:07<00:59,  5.01it/s, loss=0.298]\u001b[A\n",
      "Train step of epoch 0:  11%|‚ñà‚ñè        | 38/334 [00:07<00:59,  5.00it/s, loss=0.298]\u001b[A\n",
      "Train step of epoch 0:  11%|‚ñà‚ñè        | 38/334 [00:08<00:59,  5.00it/s, loss=0.183]\u001b[A\n",
      "Train step of epoch 0:  12%|‚ñà‚ñè        | 39/334 [00:08<00:58,  5.01it/s, loss=0.183]\u001b[A\n",
      "Train step of epoch 0:  12%|‚ñà‚ñè        | 39/334 [00:08<00:58,  5.01it/s, loss=0.463]\u001b[A\n",
      "Train step of epoch 0:  12%|‚ñà‚ñè        | 40/334 [00:08<00:58,  5.00it/s, loss=0.463]\u001b[A\n",
      "Train step of epoch 0:  12%|‚ñà‚ñè        | 40/334 [00:08<00:58,  5.00it/s, loss=0.481]\u001b[A\n",
      "Train step of epoch 0:  12%|‚ñà‚ñè        | 41/334 [00:08<00:58,  5.00it/s, loss=0.481]\u001b[A\n",
      "Train step of epoch 0:  12%|‚ñà‚ñè        | 41/334 [00:08<00:58,  5.00it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  13%|‚ñà‚ñé        | 42/334 [00:08<00:58,  5.01it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  13%|‚ñà‚ñé        | 42/334 [00:08<00:58,  5.01it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  13%|‚ñà‚ñé        | 43/334 [00:08<00:58,  5.02it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  13%|‚ñà‚ñé        | 43/334 [00:09<00:58,  5.02it/s, loss=0.298]\u001b[A\n",
      "Train step of epoch 0:  13%|‚ñà‚ñé        | 44/334 [00:09<00:57,  5.02it/s, loss=0.298]\u001b[A\n",
      "Train step of epoch 0:  13%|‚ñà‚ñé        | 44/334 [00:09<00:57,  5.02it/s, loss=0.0426]\u001b[A\n",
      "Train step of epoch 0:  13%|‚ñà‚ñé        | 45/334 [00:09<00:57,  5.02it/s, loss=0.0426]\u001b[A\n",
      "Train step of epoch 0:  13%|‚ñà‚ñé        | 45/334 [00:09<00:57,  5.02it/s, loss=0.238] \u001b[A\n",
      "Train step of epoch 0:  14%|‚ñà‚ñç        | 46/334 [00:09<00:57,  5.01it/s, loss=0.238]\u001b[A\n",
      "Train step of epoch 0:  14%|‚ñà‚ñç        | 46/334 [00:09<00:57,  5.01it/s, loss=0.819]\u001b[A\n",
      "Train step of epoch 0:  14%|‚ñà‚ñç        | 47/334 [00:09<00:57,  5.00it/s, loss=0.819]\u001b[A\n",
      "Train step of epoch 0:  14%|‚ñà‚ñç        | 47/334 [00:09<00:57,  5.00it/s, loss=0.0182]\u001b[A\n",
      "Train step of epoch 0:  14%|‚ñà‚ñç        | 48/334 [00:09<00:57,  5.01it/s, loss=0.0182]\u001b[A\n",
      "Train step of epoch 0:  14%|‚ñà‚ñç        | 48/334 [00:09<00:57,  5.01it/s, loss=0.387] \u001b[A\n",
      "Train step of epoch 0:  15%|‚ñà‚ñç        | 49/334 [00:10<00:56,  5.03it/s, loss=0.387]\u001b[A\n",
      "Train step of epoch 0:  15%|‚ñà‚ñç        | 49/334 [00:10<00:56,  5.03it/s, loss=0.287]\u001b[A\n",
      "Train step of epoch 0:  15%|‚ñà‚ñç        | 50/334 [00:10<00:56,  5.03it/s, loss=0.287]\u001b[A\n",
      "Train step of epoch 0:  15%|‚ñà‚ñç        | 50/334 [00:10<00:56,  5.03it/s, loss=0.221]\u001b[A\n",
      "Train step of epoch 0:  15%|‚ñà‚ñå        | 51/334 [00:10<00:56,  5.01it/s, loss=0.221]\u001b[A\n",
      "Train step of epoch 0:  15%|‚ñà‚ñå        | 51/334 [00:10<00:56,  5.01it/s, loss=0.328]\u001b[A\n",
      "Train step of epoch 0:  16%|‚ñà‚ñå        | 52/334 [00:10<00:56,  4.98it/s, loss=0.328]\u001b[A\n",
      "Train step of epoch 0:  16%|‚ñà‚ñå        | 52/334 [00:10<00:56,  4.98it/s, loss=0.112]\u001b[A\n",
      "Train step of epoch 0:  16%|‚ñà‚ñå        | 53/334 [00:10<00:56,  4.95it/s, loss=0.112]\u001b[A\n",
      "Train step of epoch 0:  16%|‚ñà‚ñå        | 53/334 [00:11<00:56,  4.95it/s, loss=0.582]\u001b[A\n",
      "Train step of epoch 0:  16%|‚ñà‚ñå        | 54/334 [00:11<00:56,  4.97it/s, loss=0.582]\u001b[A\n",
      "Train step of epoch 0:  16%|‚ñà‚ñå        | 54/334 [00:11<00:56,  4.97it/s, loss=0.0111]\u001b[A\n",
      "Train step of epoch 0:  16%|‚ñà‚ñã        | 55/334 [00:11<00:56,  4.98it/s, loss=0.0111]\u001b[A\n",
      "Train step of epoch 0:  16%|‚ñà‚ñã        | 55/334 [00:11<00:56,  4.98it/s, loss=0.13]  \u001b[A\n",
      "Train step of epoch 0:  17%|‚ñà‚ñã        | 56/334 [00:11<00:55,  4.98it/s, loss=0.13]\u001b[A\n",
      "Train step of epoch 0:  17%|‚ñà‚ñã        | 56/334 [00:11<00:55,  4.98it/s, loss=0.00433]\u001b[A\n",
      "Train step of epoch 0:  17%|‚ñà‚ñã        | 57/334 [00:11<00:55,  5.00it/s, loss=0.00433]\u001b[A\n",
      "Train step of epoch 0:  17%|‚ñà‚ñã        | 57/334 [00:11<00:55,  5.00it/s, loss=0.0248] \u001b[A\n",
      "Train step of epoch 0:  17%|‚ñà‚ñã        | 58/334 [00:11<00:55,  5.01it/s, loss=0.0248]\u001b[A\n",
      "Train step of epoch 0:  17%|‚ñà‚ñã        | 58/334 [00:12<00:55,  5.01it/s, loss=0.0932]\u001b[A\n",
      "Train step of epoch 0:  18%|‚ñà‚ñä        | 59/334 [00:12<00:54,  5.04it/s, loss=0.0932]\u001b[A\n",
      "Train step of epoch 0:  18%|‚ñà‚ñä        | 59/334 [00:12<00:54,  5.04it/s, loss=0.103] \u001b[A\n",
      "Train step of epoch 0:  18%|‚ñà‚ñä        | 60/334 [00:12<00:54,  5.04it/s, loss=0.103]\u001b[A\n",
      "Train step of epoch 0:  18%|‚ñà‚ñä        | 60/334 [00:12<00:54,  5.04it/s, loss=0.225]\u001b[A\n",
      "Train step of epoch 0:  18%|‚ñà‚ñä        | 61/334 [00:12<00:54,  5.03it/s, loss=0.225]\u001b[A\n",
      "Train step of epoch 0:  18%|‚ñà‚ñä        | 61/334 [00:12<00:54,  5.03it/s, loss=0.000114]\u001b[A\n",
      "Train step of epoch 0:  19%|‚ñà‚ñä        | 62/334 [00:12<00:54,  5.01it/s, loss=0.000114]\u001b[A\n",
      "Train step of epoch 0:  19%|‚ñà‚ñä        | 62/334 [00:12<00:54,  5.01it/s, loss=0.0297]  \u001b[A\n",
      "Train step of epoch 0:  19%|‚ñà‚ñâ        | 63/334 [00:12<00:53,  5.03it/s, loss=0.0297]\u001b[A\n",
      "Train step of epoch 0:  19%|‚ñà‚ñâ        | 63/334 [00:12<00:53,  5.03it/s, loss=0.148] \u001b[A\n",
      "Train step of epoch 0:  19%|‚ñà‚ñâ        | 64/334 [00:13<00:53,  5.03it/s, loss=0.148]\u001b[A\n",
      "Train step of epoch 0:  19%|‚ñà‚ñâ        | 64/334 [00:13<00:53,  5.03it/s, loss=0.00768]\u001b[A\n",
      "Train step of epoch 0:  19%|‚ñà‚ñâ        | 65/334 [00:13<00:52,  5.08it/s, loss=0.00768]\u001b[A\n",
      "Train step of epoch 0:  19%|‚ñà‚ñâ        | 65/334 [00:13<00:52,  5.08it/s, loss=0.74]   \u001b[A\n",
      "Train step of epoch 0:  20%|‚ñà‚ñâ        | 66/334 [00:13<00:52,  5.08it/s, loss=0.74]\u001b[A\n",
      "Train step of epoch 0:  20%|‚ñà‚ñâ        | 66/334 [00:13<00:52,  5.08it/s, loss=0.305]\u001b[A\n",
      "Train step of epoch 0:  20%|‚ñà‚ñà        | 67/334 [00:13<00:52,  5.04it/s, loss=0.305]\u001b[A\n",
      "Train step of epoch 0:  20%|‚ñà‚ñà        | 67/334 [00:13<00:52,  5.04it/s, loss=0.366]\u001b[A\n",
      "Train step of epoch 0:  20%|‚ñà‚ñà        | 68/334 [00:13<00:52,  5.03it/s, loss=0.366]\u001b[A\n",
      "Train step of epoch 0:  20%|‚ñà‚ñà        | 68/334 [00:13<00:52,  5.03it/s, loss=0.000633]\u001b[A\n",
      "Train step of epoch 0:  21%|‚ñà‚ñà        | 69/334 [00:14<00:52,  5.06it/s, loss=0.000633]\u001b[A\n",
      "Train step of epoch 0:  21%|‚ñà‚ñà        | 69/334 [00:14<00:52,  5.06it/s, loss=0.0718]  \u001b[A\n",
      "Train step of epoch 0:  21%|‚ñà‚ñà        | 70/334 [00:14<00:52,  5.05it/s, loss=0.0718]\u001b[A\n",
      "Train step of epoch 0:  21%|‚ñà‚ñà        | 70/334 [00:14<00:52,  5.05it/s, loss=0.135] \u001b[A\n",
      "Train step of epoch 0:  21%|‚ñà‚ñà‚ñè       | 71/334 [00:14<00:52,  5.05it/s, loss=0.135]\u001b[A\n",
      "Train step of epoch 0:  21%|‚ñà‚ñà‚ñè       | 71/334 [00:14<00:52,  5.05it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  22%|‚ñà‚ñà‚ñè       | 72/334 [00:14<00:51,  5.05it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  22%|‚ñà‚ñà‚ñè       | 72/334 [00:14<00:51,  5.05it/s, loss=0.0702]\u001b[A\n",
      "Train step of epoch 0:  22%|‚ñà‚ñà‚ñè       | 73/334 [00:14<00:52,  5.02it/s, loss=0.0702]\u001b[A\n",
      "Train step of epoch 0:  22%|‚ñà‚ñà‚ñè       | 73/334 [00:14<00:52,  5.02it/s, loss=0.201] \u001b[A\n",
      "Train step of epoch 0:  22%|‚ñà‚ñà‚ñè       | 74/334 [00:15<00:52,  4.99it/s, loss=0.201]\u001b[A\n",
      "Train step of epoch 0:  22%|‚ñà‚ñà‚ñè       | 74/334 [00:15<00:52,  4.99it/s, loss=0.0897]\u001b[A\n",
      "Train step of epoch 0:  22%|‚ñà‚ñà‚ñè       | 75/334 [00:15<00:51,  5.01it/s, loss=0.0897]\u001b[A\n",
      "Train step of epoch 0:  22%|‚ñà‚ñà‚ñè       | 75/334 [00:15<00:51,  5.01it/s, loss=0.0348]\u001b[A\n",
      "Train step of epoch 0:  23%|‚ñà‚ñà‚ñé       | 76/334 [00:15<00:51,  5.01it/s, loss=0.0348]\u001b[A\n",
      "Train step of epoch 0:  23%|‚ñà‚ñà‚ñé       | 76/334 [00:15<00:51,  5.01it/s, loss=0.0165]\u001b[A\n",
      "Train step of epoch 0:  23%|‚ñà‚ñà‚ñé       | 77/334 [00:15<00:51,  5.01it/s, loss=0.0165]\u001b[A\n",
      "Train step of epoch 0:  23%|‚ñà‚ñà‚ñé       | 77/334 [00:15<00:51,  5.01it/s, loss=5.21e-6]\u001b[A\n",
      "Train step of epoch 0:  23%|‚ñà‚ñà‚ñé       | 78/334 [00:15<00:51,  5.01it/s, loss=5.21e-6]\u001b[A\n",
      "Train step of epoch 0:  23%|‚ñà‚ñà‚ñé       | 78/334 [00:15<00:51,  5.01it/s, loss=0.0349] \u001b[A\n",
      "Train step of epoch 0:  24%|‚ñà‚ñà‚ñé       | 79/334 [00:16<00:51,  5.00it/s, loss=0.0349]\u001b[A\n",
      "Train step of epoch 0:  24%|‚ñà‚ñà‚ñé       | 79/334 [00:16<00:51,  5.00it/s, loss=0.881] \u001b[A\n",
      "Train step of epoch 0:  24%|‚ñà‚ñà‚ñç       | 80/334 [00:16<00:50,  5.02it/s, loss=0.881]\u001b[A\n",
      "Train step of epoch 0:  24%|‚ñà‚ñà‚ñç       | 80/334 [00:16<00:50,  5.02it/s, loss=0.00128]\u001b[A\n",
      "Train step of epoch 0:  24%|‚ñà‚ñà‚ñç       | 81/334 [00:16<00:50,  5.04it/s, loss=0.00128]\u001b[A\n",
      "Train step of epoch 0:  24%|‚ñà‚ñà‚ñç       | 81/334 [00:16<00:50,  5.04it/s, loss=0.208]  \u001b[A\n",
      "Train step of epoch 0:  25%|‚ñà‚ñà‚ñç       | 82/334 [00:16<00:50,  5.03it/s, loss=0.208]\u001b[A\n",
      "Train step of epoch 0:  25%|‚ñà‚ñà‚ñç       | 82/334 [00:16<00:50,  5.03it/s, loss=0.162]\u001b[A\n",
      "Train step of epoch 0:  25%|‚ñà‚ñà‚ñç       | 83/334 [00:16<00:49,  5.03it/s, loss=0.162]\u001b[A\n",
      "Train step of epoch 0:  25%|‚ñà‚ñà‚ñç       | 83/334 [00:16<00:49,  5.03it/s, loss=0.323]\u001b[A\n",
      "Train step of epoch 0:  25%|‚ñà‚ñà‚ñå       | 84/334 [00:17<00:49,  5.00it/s, loss=0.323]\u001b[A\n",
      "Train step of epoch 0:  25%|‚ñà‚ñà‚ñå       | 84/334 [00:17<00:49,  5.00it/s, loss=0.0991]\u001b[A\n",
      "Train step of epoch 0:  25%|‚ñà‚ñà‚ñå       | 85/334 [00:17<00:49,  5.00it/s, loss=0.0991]\u001b[A\n",
      "Train step of epoch 0:  25%|‚ñà‚ñà‚ñå       | 85/334 [00:17<00:49,  5.00it/s, loss=0.39]  \u001b[A\n",
      "Train step of epoch 0:  26%|‚ñà‚ñà‚ñå       | 86/334 [00:17<00:49,  5.00it/s, loss=0.39]\u001b[A\n",
      "Train step of epoch 0:  26%|‚ñà‚ñà‚ñå       | 86/334 [00:17<00:49,  5.00it/s, loss=0.188]\u001b[A\n",
      "Train step of epoch 0:  26%|‚ñà‚ñà‚ñå       | 87/334 [00:17<00:49,  4.99it/s, loss=0.188]\u001b[A\n",
      "Train step of epoch 0:  26%|‚ñà‚ñà‚ñå       | 87/334 [00:17<00:49,  4.99it/s, loss=0.0646]\u001b[A\n",
      "Train step of epoch 0:  26%|‚ñà‚ñà‚ñã       | 88/334 [00:17<00:49,  4.98it/s, loss=0.0646]\u001b[A\n",
      "Train step of epoch 0:  26%|‚ñà‚ñà‚ñã       | 88/334 [00:17<00:49,  4.98it/s, loss=0.219] \u001b[A\n",
      "Train step of epoch 0:  27%|‚ñà‚ñà‚ñã       | 89/334 [00:18<00:49,  4.96it/s, loss=0.219]\u001b[A\n",
      "Train step of epoch 0:  27%|‚ñà‚ñà‚ñã       | 89/334 [00:18<00:49,  4.96it/s, loss=0.005]\u001b[A\n",
      "Train step of epoch 0:  27%|‚ñà‚ñà‚ñã       | 90/334 [00:18<00:49,  4.96it/s, loss=0.005]\u001b[A\n",
      "Train step of epoch 0:  27%|‚ñà‚ñà‚ñã       | 90/334 [00:18<00:49,  4.96it/s, loss=0.0396]\u001b[A\n",
      "Train step of epoch 0:  27%|‚ñà‚ñà‚ñã       | 91/334 [00:18<00:48,  4.96it/s, loss=0.0396]\u001b[A\n",
      "Train step of epoch 0:  27%|‚ñà‚ñà‚ñã       | 91/334 [00:18<00:48,  4.96it/s, loss=0.00175]\u001b[A\n",
      "Train step of epoch 0:  28%|‚ñà‚ñà‚ñä       | 92/334 [00:18<00:48,  4.97it/s, loss=0.00175]\u001b[A\n",
      "Train step of epoch 0:  28%|‚ñà‚ñà‚ñä       | 92/334 [00:18<00:48,  4.97it/s, loss=0.0156] \u001b[A\n",
      "Train step of epoch 0:  28%|‚ñà‚ñà‚ñä       | 93/334 [00:18<00:48,  4.97it/s, loss=0.0156]\u001b[A\n",
      "Train step of epoch 0:  28%|‚ñà‚ñà‚ñä       | 93/334 [00:18<00:48,  4.97it/s, loss=0.117] \u001b[A\n",
      "Train step of epoch 0:  28%|‚ñà‚ñà‚ñä       | 94/334 [00:19<00:48,  4.97it/s, loss=0.117]\u001b[A\n",
      "Train step of epoch 0:  28%|‚ñà‚ñà‚ñä       | 94/334 [00:19<00:48,  4.97it/s, loss=0.0088]\u001b[A\n",
      "Train step of epoch 0:  28%|‚ñà‚ñà‚ñä       | 95/334 [00:19<00:47,  4.98it/s, loss=0.0088]\u001b[A\n",
      "Train step of epoch 0:  28%|‚ñà‚ñà‚ñä       | 95/334 [00:19<00:47,  4.98it/s, loss=0.0458]\u001b[A\n",
      "Train step of epoch 0:  29%|‚ñà‚ñà‚ñä       | 96/334 [00:19<00:47,  4.99it/s, loss=0.0458]\u001b[A\n",
      "Train step of epoch 0:  29%|‚ñà‚ñà‚ñä       | 96/334 [00:19<00:47,  4.99it/s, loss=0.000682]\u001b[A\n",
      "Train step of epoch 0:  29%|‚ñà‚ñà‚ñâ       | 97/334 [00:19<00:47,  4.99it/s, loss=0.000682]\u001b[A\n",
      "Train step of epoch 0:  29%|‚ñà‚ñà‚ñâ       | 97/334 [00:19<00:47,  4.99it/s, loss=0.0025]  \u001b[A\n",
      "Train step of epoch 0:  29%|‚ñà‚ñà‚ñâ       | 98/334 [00:19<00:47,  5.00it/s, loss=0.0025]\u001b[A\n",
      "Train step of epoch 0:  29%|‚ñà‚ñà‚ñâ       | 98/334 [00:19<00:47,  5.00it/s, loss=0.000158]\u001b[A\n",
      "Train step of epoch 0:  30%|‚ñà‚ñà‚ñâ       | 99/334 [00:20<00:47,  4.99it/s, loss=0.000158]\u001b[A\n",
      "Train step of epoch 0:  30%|‚ñà‚ñà‚ñâ       | 99/334 [00:20<00:47,  4.99it/s, loss=0.241]   \u001b[A\n",
      "Train step of epoch 0:  30%|‚ñà‚ñà‚ñâ       | 100/334 [00:20<00:46,  4.99it/s, loss=0.241]\u001b[A\n",
      "Train step of epoch 0:  30%|‚ñà‚ñà‚ñâ       | 100/334 [00:20<00:46,  4.99it/s, loss=0.263]\u001b[A\n",
      "Train step of epoch 0:  30%|‚ñà‚ñà‚ñà       | 101/334 [00:20<00:47,  4.95it/s, loss=0.263]\u001b[A\n",
      "Train step of epoch 0:  30%|‚ñà‚ñà‚ñà       | 101/334 [00:20<00:47,  4.95it/s, loss=0.297]\u001b[A\n",
      "Train step of epoch 0:  31%|‚ñà‚ñà‚ñà       | 102/334 [00:20<00:46,  4.97it/s, loss=0.297]\u001b[A\n",
      "Train step of epoch 0:  31%|‚ñà‚ñà‚ñà       | 102/334 [00:20<00:46,  4.97it/s, loss=1.28] \u001b[A\n",
      "Train step of epoch 0:  31%|‚ñà‚ñà‚ñà       | 103/334 [00:20<00:46,  4.98it/s, loss=1.28]\u001b[A\n",
      "Train step of epoch 0:  31%|‚ñà‚ñà‚ñà       | 103/334 [00:20<00:46,  4.98it/s, loss=0.14]\u001b[A\n",
      "Train step of epoch 0:  31%|‚ñà‚ñà‚ñà       | 104/334 [00:21<00:46,  4.97it/s, loss=0.14]\u001b[A\n",
      "Train step of epoch 0:  31%|‚ñà‚ñà‚ñà       | 104/334 [00:21<00:46,  4.97it/s, loss=0.151]\u001b[A\n",
      "Train step of epoch 0:  31%|‚ñà‚ñà‚ñà‚ñè      | 105/334 [00:21<00:46,  4.97it/s, loss=0.151]\u001b[A\n",
      "Train step of epoch 0:  31%|‚ñà‚ñà‚ñà‚ñè      | 105/334 [00:21<00:46,  4.97it/s, loss=0.00486]\u001b[A\n",
      "Train step of epoch 0:  32%|‚ñà‚ñà‚ñà‚ñè      | 106/334 [00:21<00:45,  4.98it/s, loss=0.00486]\u001b[A\n",
      "Train step of epoch 0:  32%|‚ñà‚ñà‚ñà‚ñè      | 106/334 [00:21<00:45,  4.98it/s, loss=0.622]  \u001b[A\n",
      "Train step of epoch 0:  32%|‚ñà‚ñà‚ñà‚ñè      | 107/334 [00:21<00:45,  4.97it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  32%|‚ñà‚ñà‚ñà‚ñè      | 107/334 [00:21<00:45,  4.97it/s, loss=0.0476]\u001b[A\n",
      "Train step of epoch 0:  32%|‚ñà‚ñà‚ñà‚ñè      | 108/334 [00:21<00:45,  4.97it/s, loss=0.0476]\u001b[A\n",
      "Train step of epoch 0:  32%|‚ñà‚ñà‚ñà‚ñè      | 108/334 [00:21<00:45,  4.97it/s, loss=0.231] \u001b[A\n",
      "Train step of epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 109/334 [00:22<00:45,  4.98it/s, loss=0.231]\u001b[A\n",
      "Train step of epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 109/334 [00:22<00:45,  4.98it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 110/334 [00:22<00:44,  4.98it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 110/334 [00:22<00:44,  4.98it/s, loss=0.208]\u001b[A\n",
      "Train step of epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 111/334 [00:22<00:44,  4.99it/s, loss=0.208]\u001b[A\n",
      "Train step of epoch 0:  33%|‚ñà‚ñà‚ñà‚ñé      | 111/334 [00:22<00:44,  4.99it/s, loss=0.103]\u001b[A\n",
      "Train step of epoch 0:  34%|‚ñà‚ñà‚ñà‚ñé      | 112/334 [00:22<00:44,  4.97it/s, loss=0.103]\u001b[A\n",
      "Train step of epoch 0:  34%|‚ñà‚ñà‚ñà‚ñé      | 112/334 [00:22<00:44,  4.97it/s, loss=0.435]\u001b[A\n",
      "Train step of epoch 0:  34%|‚ñà‚ñà‚ñà‚ñç      | 113/334 [00:22<00:44,  4.97it/s, loss=0.435]\u001b[A\n",
      "Train step of epoch 0:  34%|‚ñà‚ñà‚ñà‚ñç      | 113/334 [00:23<00:44,  4.97it/s, loss=0.255]\u001b[A\n",
      "Train step of epoch 0:  34%|‚ñà‚ñà‚ñà‚ñç      | 114/334 [00:23<00:44,  4.97it/s, loss=0.255]\u001b[A\n",
      "Train step of epoch 0:  34%|‚ñà‚ñà‚ñà‚ñç      | 114/334 [00:23<00:44,  4.97it/s, loss=0.15] \u001b[A\n",
      "Train step of epoch 0:  34%|‚ñà‚ñà‚ñà‚ñç      | 115/334 [00:23<00:44,  4.96it/s, loss=0.15]\u001b[A\n",
      "Train step of epoch 0:  34%|‚ñà‚ñà‚ñà‚ñç      | 115/334 [00:23<00:44,  4.96it/s, loss=0.00484]\u001b[A\n",
      "Train step of epoch 0:  35%|‚ñà‚ñà‚ñà‚ñç      | 116/334 [00:23<00:43,  4.97it/s, loss=0.00484]\u001b[A\n",
      "Train step of epoch 0:  35%|‚ñà‚ñà‚ñà‚ñç      | 116/334 [00:23<00:43,  4.97it/s, loss=0.0554] \u001b[A\n",
      "Train step of epoch 0:  35%|‚ñà‚ñà‚ñà‚ñå      | 117/334 [00:23<00:43,  4.97it/s, loss=0.0554]\u001b[A\n",
      "Train step of epoch 0:  35%|‚ñà‚ñà‚ñà‚ñå      | 117/334 [00:23<00:43,  4.97it/s, loss=0.625] \u001b[A\n",
      "Train step of epoch 0:  35%|‚ñà‚ñà‚ñà‚ñå      | 118/334 [00:23<00:43,  4.98it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:  35%|‚ñà‚ñà‚ñà‚ñå      | 118/334 [00:24<00:43,  4.98it/s, loss=0.693]\u001b[A\n",
      "Train step of epoch 0:  36%|‚ñà‚ñà‚ñà‚ñå      | 119/334 [00:24<00:43,  4.98it/s, loss=0.693]\u001b[A\n",
      "Train step of epoch 0:  36%|‚ñà‚ñà‚ñà‚ñå      | 119/334 [00:24<00:43,  4.98it/s, loss=0.0856]\u001b[A\n",
      "Train step of epoch 0:  36%|‚ñà‚ñà‚ñà‚ñå      | 120/334 [00:24<00:42,  4.98it/s, loss=0.0856]\u001b[A\n",
      "Train step of epoch 0:  36%|‚ñà‚ñà‚ñà‚ñå      | 120/334 [00:24<00:42,  4.98it/s, loss=0.993] \u001b[A\n",
      "Train step of epoch 0:  36%|‚ñà‚ñà‚ñà‚ñå      | 121/334 [00:24<00:42,  4.98it/s, loss=0.993]\u001b[A\n",
      "Train step of epoch 0:  36%|‚ñà‚ñà‚ñà‚ñå      | 121/334 [00:24<00:42,  4.98it/s, loss=0.298]\u001b[A\n",
      "Train step of epoch 0:  37%|‚ñà‚ñà‚ñà‚ñã      | 122/334 [00:24<00:42,  4.96it/s, loss=0.298]\u001b[A\n",
      "Train step of epoch 0:  37%|‚ñà‚ñà‚ñà‚ñã      | 122/334 [00:24<00:42,  4.96it/s, loss=0.095]\u001b[A\n",
      "Train step of epoch 0:  37%|‚ñà‚ñà‚ñà‚ñã      | 123/334 [00:24<00:42,  4.97it/s, loss=0.095]\u001b[A\n",
      "Train step of epoch 0:  37%|‚ñà‚ñà‚ñà‚ñã      | 123/334 [00:25<00:42,  4.97it/s, loss=0.17] \u001b[A\n",
      "Train step of epoch 0:  37%|‚ñà‚ñà‚ñà‚ñã      | 124/334 [00:25<00:42,  4.96it/s, loss=0.17]\u001b[A\n",
      "Train step of epoch 0:  37%|‚ñà‚ñà‚ñà‚ñã      | 124/334 [00:25<00:42,  4.96it/s, loss=0.235]\u001b[A\n",
      "Train step of epoch 0:  37%|‚ñà‚ñà‚ñà‚ñã      | 125/334 [00:25<00:42,  4.97it/s, loss=0.235]\u001b[A\n",
      "Train step of epoch 0:  37%|‚ñà‚ñà‚ñà‚ñã      | 125/334 [00:25<00:42,  4.97it/s, loss=0.00575]\u001b[A\n",
      "Train step of epoch 0:  38%|‚ñà‚ñà‚ñà‚ñä      | 126/334 [00:25<00:41,  4.98it/s, loss=0.00575]\u001b[A\n",
      "Train step of epoch 0:  38%|‚ñà‚ñà‚ñà‚ñä      | 126/334 [00:25<00:41,  4.98it/s, loss=0.0387] \u001b[A\n",
      "Train step of epoch 0:  38%|‚ñà‚ñà‚ñà‚ñä      | 127/334 [00:25<00:41,  4.98it/s, loss=0.0387]\u001b[A\n",
      "Train step of epoch 0:  38%|‚ñà‚ñà‚ñà‚ñä      | 127/334 [00:25<00:41,  4.98it/s, loss=0.46]  \u001b[A\n",
      "Train step of epoch 0:  38%|‚ñà‚ñà‚ñà‚ñä      | 128/334 [00:25<00:41,  4.98it/s, loss=0.46]\u001b[A\n",
      "Train step of epoch 0:  38%|‚ñà‚ñà‚ñà‚ñä      | 128/334 [00:26<00:41,  4.98it/s, loss=2.59e-5]\u001b[A\n",
      "Train step of epoch 0:  39%|‚ñà‚ñà‚ñà‚ñä      | 129/334 [00:26<00:41,  4.97it/s, loss=2.59e-5]\u001b[A\n",
      "Train step of epoch 0:  39%|‚ñà‚ñà‚ñà‚ñä      | 129/334 [00:26<00:41,  4.97it/s, loss=0.167]  \u001b[A\n",
      "Train step of epoch 0:  39%|‚ñà‚ñà‚ñà‚ñâ      | 130/334 [00:26<00:41,  4.96it/s, loss=0.167]\u001b[A\n",
      "Train step of epoch 0:  39%|‚ñà‚ñà‚ñà‚ñâ      | 130/334 [00:26<00:41,  4.96it/s, loss=0.0014]\u001b[A\n",
      "Train step of epoch 0:  39%|‚ñà‚ñà‚ñà‚ñâ      | 131/334 [00:26<00:40,  4.95it/s, loss=0.0014]\u001b[A\n",
      "Train step of epoch 0:  39%|‚ñà‚ñà‚ñà‚ñâ      | 131/334 [00:26<00:40,  4.95it/s, loss=0.0345]\u001b[A\n",
      "Train step of epoch 0:  40%|‚ñà‚ñà‚ñà‚ñâ      | 132/334 [00:26<00:40,  4.95it/s, loss=0.0345]\u001b[A\n",
      "Train step of epoch 0:  40%|‚ñà‚ñà‚ñà‚ñâ      | 132/334 [00:26<00:40,  4.95it/s, loss=0.00332]\u001b[A\n",
      "Train step of epoch 0:  40%|‚ñà‚ñà‚ñà‚ñâ      | 133/334 [00:27<00:40,  4.94it/s, loss=0.00332]\u001b[A\n",
      "Train step of epoch 0:  40%|‚ñà‚ñà‚ñà‚ñâ      | 133/334 [00:27<00:40,  4.94it/s, loss=0.151]  \u001b[A\n",
      "Train step of epoch 0:  40%|‚ñà‚ñà‚ñà‚ñà      | 134/334 [00:27<00:40,  4.94it/s, loss=0.151]\u001b[A\n",
      "Train step of epoch 0:  40%|‚ñà‚ñà‚ñà‚ñà      | 134/334 [00:27<00:40,  4.94it/s, loss=0.0931]\u001b[A\n",
      "Train step of epoch 0:  40%|‚ñà‚ñà‚ñà‚ñà      | 135/334 [00:27<00:40,  4.96it/s, loss=0.0931]\u001b[A\n",
      "Train step of epoch 0:  40%|‚ñà‚ñà‚ñà‚ñà      | 135/334 [00:27<00:40,  4.96it/s, loss=1.16]  \u001b[A\n",
      "Train step of epoch 0:  41%|‚ñà‚ñà‚ñà‚ñà      | 136/334 [00:27<00:39,  4.97it/s, loss=1.16]\u001b[A\n",
      "Train step of epoch 0:  41%|‚ñà‚ñà‚ñà‚ñà      | 136/334 [00:27<00:39,  4.97it/s, loss=0.0172]\u001b[A\n",
      "Train step of epoch 0:  41%|‚ñà‚ñà‚ñà‚ñà      | 137/334 [00:27<00:39,  4.97it/s, loss=0.0172]\u001b[A\n",
      "Train step of epoch 0:  41%|‚ñà‚ñà‚ñà‚ñà      | 137/334 [00:27<00:39,  4.97it/s, loss=0.0267]\u001b[A\n",
      "Train step of epoch 0:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 138/334 [00:28<00:39,  4.95it/s, loss=0.0267]\u001b[A\n",
      "Train step of epoch 0:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 138/334 [00:28<00:39,  4.95it/s, loss=0.402] \u001b[A\n",
      "Train step of epoch 0:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 139/334 [00:28<00:39,  4.96it/s, loss=0.402]\u001b[A\n",
      "Train step of epoch 0:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 139/334 [00:28<00:39,  4.96it/s, loss=0.56] \u001b[A\n",
      "Train step of epoch 0:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 140/334 [00:28<00:39,  4.96it/s, loss=0.56]\u001b[A\n",
      "Train step of epoch 0:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 140/334 [00:28<00:39,  4.96it/s, loss=0.285]\u001b[A\n",
      "Train step of epoch 0:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 141/334 [00:28<00:38,  4.96it/s, loss=0.285]\u001b[A\n",
      "Train step of epoch 0:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 141/334 [00:28<00:38,  4.96it/s, loss=0.0286]\u001b[A\n",
      "Train step of epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 142/334 [00:28<00:38,  4.96it/s, loss=0.0286]\u001b[A\n",
      "Train step of epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 142/334 [00:28<00:38,  4.96it/s, loss=0.581] \u001b[A\n",
      "Train step of epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 143/334 [00:29<00:38,  4.96it/s, loss=0.581]\u001b[A\n",
      "Train step of epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 143/334 [00:29<00:38,  4.96it/s, loss=0.148]\u001b[A\n",
      "Train step of epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 144/334 [00:29<00:37,  5.01it/s, loss=0.148]\u001b[A\n",
      "Train step of epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 144/334 [00:29<00:37,  5.01it/s, loss=0.0291]\u001b[A\n",
      "Train step of epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 145/334 [00:29<00:38,  4.96it/s, loss=0.0291]\u001b[A\n",
      "Train step of epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 145/334 [00:29<00:38,  4.96it/s, loss=0.169] \u001b[A\n",
      "Train step of epoch 0:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 146/334 [00:29<00:37,  4.95it/s, loss=0.169]\u001b[A\n",
      "Train step of epoch 0:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 146/334 [00:29<00:37,  4.95it/s, loss=0.126]\u001b[A\n",
      "Train step of epoch 0:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 147/334 [00:29<00:37,  4.95it/s, loss=0.126]\u001b[A\n",
      "Train step of epoch 0:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 147/334 [00:29<00:37,  4.95it/s, loss=0.104]\u001b[A\n",
      "Train step of epoch 0:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 148/334 [00:30<00:37,  4.95it/s, loss=0.104]\u001b[A\n",
      "Train step of epoch 0:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 148/334 [00:30<00:37,  4.95it/s, loss=0.0752]\u001b[A\n",
      "Train step of epoch 0:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 149/334 [00:30<00:37,  4.96it/s, loss=0.0752]\u001b[A\n",
      "Train step of epoch 0:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 149/334 [00:30<00:37,  4.96it/s, loss=0.277] \u001b[A\n",
      "Train step of epoch 0:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 150/334 [00:30<00:37,  4.97it/s, loss=0.277]\u001b[A\n",
      "Train step of epoch 0:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 150/334 [00:30<00:37,  4.97it/s, loss=0.184]\u001b[A\n",
      "Train step of epoch 0:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 151/334 [00:30<00:36,  5.00it/s, loss=0.184]\u001b[A\n",
      "Train step of epoch 0:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 151/334 [00:30<00:36,  5.00it/s, loss=0.895]\u001b[A\n",
      "Train step of epoch 0:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 152/334 [00:30<00:36,  4.97it/s, loss=0.895]\u001b[A\n",
      "Train step of epoch 0:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 152/334 [00:30<00:36,  4.97it/s, loss=0.012]\u001b[A\n",
      "Train step of epoch 0:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 153/334 [00:31<00:36,  4.96it/s, loss=0.012]\u001b[A\n",
      "Train step of epoch 0:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 153/334 [00:31<00:36,  4.96it/s, loss=0.127]\u001b[A\n",
      "Train step of epoch 0:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 154/334 [00:31<00:36,  4.96it/s, loss=0.127]\u001b[A\n",
      "Train step of epoch 0:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 154/334 [00:31<00:36,  4.96it/s, loss=0.529]\u001b[A\n",
      "Train step of epoch 0:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 155/334 [00:31<00:36,  4.96it/s, loss=0.529]\u001b[A\n",
      "Train step of epoch 0:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 155/334 [00:31<00:36,  4.96it/s, loss=0.225]\u001b[A\n",
      "Train step of epoch 0:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 156/334 [00:31<00:35,  4.95it/s, loss=0.225]\u001b[A\n",
      "Train step of epoch 0:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 156/334 [00:31<00:35,  4.95it/s, loss=0.297]\u001b[A\n",
      "Train step of epoch 0:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 157/334 [00:31<00:35,  4.94it/s, loss=0.297]\u001b[A\n",
      "Train step of epoch 0:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 157/334 [00:31<00:35,  4.94it/s, loss=0.153]\u001b[A\n",
      "Train step of epoch 0:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 158/334 [00:32<00:35,  4.93it/s, loss=0.153]\u001b[A\n",
      "Train step of epoch 0:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 158/334 [00:32<00:35,  4.93it/s, loss=0.178]\u001b[A\n",
      "Train step of epoch 0:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 159/334 [00:32<00:35,  4.93it/s, loss=0.178]\u001b[A\n",
      "Train step of epoch 0:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 159/334 [00:32<00:35,  4.93it/s, loss=0.00121]\u001b[A\n",
      "Train step of epoch 0:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 160/334 [00:32<00:35,  4.92it/s, loss=0.00121]\u001b[A\n",
      "Train step of epoch 0:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 160/334 [00:32<00:35,  4.92it/s, loss=0.0217] \u001b[A\n",
      "Train step of epoch 0:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 161/334 [00:32<00:35,  4.94it/s, loss=0.0217]\u001b[A\n",
      "Train step of epoch 0:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 161/334 [00:32<00:35,  4.94it/s, loss=0.431] \u001b[A\n",
      "Train step of epoch 0:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 162/334 [00:32<00:34,  4.94it/s, loss=0.431]\u001b[A\n",
      "Train step of epoch 0:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 162/334 [00:32<00:34,  4.94it/s, loss=0.00235]\u001b[A\n",
      "Train step of epoch 0:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 163/334 [00:33<00:34,  4.94it/s, loss=0.00235]\u001b[A\n",
      "Train step of epoch 0:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 163/334 [00:33<00:34,  4.94it/s, loss=0.0437] \u001b[A\n",
      "Train step of epoch 0:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 164/334 [00:33<00:34,  4.94it/s, loss=0.0437]\u001b[A\n",
      "Train step of epoch 0:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 164/334 [00:33<00:34,  4.94it/s, loss=0.246] \u001b[A\n",
      "Train step of epoch 0:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 165/334 [00:33<00:34,  4.94it/s, loss=0.246]\u001b[A\n",
      "Train step of epoch 0:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 165/334 [00:33<00:34,  4.94it/s, loss=0.126]\u001b[A\n",
      "Train step of epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 166/334 [00:33<00:33,  4.95it/s, loss=0.126]\u001b[A\n",
      "Train step of epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 166/334 [00:33<00:33,  4.95it/s, loss=0.223]\u001b[A\n",
      "Train step of epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 167/334 [00:33<00:33,  4.96it/s, loss=0.223]\u001b[A\n",
      "Train step of epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 167/334 [00:33<00:33,  4.96it/s, loss=0.00187]\u001b[A\n",
      "Train step of epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 168/334 [00:34<00:33,  4.95it/s, loss=0.00187]\u001b[A\n",
      "Train step of epoch 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 168/334 [00:34<00:33,  4.95it/s, loss=0.00359]\u001b[A\n",
      "Train step of epoch 0:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 169/334 [00:34<00:33,  4.94it/s, loss=0.00359]\u001b[A\n",
      "Train step of epoch 0:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 169/334 [00:34<00:33,  4.94it/s, loss=0.442]  \u001b[A\n",
      "Train step of epoch 0:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 170/334 [00:34<00:33,  4.94it/s, loss=0.442]\u001b[A\n",
      "Train step of epoch 0:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 170/334 [00:34<00:33,  4.94it/s, loss=2.08] \u001b[A\n",
      "Train step of epoch 0:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 171/334 [00:34<00:33,  4.93it/s, loss=2.08]\u001b[A\n",
      "Train step of epoch 0:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 171/334 [00:34<00:33,  4.93it/s, loss=0.0139]\u001b[A\n",
      "Train step of epoch 0:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 172/334 [00:34<00:32,  4.93it/s, loss=0.0139]\u001b[A\n",
      "Train step of epoch 0:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 172/334 [00:34<00:32,  4.93it/s, loss=0.00113]\u001b[A\n",
      "Train step of epoch 0:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 173/334 [00:35<00:32,  4.93it/s, loss=0.00113]\u001b[A\n",
      "Train step of epoch 0:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 173/334 [00:35<00:32,  4.93it/s, loss=0.148]  \u001b[A\n",
      "Train step of epoch 0:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 174/334 [00:35<00:32,  4.93it/s, loss=0.148]\u001b[A\n",
      "Train step of epoch 0:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 174/334 [00:35<00:32,  4.93it/s, loss=0.00808]\u001b[A\n",
      "Train step of epoch 0:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 175/334 [00:35<00:32,  4.93it/s, loss=0.00808]\u001b[A\n",
      "Train step of epoch 0:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 175/334 [00:35<00:32,  4.93it/s, loss=0.233]  \u001b[A\n",
      "Train step of epoch 0:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 176/334 [00:35<00:31,  4.95it/s, loss=0.233]\u001b[A\n",
      "Train step of epoch 0:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 176/334 [00:35<00:31,  4.95it/s, loss=0.0414]\u001b[A\n",
      "Train step of epoch 0:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 177/334 [00:35<00:31,  4.95it/s, loss=0.0414]\u001b[A\n",
      "Train step of epoch 0:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 177/334 [00:35<00:31,  4.95it/s, loss=0.094] \u001b[A\n",
      "Train step of epoch 0:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 178/334 [00:36<00:31,  4.94it/s, loss=0.094]\u001b[A\n",
      "Train step of epoch 0:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 178/334 [00:36<00:31,  4.94it/s, loss=0.341]\u001b[A\n",
      "Train step of epoch 0:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 179/334 [00:36<00:31,  4.96it/s, loss=0.341]\u001b[A\n",
      "Train step of epoch 0:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 179/334 [00:36<00:31,  4.96it/s, loss=0.265]\u001b[A\n",
      "Train step of epoch 0:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 180/334 [00:36<00:31,  4.94it/s, loss=0.265]\u001b[A\n",
      "Train step of epoch 0:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 180/334 [00:36<00:31,  4.94it/s, loss=0.562]\u001b[A\n",
      "Train step of epoch 0:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 181/334 [00:36<00:30,  4.95it/s, loss=0.562]\u001b[A\n",
      "Train step of epoch 0:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 181/334 [00:36<00:30,  4.95it/s, loss=0.611]\u001b[A\n",
      "Train step of epoch 0:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 182/334 [00:36<00:30,  4.95it/s, loss=0.611]\u001b[A\n",
      "Train step of epoch 0:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 182/334 [00:36<00:30,  4.95it/s, loss=0.086]\u001b[A\n",
      "Train step of epoch 0:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 183/334 [00:37<00:30,  4.94it/s, loss=0.086]\u001b[A\n",
      "Train step of epoch 0:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 183/334 [00:37<00:30,  4.94it/s, loss=0.116]\u001b[A\n",
      "Train step of epoch 0:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 184/334 [00:37<00:30,  4.94it/s, loss=0.116]\u001b[A\n",
      "Train step of epoch 0:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 184/334 [00:37<00:30,  4.94it/s, loss=0.228]\u001b[A\n",
      "Train step of epoch 0:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 185/334 [00:37<00:30,  4.95it/s, loss=0.228]\u001b[A\n",
      "Train step of epoch 0:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 185/334 [00:37<00:30,  4.95it/s, loss=0.0922]\u001b[A\n",
      "Train step of epoch 0:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 186/334 [00:37<00:30,  4.93it/s, loss=0.0922]\u001b[A\n",
      "Train step of epoch 0:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 186/334 [00:37<00:30,  4.93it/s, loss=0.171] \u001b[A\n",
      "Train step of epoch 0:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 187/334 [00:37<00:29,  4.92it/s, loss=0.171]\u001b[A\n",
      "Train step of epoch 0:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 187/334 [00:37<00:29,  4.92it/s, loss=0.342]\u001b[A\n",
      "Train step of epoch 0:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 188/334 [00:38<00:29,  4.91it/s, loss=0.342]\u001b[A\n",
      "Train step of epoch 0:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 188/334 [00:38<00:29,  4.91it/s, loss=0.15] \u001b[A\n",
      "Train step of epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 189/334 [00:38<00:29,  4.92it/s, loss=0.15]\u001b[A\n",
      "Train step of epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 189/334 [00:38<00:29,  4.92it/s, loss=0.248]\u001b[A\n",
      "Train step of epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 190/334 [00:38<00:29,  4.93it/s, loss=0.248]\u001b[A\n",
      "Train step of epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 190/334 [00:38<00:29,  4.93it/s, loss=0.606]\u001b[A\n",
      "Train step of epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 191/334 [00:38<00:28,  4.94it/s, loss=0.606]\u001b[A\n",
      "Train step of epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 191/334 [00:38<00:28,  4.94it/s, loss=0.0189]\u001b[A\n",
      "Train step of epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 192/334 [00:38<00:28,  4.94it/s, loss=0.0189]\u001b[A\n",
      "Train step of epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 192/334 [00:38<00:28,  4.94it/s, loss=0.000332]\u001b[A\n",
      "Train step of epoch 0:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 193/334 [00:39<00:28,  4.93it/s, loss=0.000332]\u001b[A\n",
      "Train step of epoch 0:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 193/334 [00:39<00:28,  4.93it/s, loss=0.0045]  \u001b[A\n",
      "Train step of epoch 0:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 194/334 [00:39<00:28,  4.94it/s, loss=0.0045]\u001b[A\n",
      "Train step of epoch 0:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 194/334 [00:39<00:28,  4.94it/s, loss=0.307] \u001b[A\n",
      "Train step of epoch 0:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 195/334 [00:39<00:28,  4.95it/s, loss=0.307]\u001b[A\n",
      "Train step of epoch 0:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 195/334 [00:39<00:28,  4.95it/s, loss=0.264]\u001b[A\n",
      "Train step of epoch 0:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 196/334 [00:39<00:27,  4.95it/s, loss=0.264]\u001b[A\n",
      "Train step of epoch 0:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 196/334 [00:39<00:27,  4.95it/s, loss=0.242]\u001b[A\n",
      "Train step of epoch 0:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 197/334 [00:39<00:27,  4.94it/s, loss=0.242]\u001b[A\n",
      "Train step of epoch 0:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 197/334 [00:39<00:27,  4.94it/s, loss=0.0275]\u001b[A\n",
      "Train step of epoch 0:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 198/334 [00:40<00:27,  4.93it/s, loss=0.0275]\u001b[A\n",
      "Train step of epoch 0:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 198/334 [00:40<00:27,  4.93it/s, loss=0.466] \u001b[A\n",
      "Train step of epoch 0:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 199/334 [00:40<00:27,  4.93it/s, loss=0.466]\u001b[A\n",
      "Train step of epoch 0:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 199/334 [00:40<00:27,  4.93it/s, loss=0.0266]\u001b[A\n",
      "Train step of epoch 0:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 200/334 [00:40<00:27,  4.93it/s, loss=0.0266]\u001b[A\n",
      "Train step of epoch 0:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 200/334 [00:40<00:27,  4.93it/s, loss=0.14]  \u001b[A\n",
      "Train step of epoch 0:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 201/334 [00:40<00:26,  4.95it/s, loss=0.14]\u001b[A\n",
      "Train step of epoch 0:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 201/334 [00:40<00:26,  4.95it/s, loss=0.262]\u001b[A\n",
      "Train step of epoch 0:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 202/334 [00:40<00:26,  4.93it/s, loss=0.262]\u001b[A\n",
      "Train step of epoch 0:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 202/334 [00:40<00:26,  4.93it/s, loss=0.00612]\u001b[A\n",
      "Train step of epoch 0:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 203/334 [00:41<00:26,  4.94it/s, loss=0.00612]\u001b[A\n",
      "Train step of epoch 0:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 203/334 [00:41<00:26,  4.94it/s, loss=0.0991] \u001b[A\n",
      "Train step of epoch 0:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 204/334 [00:41<00:26,  4.95it/s, loss=0.0991]\u001b[A\n",
      "Train step of epoch 0:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 204/334 [00:41<00:26,  4.95it/s, loss=0.0165]\u001b[A\n",
      "Train step of epoch 0:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 205/334 [00:41<00:25,  4.97it/s, loss=0.0165]\u001b[A\n",
      "Train step of epoch 0:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 205/334 [00:41<00:25,  4.97it/s, loss=1.15e-6]\u001b[A\n",
      "Train step of epoch 0:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 206/334 [00:41<00:25,  4.95it/s, loss=1.15e-6]\u001b[A\n",
      "Train step of epoch 0:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 206/334 [00:41<00:25,  4.95it/s, loss=0.0653] \u001b[A\n",
      "Train step of epoch 0:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 207/334 [00:41<00:25,  4.94it/s, loss=0.0653]\u001b[A\n",
      "Train step of epoch 0:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 207/334 [00:41<00:25,  4.94it/s, loss=1.02]  \u001b[A\n",
      "Train step of epoch 0:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 208/334 [00:42<00:25,  4.94it/s, loss=1.02]\u001b[A\n",
      "Train step of epoch 0:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 208/334 [00:42<00:25,  4.94it/s, loss=0.0243]\u001b[A\n",
      "Train step of epoch 0:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 209/334 [00:42<00:25,  4.95it/s, loss=0.0243]\u001b[A\n",
      "Train step of epoch 0:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 209/334 [00:42<00:25,  4.95it/s, loss=0.000211]\u001b[A\n",
      "Train step of epoch 0:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 210/334 [00:42<00:25,  4.94it/s, loss=0.000211]\u001b[A\n",
      "Train step of epoch 0:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 210/334 [00:42<00:25,  4.94it/s, loss=0.275]   \u001b[A\n",
      "Train step of epoch 0:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 211/334 [00:42<00:24,  4.95it/s, loss=0.275]\u001b[A\n",
      "Train step of epoch 0:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 211/334 [00:42<00:24,  4.95it/s, loss=0.00309]\u001b[A\n",
      "Train step of epoch 0:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 212/334 [00:42<00:24,  4.95it/s, loss=0.00309]\u001b[A\n",
      "Train step of epoch 0:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 212/334 [00:42<00:24,  4.95it/s, loss=0.0453] \u001b[A\n",
      "Train step of epoch 0:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 213/334 [00:43<00:24,  4.94it/s, loss=0.0453]\u001b[A\n",
      "Train step of epoch 0:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 213/334 [00:43<00:24,  4.94it/s, loss=0.00797]\u001b[A\n",
      "Train step of epoch 0:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 214/334 [00:43<00:24,  4.95it/s, loss=0.00797]\u001b[A\n",
      "Train step of epoch 0:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 214/334 [00:43<00:24,  4.95it/s, loss=0.101]  \u001b[A\n",
      "Train step of epoch 0:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 215/334 [00:43<00:24,  4.94it/s, loss=0.101]\u001b[A\n",
      "Train step of epoch 0:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 215/334 [00:43<00:24,  4.94it/s, loss=0.000645]\u001b[A\n",
      "Train step of epoch 0:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 216/334 [00:43<00:23,  4.99it/s, loss=0.000645]\u001b[A\n",
      "Train step of epoch 0:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 216/334 [00:43<00:23,  4.99it/s, loss=7.83e-6] \u001b[A\n",
      "Train step of epoch 0:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 217/334 [00:43<00:23,  4.96it/s, loss=7.83e-6]\u001b[A\n",
      "Train step of epoch 0:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 217/334 [00:44<00:23,  4.96it/s, loss=0.0409] \u001b[A\n",
      "Train step of epoch 0:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 218/334 [00:44<00:23,  4.97it/s, loss=0.0409]\u001b[A\n",
      "Train step of epoch 0:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 218/334 [00:44<00:23,  4.97it/s, loss=5.13e-6]\u001b[A\n",
      "Train step of epoch 0:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 219/334 [00:44<00:23,  4.95it/s, loss=5.13e-6]\u001b[A\n",
      "Train step of epoch 0:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 219/334 [00:44<00:23,  4.95it/s, loss=0.000684]\u001b[A\n",
      "Train step of epoch 0:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 220/334 [00:44<00:23,  4.93it/s, loss=0.000684]\u001b[A\n",
      "Train step of epoch 0:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 220/334 [00:44<00:23,  4.93it/s, loss=0.531]   \u001b[A\n",
      "Train step of epoch 0:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 221/334 [00:44<00:23,  4.91it/s, loss=0.531]\u001b[A\n",
      "Train step of epoch 0:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 221/334 [00:44<00:23,  4.91it/s, loss=0.0146]\u001b[A\n",
      "Train step of epoch 0:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 222/334 [00:45<00:22,  4.91it/s, loss=0.0146]\u001b[A\n",
      "Train step of epoch 0:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 222/334 [00:45<00:22,  4.91it/s, loss=0.0141]\u001b[A\n",
      "Train step of epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 223/334 [00:45<00:22,  4.93it/s, loss=0.0141]\u001b[A\n",
      "Train step of epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 223/334 [00:45<00:22,  4.93it/s, loss=7.51e-5]\u001b[A\n",
      "Train step of epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 224/334 [00:45<00:22,  4.95it/s, loss=7.51e-5]\u001b[A\n",
      "Train step of epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 224/334 [00:45<00:22,  4.95it/s, loss=1.99e-7]\u001b[A\n",
      "Train step of epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 225/334 [00:45<00:21,  4.95it/s, loss=1.99e-7]\u001b[A\n",
      "Train step of epoch 0:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 225/334 [00:45<00:21,  4.95it/s, loss=0.022]  \u001b[A\n",
      "Train step of epoch 0:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 226/334 [00:45<00:21,  4.93it/s, loss=0.022]\u001b[A\n",
      "Train step of epoch 0:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 226/334 [00:45<00:21,  4.93it/s, loss=0.000299]\u001b[A\n",
      "Train step of epoch 0:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 227/334 [00:46<00:21,  4.92it/s, loss=0.000299]\u001b[A\n",
      "Train step of epoch 0:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 227/334 [00:46<00:21,  4.92it/s, loss=0.0358]  \u001b[A\n",
      "Train step of epoch 0:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 228/334 [00:46<00:21,  4.92it/s, loss=0.0358]\u001b[A\n",
      "Train step of epoch 0:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 228/334 [00:46<00:21,  4.92it/s, loss=0.543] \u001b[A\n",
      "Train step of epoch 0:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 229/334 [00:46<00:21,  4.90it/s, loss=0.543]\u001b[A\n",
      "Train step of epoch 0:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 229/334 [00:46<00:21,  4.90it/s, loss=0.00011]\u001b[A\n",
      "Train step of epoch 0:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 230/334 [00:46<00:21,  4.93it/s, loss=0.00011]\u001b[A\n",
      "Train step of epoch 0:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 230/334 [00:46<00:21,  4.93it/s, loss=0.0079] \u001b[A\n",
      "Train step of epoch 0:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 231/334 [00:46<00:21,  4.90it/s, loss=0.0079]\u001b[A\n",
      "Train step of epoch 0:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 231/334 [00:46<00:21,  4.90it/s, loss=0.00115]\u001b[A\n",
      "Train step of epoch 0:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 232/334 [00:47<00:20,  4.92it/s, loss=0.00115]\u001b[A\n",
      "Train step of epoch 0:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 232/334 [00:47<00:20,  4.92it/s, loss=0.29]   \u001b[A\n",
      "Train step of epoch 0:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 233/334 [00:47<00:20,  4.94it/s, loss=0.29]\u001b[A\n",
      "Train step of epoch 0:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 233/334 [00:47<00:20,  4.94it/s, loss=0.0196]\u001b[A\n",
      "Train step of epoch 0:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 234/334 [00:47<00:20,  4.94it/s, loss=0.0196]\u001b[A\n",
      "Train step of epoch 0:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 234/334 [00:47<00:20,  4.94it/s, loss=0.505] \u001b[A\n",
      "Train step of epoch 0:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 235/334 [00:47<00:20,  4.93it/s, loss=0.505]\u001b[A\n",
      "Train step of epoch 0:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 235/334 [00:47<00:20,  4.93it/s, loss=0.000536]\u001b[A\n",
      "Train step of epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 236/334 [00:47<00:19,  4.90it/s, loss=0.000536]\u001b[A\n",
      "Train step of epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 236/334 [00:47<00:19,  4.90it/s, loss=0.000313]\u001b[A\n",
      "Train step of epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 237/334 [00:48<00:19,  4.91it/s, loss=0.000313]\u001b[A\n",
      "Train step of epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 237/334 [00:48<00:19,  4.91it/s, loss=0.039]   \u001b[A\n",
      "Train step of epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 238/334 [00:48<00:19,  4.90it/s, loss=0.039]\u001b[A\n",
      "Train step of epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 238/334 [00:48<00:19,  4.90it/s, loss=0.115]\u001b[A\n",
      "Train step of epoch 0:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 239/334 [00:48<00:19,  4.92it/s, loss=0.115]\u001b[A\n",
      "Train step of epoch 0:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 239/334 [00:48<00:19,  4.92it/s, loss=2.11e-6]\u001b[A\n",
      "Train step of epoch 0:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 240/334 [00:48<00:19,  4.92it/s, loss=2.11e-6]\u001b[A\n",
      "Train step of epoch 0:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 240/334 [00:48<00:19,  4.92it/s, loss=0.235]  \u001b[A\n",
      "Train step of epoch 0:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 241/334 [00:48<00:18,  4.91it/s, loss=0.235]\u001b[A\n",
      "Train step of epoch 0:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 241/334 [00:48<00:18,  4.91it/s, loss=0.17] \u001b[A\n",
      "Train step of epoch 0:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 242/334 [00:49<00:18,  4.93it/s, loss=0.17]\u001b[A\n",
      "Train step of epoch 0:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 242/334 [00:49<00:18,  4.93it/s, loss=0.00533]\u001b[A\n",
      "Train step of epoch 0:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 243/334 [00:49<00:18,  4.92it/s, loss=0.00533]\u001b[A\n",
      "Train step of epoch 0:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 243/334 [00:49<00:18,  4.92it/s, loss=0.000284]\u001b[A\n",
      "Train step of epoch 0:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 244/334 [00:49<00:18,  4.91it/s, loss=0.000284]\u001b[A\n",
      "Train step of epoch 0:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 244/334 [00:49<00:18,  4.91it/s, loss=0.00156] \u001b[A\n",
      "Train step of epoch 0:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 245/334 [00:49<00:18,  4.93it/s, loss=0.00156]\u001b[A\n",
      "Train step of epoch 0:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 245/334 [00:49<00:18,  4.93it/s, loss=0.000505]\u001b[A\n",
      "Train step of epoch 0:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 246/334 [00:49<00:17,  4.92it/s, loss=0.000505]\u001b[A\n",
      "Train step of epoch 0:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 246/334 [00:49<00:17,  4.92it/s, loss=0.0207]  \u001b[A\n",
      "Train step of epoch 0:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 247/334 [00:50<00:17,  4.93it/s, loss=0.0207]\u001b[A\n",
      "Train step of epoch 0:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 247/334 [00:50<00:17,  4.93it/s, loss=1.17]  \u001b[A\n",
      "Train step of epoch 0:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 248/334 [00:50<00:17,  4.93it/s, loss=1.17]\u001b[A\n",
      "Train step of epoch 0:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 248/334 [00:50<00:17,  4.93it/s, loss=0.0519]\u001b[A\n",
      "Train step of epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 249/334 [00:50<00:17,  4.91it/s, loss=0.0519]\u001b[A\n",
      "Train step of epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 249/334 [00:50<00:17,  4.91it/s, loss=0.155] \u001b[A\n",
      "Train step of epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 250/334 [00:50<00:17,  4.90it/s, loss=0.155]\u001b[A\n",
      "Train step of epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 250/334 [00:50<00:17,  4.90it/s, loss=0.406]\u001b[A\n",
      "Train step of epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 251/334 [00:50<00:16,  4.90it/s, loss=0.406]\u001b[A\n",
      "Train step of epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 251/334 [00:50<00:16,  4.90it/s, loss=0.00199]\u001b[A\n",
      "Train step of epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 252/334 [00:51<00:16,  4.91it/s, loss=0.00199]\u001b[A\n",
      "Train step of epoch 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 252/334 [00:51<00:16,  4.91it/s, loss=0.986]  \u001b[A\n",
      "Train step of epoch 0:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 253/334 [00:51<00:16,  4.90it/s, loss=0.986]\u001b[A\n",
      "Train step of epoch 0:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 253/334 [00:51<00:16,  4.90it/s, loss=0.00223]\u001b[A\n",
      "Train step of epoch 0:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 254/334 [00:51<00:16,  4.90it/s, loss=0.00223]\u001b[A\n",
      "Train step of epoch 0:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 254/334 [00:51<00:16,  4.90it/s, loss=0.0387] \u001b[A\n",
      "Train step of epoch 0:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 255/334 [00:51<00:16,  4.91it/s, loss=0.0387]\u001b[A\n",
      "Train step of epoch 0:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 255/334 [00:51<00:16,  4.91it/s, loss=0.187] \u001b[A\n",
      "Train step of epoch 0:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 256/334 [00:51<00:15,  4.91it/s, loss=0.187]\u001b[A\n",
      "Train step of epoch 0:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 256/334 [00:51<00:15,  4.91it/s, loss=0.00575]\u001b[A\n",
      "Train step of epoch 0:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 257/334 [00:52<00:15,  4.91it/s, loss=0.00575]\u001b[A\n",
      "Train step of epoch 0:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 257/334 [00:52<00:15,  4.91it/s, loss=0.0665] \u001b[A\n",
      "Train step of epoch 0:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 258/334 [00:52<00:15,  4.91it/s, loss=0.0665]\u001b[A\n",
      "Train step of epoch 0:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 258/334 [00:52<00:15,  4.91it/s, loss=0.284] \u001b[A\n",
      "Train step of epoch 0:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 259/334 [00:52<00:15,  4.91it/s, loss=0.284]\u001b[A\n",
      "Train step of epoch 0:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 259/334 [00:52<00:15,  4.91it/s, loss=0.339]\u001b[A\n",
      "Train step of epoch 0:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 260/334 [00:52<00:15,  4.92it/s, loss=0.339]\u001b[A\n",
      "Train step of epoch 0:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 260/334 [00:52<00:15,  4.92it/s, loss=0.225]\u001b[A\n",
      "Train step of epoch 0:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 261/334 [00:52<00:14,  4.92it/s, loss=0.225]\u001b[A\n",
      "Train step of epoch 0:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 261/334 [00:52<00:14,  4.92it/s, loss=0.0183]\u001b[A\n",
      "Train step of epoch 0:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 262/334 [00:53<00:14,  4.88it/s, loss=0.0183]\u001b[A\n",
      "Train step of epoch 0:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 262/334 [00:53<00:14,  4.88it/s, loss=0.518] \u001b[A\n",
      "Train step of epoch 0:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 263/334 [00:53<00:14,  4.86it/s, loss=0.518]\u001b[A\n",
      "Train step of epoch 0:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 263/334 [00:53<00:14,  4.86it/s, loss=0.189]\u001b[A\n",
      "Train step of epoch 0:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 264/334 [00:53<00:14,  4.87it/s, loss=0.189]\u001b[A\n",
      "Train step of epoch 0:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 264/334 [00:53<00:14,  4.87it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 265/334 [00:53<00:14,  4.88it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 265/334 [00:53<00:14,  4.88it/s, loss=0.122]\u001b[A\n",
      "Train step of epoch 0:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 266/334 [00:53<00:13,  4.89it/s, loss=0.122]\u001b[A\n",
      "Train step of epoch 0:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 266/334 [00:53<00:13,  4.89it/s, loss=0.00701]\u001b[A\n",
      "Train step of epoch 0:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 267/334 [00:54<00:13,  4.89it/s, loss=0.00701]\u001b[A\n",
      "Train step of epoch 0:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 267/334 [00:54<00:13,  4.89it/s, loss=0.378]  \u001b[A\n",
      "Train step of epoch 0:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 268/334 [00:54<00:13,  4.89it/s, loss=0.378]\u001b[A\n",
      "Train step of epoch 0:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 268/334 [00:54<00:13,  4.89it/s, loss=0.142]\u001b[A\n",
      "Train step of epoch 0:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 269/334 [00:54<00:13,  4.90it/s, loss=0.142]\u001b[A\n",
      "Train step of epoch 0:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 269/334 [00:54<00:13,  4.90it/s, loss=0.111]\u001b[A\n",
      "Train step of epoch 0:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 270/334 [00:54<00:13,  4.89it/s, loss=0.111]\u001b[A\n",
      "Train step of epoch 0:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 270/334 [00:54<00:13,  4.89it/s, loss=0.124]\u001b[A\n",
      "Train step of epoch 0:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 271/334 [00:54<00:12,  4.91it/s, loss=0.124]\u001b[A\n",
      "Train step of epoch 0:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 271/334 [00:55<00:12,  4.91it/s, loss=0.00767]\u001b[A\n",
      "Train step of epoch 0:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 272/334 [00:55<00:12,  4.89it/s, loss=0.00767]\u001b[A\n",
      "Train step of epoch 0:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 272/334 [00:55<00:12,  4.89it/s, loss=0.000359]\u001b[A\n",
      "Train step of epoch 0:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 273/334 [00:55<00:12,  4.90it/s, loss=0.000359]\u001b[A\n",
      "Train step of epoch 0:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 273/334 [00:55<00:12,  4.90it/s, loss=0.391]   \u001b[A\n",
      "Train step of epoch 0:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 274/334 [00:55<00:12,  4.90it/s, loss=0.391]\u001b[A\n",
      "Train step of epoch 0:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 274/334 [00:55<00:12,  4.90it/s, loss=0.0831]\u001b[A\n",
      "Train step of epoch 0:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 275/334 [00:55<00:12,  4.92it/s, loss=0.0831]\u001b[A\n",
      "Train step of epoch 0:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 275/334 [00:55<00:12,  4.92it/s, loss=0.346] \u001b[A\n",
      "Train step of epoch 0:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 276/334 [00:55<00:11,  4.90it/s, loss=0.346]\u001b[A\n",
      "Train step of epoch 0:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 276/334 [00:56<00:11,  4.90it/s, loss=0.0865]\u001b[A\n",
      "Train step of epoch 0:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 277/334 [00:56<00:11,  4.89it/s, loss=0.0865]\u001b[A\n",
      "Train step of epoch 0:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 277/334 [00:56<00:11,  4.89it/s, loss=4.99e-5]\u001b[A\n",
      "Train step of epoch 0:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 278/334 [00:56<00:11,  4.89it/s, loss=4.99e-5]\u001b[A\n",
      "Train step of epoch 0:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 278/334 [00:56<00:11,  4.89it/s, loss=0.0066] \u001b[A\n",
      "Train step of epoch 0:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 279/334 [00:56<00:11,  4.90it/s, loss=0.0066]\u001b[A\n",
      "Train step of epoch 0:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 279/334 [00:56<00:11,  4.90it/s, loss=0.000211]\u001b[A\n",
      "Train step of epoch 0:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 280/334 [00:56<00:11,  4.91it/s, loss=0.000211]\u001b[A\n",
      "Train step of epoch 0:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 280/334 [00:56<00:11,  4.91it/s, loss=0.19]    \u001b[A\n",
      "Train step of epoch 0:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 281/334 [00:57<00:10,  4.90it/s, loss=0.19]\u001b[A\n",
      "Train step of epoch 0:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 281/334 [00:57<00:10,  4.90it/s, loss=0.188]\u001b[A\n",
      "Train step of epoch 0:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 282/334 [00:57<00:10,  4.92it/s, loss=0.188]\u001b[A\n",
      "Train step of epoch 0:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 282/334 [00:57<00:10,  4.92it/s, loss=0.204]\u001b[A\n",
      "Train step of epoch 0:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 283/334 [00:57<00:10,  4.91it/s, loss=0.204]\u001b[A\n",
      "Train step of epoch 0:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 283/334 [00:57<00:10,  4.91it/s, loss=0.00194]\u001b[A\n",
      "Train step of epoch 0:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 284/334 [00:57<00:10,  4.89it/s, loss=0.00194]\u001b[A\n",
      "Train step of epoch 0:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 284/334 [00:57<00:10,  4.89it/s, loss=0.00441]\u001b[A\n",
      "Train step of epoch 0:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 285/334 [00:57<00:09,  4.90it/s, loss=0.00441]\u001b[A\n",
      "Train step of epoch 0:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 285/334 [00:57<00:09,  4.90it/s, loss=3.97e-8]\u001b[A\n",
      "Train step of epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 286/334 [00:58<00:09,  4.88it/s, loss=3.97e-8]\u001b[A\n",
      "Train step of epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 286/334 [00:58<00:09,  4.88it/s, loss=0.00013]\u001b[A\n",
      "Train step of epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 287/334 [00:58<00:09,  4.88it/s, loss=0.00013]\u001b[A\n",
      "Train step of epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 287/334 [00:58<00:09,  4.88it/s, loss=0.00466]\u001b[A\n",
      "Train step of epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 288/334 [00:58<00:09,  4.89it/s, loss=0.00466]\u001b[A\n",
      "Train step of epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 288/334 [00:58<00:09,  4.89it/s, loss=0.693]  \u001b[A\n",
      "Train step of epoch 0:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 289/334 [00:58<00:09,  4.89it/s, loss=0.693]\u001b[A\n",
      "Train step of epoch 0:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 289/334 [00:58<00:09,  4.89it/s, loss=0.0588]\u001b[A\n",
      "Train step of epoch 0:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 290/334 [00:58<00:08,  4.92it/s, loss=0.0588]\u001b[A\n",
      "Train step of epoch 0:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 290/334 [00:58<00:08,  4.92it/s, loss=0.0099]\u001b[A\n",
      "Train step of epoch 0:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 291/334 [00:59<00:08,  4.91it/s, loss=0.0099]\u001b[A\n",
      "Train step of epoch 0:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 291/334 [00:59<00:08,  4.91it/s, loss=1.56]  \u001b[A\n",
      "Train step of epoch 0:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 292/334 [00:59<00:08,  4.91it/s, loss=1.56]\u001b[A\n",
      "Train step of epoch 0:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 292/334 [00:59<00:08,  4.91it/s, loss=0.788]\u001b[A\n",
      "Train step of epoch 0:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 293/334 [00:59<00:08,  4.92it/s, loss=0.788]\u001b[A\n",
      "Train step of epoch 0:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 293/334 [00:59<00:08,  4.92it/s, loss=0.00112]\u001b[A\n",
      "Train step of epoch 0:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 294/334 [00:59<00:08,  4.92it/s, loss=0.00112]\u001b[A\n",
      "Train step of epoch 0:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 294/334 [00:59<00:08,  4.92it/s, loss=0.0375] \u001b[A\n",
      "Train step of epoch 0:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 295/334 [00:59<00:07,  4.90it/s, loss=0.0375]\u001b[A\n",
      "Train step of epoch 0:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 295/334 [00:59<00:07,  4.90it/s, loss=0.337] \u001b[A\n",
      "Train step of epoch 0:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 296/334 [01:00<00:07,  4.90it/s, loss=0.337]\u001b[A\n",
      "Train step of epoch 0:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 296/334 [01:00<00:07,  4.90it/s, loss=0.461]\u001b[A\n",
      "Train step of epoch 0:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 297/334 [01:00<00:07,  4.91it/s, loss=0.461]\u001b[A\n",
      "Train step of epoch 0:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 297/334 [01:00<00:07,  4.91it/s, loss=0.221]\u001b[A\n",
      "Train step of epoch 0:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 298/334 [01:00<00:07,  4.89it/s, loss=0.221]\u001b[A\n",
      "Train step of epoch 0:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 298/334 [01:00<00:07,  4.89it/s, loss=0.12] \u001b[A\n",
      "Train step of epoch 0:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 299/334 [01:00<00:07,  4.89it/s, loss=0.12]\u001b[A\n",
      "Train step of epoch 0:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 299/334 [01:00<00:07,  4.89it/s, loss=0.711]\u001b[A\n",
      "Train step of epoch 0:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 300/334 [01:00<00:06,  4.87it/s, loss=0.711]\u001b[A\n",
      "Train step of epoch 0:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 300/334 [01:00<00:06,  4.87it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 301/334 [01:01<00:06,  4.86it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 301/334 [01:01<00:06,  4.86it/s, loss=0.0667]\u001b[A\n",
      "Train step of epoch 0:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 302/334 [01:01<00:06,  4.86it/s, loss=0.0667]\u001b[A\n",
      "Train step of epoch 0:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 302/334 [01:01<00:06,  4.86it/s, loss=0.324] \u001b[A\n",
      "Train step of epoch 0:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 303/334 [01:01<00:06,  4.84it/s, loss=0.324]\u001b[A\n",
      "Train step of epoch 0:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 303/334 [01:01<00:06,  4.84it/s, loss=0.00591]\u001b[A\n",
      "Train step of epoch 0:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 304/334 [01:01<00:06,  4.86it/s, loss=0.00591]\u001b[A\n",
      "Train step of epoch 0:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 304/334 [01:01<00:06,  4.86it/s, loss=0.143]  \u001b[A\n",
      "Train step of epoch 0:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 305/334 [01:01<00:05,  4.86it/s, loss=0.143]\u001b[A\n",
      "Train step of epoch 0:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 305/334 [01:01<00:05,  4.86it/s, loss=0.462]\u001b[A\n",
      "Train step of epoch 0:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 306/334 [01:02<00:05,  4.85it/s, loss=0.462]\u001b[A\n",
      "Train step of epoch 0:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 306/334 [01:02<00:05,  4.85it/s, loss=0.456]\u001b[A\n",
      "Train step of epoch 0:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 307/334 [01:02<00:05,  4.86it/s, loss=0.456]\u001b[A\n",
      "Train step of epoch 0:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 307/334 [01:02<00:05,  4.86it/s, loss=0.0478]\u001b[A\n",
      "Train step of epoch 0:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 308/334 [01:02<00:05,  4.85it/s, loss=0.0478]\u001b[A\n",
      "Train step of epoch 0:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 308/334 [01:02<00:05,  4.85it/s, loss=0.347] \u001b[A\n",
      "Train step of epoch 0:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 309/334 [01:02<00:05,  4.85it/s, loss=0.347]\u001b[A\n",
      "Train step of epoch 0:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 309/334 [01:02<00:05,  4.85it/s, loss=0.0757]\u001b[A\n",
      "Train step of epoch 0:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 310/334 [01:02<00:04,  4.86it/s, loss=0.0757]\u001b[A\n",
      "Train step of epoch 0:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 310/334 [01:02<00:04,  4.86it/s, loss=0.0336]\u001b[A\n",
      "Train step of epoch 0:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 311/334 [01:03<00:04,  4.86it/s, loss=0.0336]\u001b[A\n",
      "Train step of epoch 0:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 311/334 [01:03<00:04,  4.86it/s, loss=0.0691]\u001b[A\n",
      "Train step of epoch 0:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 312/334 [01:03<00:04,  4.87it/s, loss=0.0691]\u001b[A\n",
      "Train step of epoch 0:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 312/334 [01:03<00:04,  4.87it/s, loss=0.153] \u001b[A\n",
      "Train step of epoch 0:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 313/334 [01:03<00:04,  4.87it/s, loss=0.153]\u001b[A\n",
      "Train step of epoch 0:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 313/334 [01:03<00:04,  4.87it/s, loss=0.125]\u001b[A\n",
      "Train step of epoch 0:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 314/334 [01:03<00:04,  4.86it/s, loss=0.125]\u001b[A\n",
      "Train step of epoch 0:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 314/334 [01:03<00:04,  4.86it/s, loss=0.19] \u001b[A\n",
      "Train step of epoch 0:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 315/334 [01:03<00:03,  4.87it/s, loss=0.19]\u001b[A\n",
      "Train step of epoch 0:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 315/334 [01:04<00:03,  4.87it/s, loss=0.0525]\u001b[A\n",
      "Train step of epoch 0:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 316/334 [01:04<00:03,  4.87it/s, loss=0.0525]\u001b[A\n",
      "Train step of epoch 0:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 316/334 [01:04<00:03,  4.87it/s, loss=0.305] \u001b[A\n",
      "Train step of epoch 0:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 317/334 [01:04<00:03,  4.86it/s, loss=0.305]\u001b[A\n",
      "Train step of epoch 0:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 317/334 [01:04<00:03,  4.86it/s, loss=0.113]\u001b[A\n",
      "Train step of epoch 0:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 318/334 [01:04<00:03,  4.86it/s, loss=0.113]\u001b[A\n",
      "Train step of epoch 0:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 318/334 [01:04<00:03,  4.86it/s, loss=0.000604]\u001b[A\n",
      "Train step of epoch 0:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 319/334 [01:04<00:03,  4.84it/s, loss=0.000604]\u001b[A\n",
      "Train step of epoch 0:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 319/334 [01:04<00:03,  4.84it/s, loss=0.000174]\u001b[A\n",
      "Train step of epoch 0:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 320/334 [01:05<00:02,  4.85it/s, loss=0.000174]\u001b[A\n",
      "Train step of epoch 0:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 320/334 [01:05<00:02,  4.85it/s, loss=0.525]   \u001b[A\n",
      "Train step of epoch 0:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 321/334 [01:05<00:02,  4.84it/s, loss=0.525]\u001b[A\n",
      "Train step of epoch 0:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 321/334 [01:05<00:02,  4.84it/s, loss=0.0543]\u001b[A\n",
      "Train step of epoch 0:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 322/334 [01:05<00:02,  4.86it/s, loss=0.0543]\u001b[A\n",
      "Train step of epoch 0:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 322/334 [01:05<00:02,  4.86it/s, loss=0.0643]\u001b[A\n",
      "Train step of epoch 0:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 323/334 [01:05<00:02,  4.88it/s, loss=0.0643]\u001b[A\n",
      "Train step of epoch 0:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 323/334 [01:05<00:02,  4.88it/s, loss=0.0133]\u001b[A\n",
      "Train step of epoch 0:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 324/334 [01:05<00:02,  4.89it/s, loss=0.0133]\u001b[A\n",
      "Train step of epoch 0:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 324/334 [01:05<00:02,  4.89it/s, loss=0.0451]\u001b[A\n",
      "Train step of epoch 0:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 325/334 [01:06<00:01,  4.88it/s, loss=0.0451]\u001b[A\n",
      "Train step of epoch 0:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 325/334 [01:06<00:01,  4.88it/s, loss=0.00628]\u001b[A\n",
      "Train step of epoch 0:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 326/334 [01:06<00:01,  4.88it/s, loss=0.00628]\u001b[A\n",
      "Train step of epoch 0:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 326/334 [01:06<00:01,  4.88it/s, loss=0.00387]\u001b[A\n",
      "Train step of epoch 0:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 327/334 [01:06<00:01,  4.90it/s, loss=0.00387]\u001b[A\n",
      "Train step of epoch 0:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 327/334 [01:06<00:01,  4.90it/s, loss=0.0854] \u001b[A\n",
      "Train step of epoch 0:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 328/334 [01:06<00:01,  4.91it/s, loss=0.0854]\u001b[A\n",
      "Train step of epoch 0:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 328/334 [01:06<00:01,  4.91it/s, loss=0.0269]\u001b[A\n",
      "Train step of epoch 0:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 329/334 [01:06<00:01,  4.95it/s, loss=0.0269]\u001b[A\n",
      "Train step of epoch 0:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 329/334 [01:06<00:01,  4.95it/s, loss=0.013] \u001b[A\n",
      "Train step of epoch 0:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 330/334 [01:07<00:00,  4.92it/s, loss=0.013]\u001b[A\n",
      "Train step of epoch 0:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 330/334 [01:07<00:00,  4.92it/s, loss=0.184]\u001b[A\n",
      "Train step of epoch 0:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 331/334 [01:07<00:00,  4.90it/s, loss=0.184]\u001b[A\n",
      "Train step of epoch 0:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 331/334 [01:07<00:00,  4.90it/s, loss=0.0971]\u001b[A\n",
      "Train step of epoch 0:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 332/334 [01:07<00:00,  4.89it/s, loss=0.0971]\u001b[A\n",
      "Train step of epoch 0:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 332/334 [01:07<00:00,  4.89it/s, loss=0.0274]\u001b[A\n",
      "Train step of epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 333/334 [01:07<00:00,  4.88it/s, loss=0.0274]\u001b[A\n",
      "Train step of epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 333/334 [01:07<00:00,  4.88it/s, loss=0.246] \u001b[A\n",
      "Train step of epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 334/334 [01:07<00:00,  5.40it/s, loss=0.246]\u001b[A\n",
      "Train epoch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [01:11<00:00, 71.26s/it]00,  5.40it/s, loss=0.000697]\u001b[A\n",
      "Train step of epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 334/334 [01:11<00:00,  4.69it/s, loss=0.174, dist_mean=11.5]\u001b[A\n",
      "Train epoch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [01:11<00:00, 71.26s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(use_lora=0)\n",
    "\n",
    "model.save_pretrained('/output_2_RM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f148f410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: Ïù∏Í≥µÏßÄÎä•ÏùÄ Îò•Î©çÏ≤≠Ïù¥ ÏûÖÎãàÎã§\n",
      "reward score: -0.7\n"
     ]
    }
   ],
   "source": [
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward\n",
    "\n",
    "input_text = 'Ïù∏Í≥µÏßÄÎä•ÏùÄ Îò•Î©çÏ≤≠Ïù¥ ÏûÖÎãàÎã§'\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f186d",
   "metadata": {},
   "source": [
    "## PPO Ï†ÅÏö©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71cbb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d7a73e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained='/output_1_SFT', lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained='aiffel/KoChatGPT/output_2_RM', lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=128\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2f8d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)\n",
    "\n",
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2abb58b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize\n",
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9dc86921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=5,  \n",
    "                     train_batch_size=16, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80ea4f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.87s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.00612]\u001b[A\n",
      "Train epoch [1/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.09it/s, actor_loss=0, critic_loss=0.00612]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.378]\u001b[A\n",
      "Train epoch [2/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.12it/s, actor_loss=0, critic_loss=0.378]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.0616]\u001b[A\n",
      "Train epoch [3/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.12it/s, actor_loss=0, critic_loss=0.0616]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.235]\u001b[A\n",
      "Train epoch [4/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.12it/s, actor_loss=0, critic_loss=0.235]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.258]\u001b[A\n",
      "Train epoch [5/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.12it/s, actor_loss=0, critic_loss=0.258]\u001b[A\n",
      "Episode [1/10]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:21<00:00,  7.30s/it]\n",
      "Episode [2/10]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.80s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.306, critic_loss=0.115]\u001b[A\n",
      "Train epoch [1/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.306, critic_loss=0.115]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.318, critic_loss=0.0159]\u001b[A\n",
      "Train epoch [2/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s, actor_loss=0.318, critic_loss=0.0159]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.319, critic_loss=0.0466]\u001b[A\n",
      "Train epoch [3/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s, actor_loss=0.319, critic_loss=0.0466]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.296, critic_loss=0.148]\u001b[A\n",
      "Train epoch [4/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s, actor_loss=0.296, critic_loss=0.148]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.296, critic_loss=0.118]\u001b[A\n",
      "Train epoch [5/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.296, critic_loss=0.118]\u001b[A\n",
      "Episode [2/10]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:22<00:00,  7.42s/it]\n",
      "Episode [3/10]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.84s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.216, critic_loss=0.0717]\u001b[A\n",
      "Train epoch [1/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.06it/s, actor_loss=-.216, critic_loss=0.0717]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.22, critic_loss=0.0204]\u001b[A\n",
      "Train epoch [2/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.06it/s, actor_loss=-.22, critic_loss=0.0204]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.221, critic_loss=0.018]\u001b[A\n",
      "Train epoch [3/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.06it/s, actor_loss=-.221, critic_loss=0.018]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.206, critic_loss=0.0538]\u001b[A\n",
      "Train epoch [4/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.206, critic_loss=0.0538]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.229, critic_loss=0.0757]\u001b[A\n",
      "Train epoch [5/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.06it/s, actor_loss=-.229, critic_loss=0.0757]\u001b[A\n",
      "Episode [3/10]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:22<00:00,  7.45s/it]\n",
      "Episode [4/10]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:10<00:05,  5.16s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.227, critic_loss=0.0565]\u001b[A\n",
      "Train epoch [1/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.06it/s, actor_loss=0.227, critic_loss=0.0565]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.221, critic_loss=0.0282]\u001b[A\n",
      "Train epoch [2/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.221, critic_loss=0.0282]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.235, critic_loss=0.0129]\u001b[A\n",
      "Train epoch [3/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.235, critic_loss=0.0129]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.263, critic_loss=0.0183]\u001b[A\n",
      "Train epoch [4/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s, actor_loss=0.263, critic_loss=0.0183]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.229, critic_loss=0.0337]\u001b[A\n",
      "Train epoch [5/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.229, critic_loss=0.0337]\u001b[A\n",
      "Episode [4/10]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:21<00:00,  7.08s/it]\n",
      "Episode [5/10]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:10<00:04,  4.98s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0672, critic_loss=0.0553]\u001b[A\n",
      "Train epoch [1/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.0672, critic_loss=0.0553]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.116, critic_loss=0.035]\u001b[A\n",
      "Train epoch [2/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.116, critic_loss=0.035]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0724, critic_loss=0.0306]\u001b[A\n",
      "Train epoch [3/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s, actor_loss=-.0724, critic_loss=0.0306]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.112, critic_loss=0.0145]\u001b[A\n",
      "Train epoch [4/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.112, critic_loss=0.0145]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0812, critic_loss=0.00753]\u001b[A\n",
      "Train epoch [5/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s, actor_loss=-.0812, critic_loss=0.00753]\u001b[A\n",
      "Episode [5/10]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:20<00:00,  6.93s/it]\n",
      "Episode [6/10]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.93s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.177, critic_loss=0.182]\u001b[A\n",
      "Train epoch [1/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.177, critic_loss=0.182]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0927, critic_loss=0.118]\u001b[A\n",
      "Train epoch [2/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.0927, critic_loss=0.118]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.00528, critic_loss=0.00769]\u001b[A\n",
      "Train epoch [3/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.00528, critic_loss=0.00769]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0937, critic_loss=0.0631]\u001b[A\n",
      "Train epoch [4/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.0937, critic_loss=0.0631]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0654, critic_loss=0.0556]\u001b[A\n",
      "Train epoch [5/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.0654, critic_loss=0.0556]\u001b[A\n",
      "Episode [6/10]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:22<00:00,  7.50s/it]\n",
      "Episode [7/10]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.83s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0763, critic_loss=0.0196]\u001b[A\n",
      "Train epoch [1/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.06it/s, actor_loss=-.0763, critic_loss=0.0196]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0846, critic_loss=0.0197]\u001b[A\n",
      "Train epoch [2/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.0846, critic_loss=0.0197]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0868, critic_loss=0.0119]\u001b[A\n",
      "Train epoch [3/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s, actor_loss=-.0868, critic_loss=0.0119]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0778, critic_loss=0.00926]\u001b[A\n",
      "Train epoch [4/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.0778, critic_loss=0.00926]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0788, critic_loss=0.025]\u001b[A\n",
      "Train epoch [5/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s, actor_loss=-.0788, critic_loss=0.025]\u001b[A\n",
      "Episode [7/10]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:22<00:00,  7.44s/it]\n",
      "Episode [8/10]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.95s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0661, critic_loss=0.0316]\u001b[A\n",
      "Train epoch [1/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.0661, critic_loss=0.0316]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0343, critic_loss=0.025]\u001b[A\n",
      "Train epoch [2/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.0343, critic_loss=0.025]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0778, critic_loss=0.0258]\u001b[A\n",
      "Train epoch [3/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s, actor_loss=0.0778, critic_loss=0.0258]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0294, critic_loss=0.014]\u001b[A\n",
      "Train epoch [4/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s, actor_loss=0.0294, critic_loss=0.014]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0684, critic_loss=0.00989]\u001b[A\n",
      "Train epoch [5/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s, actor_loss=0.0684, critic_loss=0.00989]\u001b[A\n",
      "Episode [8/10]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:22<00:00,  7.50s/it]\n",
      "Episode [9/10]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.90s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0328, critic_loss=0.0248]\u001b[A\n",
      "Train epoch [1/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.0328, critic_loss=0.0248]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0394, critic_loss=0.0152]\u001b[A\n",
      "Train epoch [2/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s, actor_loss=-.0394, critic_loss=0.0152]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0301, critic_loss=0.0129]\u001b[A\n",
      "Train epoch [3/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s, actor_loss=-.0301, critic_loss=0.0129]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0227, critic_loss=0.00416]\u001b[A\n",
      "Train epoch [4/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.08it/s, actor_loss=-.0227, critic_loss=0.00416]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0294, critic_loss=0.00774]\u001b[A\n",
      "Train epoch [5/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.0294, critic_loss=0.00774]\u001b[A\n",
      "Episode [9/10]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:22<00:00,  7.47s/it]\n",
      "Episode [10/10]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:11<00:05,  5.87s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.00604, critic_loss=0.00962]\u001b[A\n",
      "Train epoch [1/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.06it/s, actor_loss=-.00604, critic_loss=0.00962]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.00377, critic_loss=0.0178]\u001b[A\n",
      "Train epoch [2/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.06it/s, actor_loss=-.00377, critic_loss=0.0178]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.000281, critic_loss=0.0179]\u001b[A\n",
      "Train epoch [3/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.000281, critic_loss=0.0179]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.00343, critic_loss=0.0143]\u001b[A\n",
      "Train epoch [4/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.00343, critic_loss=0.0143]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.00325, critic_loss=0.00834]\u001b[A\n",
      "Train epoch [5/5]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.00325, critic_loss=0.00834]\u001b[A\n",
      "Episode [10/10]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:22<00:00,  7.47s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1633ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('/output_3_PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bf92c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=128,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.50,\n",
    "                             no_repeat_ngram_size=4, \n",
    "                             early_stopping=True,\n",
    "                             repetition_penalty=2.0,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6ac4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "RLHF_output = []\n",
    "for input_text in input_prompt:\n",
    "    new_output.append(generation(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1de07f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2325450947266871"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate BLEU score\n",
    "RLHF_bleu_score = []\n",
    "for output, target in zip(RLHF_output, labeled_completion):\n",
    "    RLHF_bleu_score.append(calculate_bleu_score([output], [target])['score'])\n",
    "\n",
    "sum(RLHF_bleu_score)/len(RLHF_bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0e066",
   "metadata": {},
   "source": [
    "## RLHF Î™®Îç∏ bleu score : 0.232"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf02e20",
   "metadata": {},
   "source": [
    "### ÎãµÎ≥Ä ÎπÑÍµê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c00c43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ïñ¥ÎîîÏóê ÍπÄÏòÅÏÇºÏùò ÏÑúÏö∏ÎåÄÌïôÍµê ÏûÖÌïô Î∞è Ï°∏ÏóÖ Ï¶ùÎ™ÖÏÑúÍ∞Ä Ï†ÑÏãúÎêòÏñ¥ ÏûàÎäîÍ∞Ä?'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_prompt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7fc303a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ïñ¥ÎîîÏóê ÍπÄÏòÅÏÇºÏùò ÏÑúÏö∏ÎåÄÌïôÍµê ÏûÖÌïô Î∞è Ï°∏ÏóÖ Ï¶ùÎ™ÖÏÑúÍ∞Ä Ï†ÑÏãúÎêòÏñ¥ ÏûàÎäîÍ∞Ä? Îö±Îö± ÏÑ∏Ïù∏Ìä∏ Ïö∏ÌîÑ [UNK]Ìù© ÏßÑ Ë®ü Ï°∞Íµê9 Ê∫ñ Ê∑Æ Í∏∞ÏóÖ È≥© Ê∑Æ Í∏∞ÏóÖ È≥© È≥©Ï´å ‰∫∫ [UNK] ÏßÑ Ë®ü Ê∫ñ Í±∞Îûò È≥© Ê∑Æ Í∏∞ÏóÖ È≥© Ìö®Í≥º Ê∑Æ! È≥©Ï´å ‰∫∫ [UNK] Ïá†ÏûÑ Ìö®Í≥º Ê∑Æ!! È≥©Ï´å È≥© Ìö®Í≥º ‰∫∫ [UNK] È≥© Ìö®Í≥º Ê∑Æ!ÎôáÏûÑÎôáÎ•¥ È≥© Ìö®Í≥º ‰∫∫ [UNK] Ìö®Í≥º ‰ª≤ Â≠´! ÏÉàÎ°úÏö¥ Â≠´ È≥© Ìö®Í≥º Ê∑Æ! È≥© Ìö®Í≥º! ‰∫¶! ÏÉàÎ°úÏö¥ Â≠´ È≥© Ìö®Í≥º ‰∫® [UNK] È≥© Ìö®Í≥º ‰∫∫ [UNK] Ìö®Í≥º ‰ª≤ Â≠´ Â≠´! ÏÉàÎ°úÏö¥ Â≠´ È≥© Ìö®Í≥º Ê∑Æ! È≥©Ï´å ‰∫∫ [UNK] Îãù Ïà± Â≠´! Ïà± Â≠´ Â≠´!'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RLHF_output[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24cfc50",
   "metadata": {},
   "source": [
    "## 2. SFTÎ•º Ï†ÅÏö©Ìïú Î™®Îç∏Í≥º RLHFÎ•º Ï†ÅÏö©Ìïú Î™®Îç∏Ïùò Í≤∞Í≥ºÎ¨ºÏùÑ Ï†ïÎüâ/Ï†ïÏÑ±Ï†ÅÏúºÎ°ú ÎπÑÍµê/Î∂ÑÏÑù\n",
    "- Ï†ïÎüâÏ†Å ÌèâÍ∞Ä\n",
    "    \n",
    "    SFT Ï†ÅÏö© Î™®Îç∏Ïùò bleu score : 0.137\n",
    "    \n",
    "    RLHF Î™®Îç∏Ïùò bleu score : 0.232\n",
    "\n",
    "    \n",
    "    * ÌòÑÏû¨ Îëê Î™®Îç∏ Î™®Îëê outputÏóê inputÏùò promptÍ∞Ä Ìè¨Ìï®ÎêòÏóàÍ∏∞ ÎïåÎ¨∏Ïóê Ïã§Ï†úÎ≥¥Îã§ Îçî ÎÜíÏùÄ scoreÍ∞Ä ÎÇòÏò¨ Í∞ÄÎä•ÏÑ±Ïù¥ ÏûàÎã§. RLHF Î™®Îç∏Ïùò bleu scoreÍ∞Ä Îçî ÎÇÆÍ≤å ÎÇòÏôîÏßÄÎßå, Ïù¥Îäî Ï†ïÌôïÌïòÏßÄ ÏïäÏùÄ ÏßÄÌëúÎùºÎäî ÏùòÎ¨∏Ïù¥ Îì†Îã§. \n",
    "        \n",
    "        \n",
    "- Ï†ïÏÑ±Ï†Å ÌèâÍ∞Ä\n",
    "    \n",
    "    SFT Î™®Îç∏Ïùò ÌèâÍ∞Ä : ÏßàÎ¨∏ÏûêÏùò ÏßàÎ¨∏Ïóê Í¥ÄÎ†®ÏÑ± ÏûàÍ≤å ÎãµÎ≥ÄÏùÑ ÌïòÏòÄÎã§. ÏßàÎ¨∏ÏûêÏùò ÏßàÎ¨∏ÏùÑ Ï†ïÌôïÌûà Ïù¥Ìï¥ÌïòÍ≥† Îß•ÎùΩÏóê ÎßûÍ≤å ÎãµÎ≥ÄÌïòÏòÄÎã§. Îã§Îßå, ÎåÄÎ∂ÄÎ∂Ñ ÏßàÎ¨∏Ïóê ÎåÄÌï¥ÏÑú Ï†ïÌôïÌïòÍ≤å ÎãµÎ≥ÄÏùÑ Ï†úÏïàÌïòÏßÄ Î™ªÌñàÎã§.\n",
    "    \n",
    "    \n",
    "    RLHF Î™®Îç∏Ïùò ÌèâÍ∞Ä : RLHFÏùò Î™®Îç∏ÏùÄ ÏßàÎ¨∏ÏûêÏùò ÏßàÎ¨∏Í≥º ÎãµÎ≥Ä Í∞ÑÏùò Í¥ÄÍ≥ÑÍ∞Ä Í±∞Ïùò ÏóÜÎã§. ÎòêÌïú Î∞òÎ≥µÎêú Îã®Ïñ¥Î•º ÏÇ¨Ïö©ÌïòÏó¨ bleu scoreÎäî ÎÜíÏùÄ Í∞íÏù¥ ÎÇòÏôîÏßÄÎßå, ÏßàÎ¨∏Í≥º Í¥ÄÍ≥ÑÏóÜÎäî ÎãµÎ≥ÄÏù¥ Î∞òÎ≥µÎêòÏñ¥ Ï±óÎ¥áÏùò Í∏∞Îä•ÏúºÎ°úÏÑú ÎèÑÏõÄÏù¥ ÎêòÏßÄ ÏïäÎäîÎã§. Îã®Ïñ¥Î•º ÎÇòÏó¥ÌïòÎäî ÏàúÏÑúÎÇò Î¨∏Ïû•Ïùò ÏôÑÏÑ±ÎèÑ ÎòêÌïú Ïò¨Î∞îÎ•¥ÏßÄ Î™ªÌñàÎã§.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d1ad23",
   "metadata": {},
   "source": [
    "# 3. Foundation Model ÍµêÏ≤¥Î•º ÌÜµÌïú Ï†ïÎüâÏ†Å ÏÑ±Îä•Ìñ•ÏÉÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6b3cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "972903c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f346d0907a4d2bae4716b3813ac071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/591 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3f0b3336d64d7a82a83d53daea40b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/449M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `ElectraForCausalLM` as a standalone, add `is_decoder=True.`\n",
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-finetuned-korquad were not used when initializing ElectraForCausalLM: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing ElectraForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForCausalLM were not initialized from the model checkpoint at monologg/koelectra-base-v3-finetuned-korquad and are newly initialized: ['generator_predictions.dense.bias', 'generator_predictions.LayerNorm.bias', 'generator_lm_head.bias', 'generator_predictions.dense.weight', 'generator_predictions.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b57ecacb2724307af4faa4268707b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf20572e1c64db28dfe8ef865665ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/263k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d55affbae984e61a56b27e8267e1b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = 'monologg/koelectra-base-v3-finetuned-korquad'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "                                           bos_token='</s>', \n",
    "                                           eos_token='</s>', \n",
    "                                           unk_token='</s>', \n",
    "                                           pad_token='</s>',\n",
    "                                           padding_side=\"right\",\n",
    "                                           model_max_length=128,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f326d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_output = []\n",
    "max_length = 128\n",
    "\n",
    "for input_txt in input_prompt:\n",
    "    input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "    output= model.generate(input_ids, max_length=max_length, num_beams=4, no_repeat_ngram_size=4, early_stopping=True,\n",
    "                                 eos_token_id=375, do_sample=True, top_k=50, repetition_penalty=2.0)\n",
    "    new_output.append(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5e22a24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (130 > 128). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2331180272431364"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate BLEU score\n",
    "new_bleu_score = []\n",
    "for output, target in zip(new_output, labeled_completion):\n",
    "    new_bleu_score.append(calculate_bleu_score([output], [target])['score'])\n",
    "    \n",
    "sum(new_bleu_score)/len(new_bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f270e461",
   "metadata": {},
   "source": [
    "### monologg/koelectra-base-v3-finetuned-korquadÏùÑ Ï†ÅÏö©Ìïú Î™®Îç∏Ïùò bleu score : 0.233"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc91506",
   "metadata": {},
   "source": [
    "## Î∂ÑÏÑù : \n",
    " monologg/koelectra-base-v3-finetuned-korquad Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ bleu scoreÎ•º 0.227ÏóêÏÑú 0.233ÍπåÏßÄ Ìñ•ÏÉÅÏãúÏº∞Îã§."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a625f10",
   "metadata": {},
   "source": [
    "# ÌöåÍ≥†\n",
    "ÏûòÌïú Ï†ê : ÏΩîÎìúÏóê ÎåÄÌïú ÏÑ§Î™ÖÏù¥ Í±∞Ïùò ÏóÜÏóàÏùåÏóêÎèÑ Îã§Î•∏ ÏûêÎ£åÎì§ÏùÑ ÌôúÏö©ÌïòÏó¨ ÏΩîÎìúÎ•º Î∂ÑÏÑùÌïòÍ≥† Ï£ºÏñ¥ÏßÑ ÎØ∏ÏÖòÏóê ÎßûÍ≤å Í≥†Ï≥ê ÏÇ¨Ïö©ÌïòÏòÄÎã§.\n",
    "    \n",
    "Î™ªÌïú Ï†ê : ÏãúÍ∞ÑÏù¥ Î∂ÄÏ°±ÌïòÏó¨ Îã§ÏñëÌïú Ï†ÑÎûµÏùÑ ÏÇ¨Ïö©Ìï¥Î≥¥ÏßÄ Î™ªÌïòÍ≥† Í∞ÑÎã®Ìïú Í≤ÉÎßå ÏãúÎèÑÌï¥Î≥∏Í≤ÉÏù¥ ÏïÑÏâΩÎã§.\n",
    "    \n",
    "ÎÖ∏Î†•Ìï† Ï†ê : bleu score Ïù¥Ïô∏ÏóêÎèÑ Ï†ïÎüâÏ†Å ÌèâÍ∞ÄÎ•º Ìï† Ïàò ÏûàÎäî metrixÎ•º ÏÇ¨Ïö©Ìï¥Î≥¥Î©¥ Îçî Ï¢ãÏùÑÍ≤É Í∞ôÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97531038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
