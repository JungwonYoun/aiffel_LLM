{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d542f8d9",
   "metadata": {},
   "source": [
    "# í”„ë¡œì íŠ¸: KoChatGPT ì—…ê·¸ë ˆì´ë“œ í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1688069b",
   "metadata": {},
   "source": [
    "### ì •ëŸ‰ì  ë¶„ì„ì„ ìœ„í•œ bleu í‰ê°€ í•¨ìˆ˜ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d309960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17755cdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sacrebleu --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38a186a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1194a97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162/3884723172.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"sacrebleu\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "# Load the BLEU metric\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e9540b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize a sentence\n",
    "def tokenize_sentence(sentence):\n",
    "    # Implement tokenization using your tokenizer\n",
    "    # Return a list of tokens\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "875953d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate BLEU score\n",
    "def calculate_bleu_score(model_outputs, target_sentences):\n",
    "    # Tokenize model outputs and target sentences\n",
    "    tokenized_outputs = [tokenize_sentence(output) for output in model_outputs]\n",
    "    tokenized_targets = [tokenize_sentence(target) for target in target_sentences]\n",
    "    \n",
    "    # Calculate BLEU score\n",
    "    bleu_score = metric.compute(predictions=tokenized_outputs, references=tokenized_targets)\n",
    "    \n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4714aa34",
   "metadata": {},
   "source": [
    "### í‰ê°€ë¥¼ ìœ„í•œ ë°ì´í„°ì…‹ ë§Œë“¤ê¸° (íš¨ìœ¨ì„ ìœ„í•´ ë°ì´í„°ì…‹ í¬ê¸° ì¤„ì´ê¸° : 100ê°œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72f2a609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'í”Œë« í™”ì´íŠ¸ê°€ ë­”ê°€ìš”?',\n",
       "  'completion': '\\'\"í”Œë« í™”ì´íŠ¸\"ëŠ” ì¼ë°˜ì ìœ¼ë¡œ í°ìƒ‰ ë°°ê²½ì— ë§Œí™”ë‚˜ ì¼ëŸ¬ìŠ¤íŠ¸ ë“±ì„ ë‹´ì€ ë””ìì¸ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì£¼ë¡œ ì›¹íˆ°, ê²Œì„, ì• ë‹ˆë©”ì´ì…˜, ì˜í™” ë“±ì—ì„œ ì‚¬ìš©ë˜ë©°, í‰ë©´ì ìœ¼ë¡œ í‘œí˜„ëœ ê·¸ë˜í”½ ë””ìì¸ì˜ ìŠ¤íƒ€ì¼ì„ ë§í•©ë‹ˆë‹¤.',\n",
       "  'tokens': 127},\n",
       " {'prompt': 'ì–´ë””ì— ê¹€ì˜ì‚¼ì˜ ì„œìš¸ëŒ€í•™êµ ì…í•™ ë° ì¡¸ì—… ì¦ëª…ì„œê°€ ì „ì‹œë˜ì–´ ìˆëŠ”ê°€?',\n",
       "  'completion': \"'ê¹€ì˜ì‚¼ì˜ ì„œìš¸ëŒ€í•™êµ ì…í•™ ë° ì¡¸ì—… ì¦ëª…ì„œëŠ” ì„œìš¸ëŒ€í•™êµ ë¯¸ìˆ ê´€ì— ì „ì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.\",\n",
       "  'tokens': 105},\n",
       " {'prompt': 'ì œê°€ ì§€ê¸ˆ ê°•ë‚¨ì—­ì¸ë°, ì—¬ê¸°ì„œ ì˜¤ë˜ ê±¸ë¦´ê¹Œìš”?',\n",
       "  'completion': \"'ì €ëŠ” ì¸ê³µì§€ëŠ¥ ì±—ë´‡ì´ë¯€ë¡œ í˜„ì¬ì˜ êµí†µ ìƒí™©ê³¼ ì—¬í–‰ ê±°ë¦¬, ì´ë™ ë°©ë²• ë“±ê³¼ ê°™ì€ ì •ë³´ë¥¼ ë³´ìœ í•˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, ì¼ë°˜ì ìœ¼ë¡œ ê°•ë‚¨ì—­ì€ êµí†µì´ êµ‰ì¥íˆ ë³µì¡í•˜ê³  í˜¼ì¡í•˜ê¸° ë•Œë¬¸ì— ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ì´ë™í•˜ì‹¤ ìœ„ì¹˜ê°€ ì–´ë””ì¸ì§€ ì•Œë ¤ì£¼ì‹ ë‹¤ë©´, ë³´ë‹¤ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\",\n",
       "  'tokens': 195}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_1_SFT = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl' \n",
    "with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file_SFT:\n",
    "    list_data_dict_SFT = json.load(json_file_SFT)[11900:]\n",
    "\n",
    "print(len(list_data_dict_SFT))\n",
    "list_data_dict_SFT[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b478f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt = []\n",
    "for i in list_data_dict_SFT:\n",
    "    input_prompt.append(i['prompt'])\n",
    "    \n",
    "labeled_completion = []\n",
    "for i in list_data_dict_SFT:\n",
    "    labeled_completion.append(i['completion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0832ef1",
   "metadata": {},
   "source": [
    "# 2. SFT ëª¨ë¸ê³¼ RM ëª¨ë¸ ê²°ê³¼ ë¶„ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1badf869",
   "metadata": {},
   "source": [
    "## RM ì ìš© ëª¨ë¸ ê²°ê³¼ ë° í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a84c937",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import modules\n",
    "import os\n",
    "import json\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.trainer import RewardModelTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoConfig\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2b0d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None,\n",
    "                 config: Optional[GPT2Config] = None,\n",
    "                 checkpoint: bool = False,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none',\n",
    "                 tokenizer=None) -> None:\n",
    "        if pretrained is not None:\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None:\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b746b5",
   "metadata": {},
   "source": [
    "### ì‚¬ìš©í•  ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfd209e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=128,\n",
    ")\n",
    "\n",
    "with NaiveStrategy().model_init_context():\n",
    "    model = GPTRM_custom(pretrained='skt/kogpt2-base-v2', lora_rank=0, tokenizer=tokenizer).cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d0f26",
   "metadata": {},
   "source": [
    "### RMì„ í›ˆë ¨ì‹œí‚¬ ë•Œ ì‚¬ìš©í•  ranking datasetì„ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1e56682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data num: 10220\n",
      "after  data num: 30660\n",
      "data example: \n",
      "{'prompt': 'ì• í”Œì€ ë¦¬ì‚¬ë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í–ˆì–´', 'chosen': 'ì• í”Œì´ ëˆ„êµ¬ì¸ì§€ ëª…í™•íˆ ì•Œ ìˆ˜ ì—†ì–´ì„œ, ë¦¬ì‚¬ê°€ ëˆ„êµ¬ì¸ì§€ì™€ ì–´ë–¤ ìƒí™©ì—ì„œ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ì— ëŒ€í•œ ì¶”ê°€ì ì¸ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, ë³´ë‹¤ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'rejected': 'ì• í”Œì€ ë¦¬ì‚¬ë¥¼ ìœ„í•´ ê³ ê° ì„œë¹„ìŠ¤ ë¶€ì„œì—ì„œ ê³ ê° ë‹¤ì–‘í•œ ì»´í“¨í„° ê´€ë ¨ ë¬¸ì œì— ëŒ€í•´ ì‘ë‹µí•˜ëŠ” ë° í•„ìš”í•œ ëª¨ë“  ì§€ì›ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìê°€ í•˜ë“œì›¨ì–´ ë¬¸ì œë¥¼ ê²½í—˜í•  ë•Œ, ì „ë¬¸ê°€ë“¤ì€ í•„ìš”í•œ ìˆ˜ë¦¬(ìˆ˜ë¦¬, ì¶”ê°€ ë¶€í’ˆ ì œê³µ, ì†Œí”„íŠ¸ì›¨ì–´ ì—…ê·¸ë ˆì´ë“œ ë“±)ì„ ì œê³µí•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì‚¬ìš©ìê°€ ì‚¬ìš© ë°©ë²• ë¬¸ì œë‚˜ ê¸°íƒ€ ë¬¸ì œë¥¼ ê²½í—˜í•  ë•Œ, ëŒ€í™” ìƒëŒ€ë¡œ ì‚¬ìš©ìë¥¼ ì§€ì›í•  ìˆ˜ ìˆëŠ” ì „ë¬¸ ê³ ê° ì„œë¹„ìŠ¤ ì§ì›ë“¤ì´ ì‚¬ìš©ìì—ê²Œ ìƒë‹´í•˜ê³  ë„ì›€ì„ ì£¼ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì¸í„°ë„·ì—ì„œ ì œê³µë˜ëŠ” ì •ë³´ë¥¼ í†µí•´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê±°ë‚˜ ê³ ê° ì„œë¹„ìŠ¤ ì›¹ ì‚¬ì´íŠ¸ë¥¼ í†µí•´ ìì‹ ì˜ ë¬¸ì œë¥¼ ì§„ë‹¨í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë“± ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ë¦¬ì‚¬ë¥¼ ì²˜ë¦¬í•´ ì™”ìŠµë‹ˆë‹¤.'}\n"
     ]
    }
   ],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f285328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_ranking2chosen = []\n",
    "\n",
    "for tmp in list_data_dict:\n",
    "     prompt = tmp['prompt']\n",
    "     ranking = tmp['ranking']\n",
    "\n",
    "     for index in range(1, len(ranking)):\n",
    "         n = ranking[0]\n",
    "         m = ranking[index]\n",
    "\n",
    "\n",
    "         data = {\n",
    "             'prompt': prompt,\n",
    "             'chosen': tmp['completion_{}'.format(n)],\n",
    "             'rejected': tmp['completion_{}'.format(m)]\n",
    "         }\n",
    "\n",
    "         total_data_ranking2chosen.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e1b7a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'ì½œë¼ ë§ˆì‹œê³  ë¦¬í•„ ë¼ìš”?', 'chosen': 'ì €ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ ë§ˆì‹œëŠ” ìŒë£Œë‚˜ ìŒì‹ì„ ë¨¹ì§€ ì•Šê¸° ë•Œë¬¸ì— ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ëŒ€ì²´ë¡œ ë§¥ë„ë‚ ë“œë‚˜ ìŒì‹ì  ë“±ì—ì„œëŠ” ì½œë¼ì˜ ë¦¬í•„ì´ ê°€ëŠ¥í•œ ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë§¤ì¥ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ, ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.', 'rejected': 'ë‹¤í•œêµ­ì˜ êµ­ì œë¥¼ ë§Œë“œëŠ” ëœ»ì´ë‹¤. í•œêµ­ì—ì„œ êµ­ì œëŠ” ê±°ì˜ êµ­ìœ  êµ­æ›ã„ä¸­ã‚’ í•œêµ­ì—ì„œ êµ­ì œë¥¼ ì´ì–´ë‚˜ê²Œ í•˜ëŠ” ê°œë…ì´ êµ­ì œë“¤ì´ ì¼ì–´ë¯€ëŠ”  ë¯¿ì„ ê°œì´ \\n\\ní•œêµ­ì´ ëˆ‡êµ­í° êµ­ì œë¥¼ íƒœëŠ” ì•„ë¹„ êµ­ë™ë“¤ì˜ êµ­'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(12)\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0222ae33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|â–ˆâ–        | 144/1000 [00:00<00:00, 1424.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|â–ˆâ–ˆâ–ˆ       | 307/1000 [00:00<00:00, 1543.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 463/1000 [00:00<00:00, 1548.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 629/1000 [00:00<00:00, 1591.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 801/1000 [00:00<00:00, 1636.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 1596.40it/s][A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 1659.83it/s]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(eval_data))\n",
    "\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 128)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a366402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################\n",
      "## prompt ##\n",
      "ë‚´ì¼ ì¤‘ìš”í•œ ì¼ì´ ìˆëŠ”ë° ì˜· ì¶”ì²œí•´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?\n",
      "######################################################################\n",
      "## chosen ##\n",
      "ì œê°€ AI ì±—ë´‡ì´ê¸° ë•Œë¬¸ì— ì˜· ì¶”ì²œë„ ê°€ëŠ¥í•©ë‹ˆë‹¤! \\n\\nì–´ëŠ ì •ë„ì˜ í¬ë©€í•¨ì¸ì§€, í˜¹ì€ ì–´ë–¤ ìƒ‰ìƒì„ ì„ í˜¸í•˜ëŠ”ì§€ ë“± ì„¸ë¶€ì ì¸ ìš”êµ¬ì‚¬í•­ì´ ìˆìœ¼ë©´ ë” ì •í™•í•œ ì¶”ì²œì´ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤. \\n\\nê·¸ëŸ¬ë‚˜ ì¼ë°˜ì ìœ¼ë¡œ ì¤‘ìš”í•œ ì¼ì´ë¼ë©´ í¬ë©€í•œ ë²”ìœ„ì—ì„œ ì„ íƒí•˜ê¸°ë¥¼ ê¶Œí•´ë“œë¦¬ë©°, ì–´ëŠ ì •ë„ ì•ˆì •ê°ì„ ì£¼ëŠ” ìƒ‰ìƒ (ex. ê²€ì •, íšŒìƒ‰, ë„¤ì´ë¹„ ë“±)ì˜ ì˜·ì„ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤. \\n\\në¬´ë‚œí•˜ì§€ë§Œ ì„¸ë ¨ëœ ëŠë‚Œì„ ì£¼ëŠ” ì˜·ì„ ì„ íƒí•˜ì‹œëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. í–‰ìš´ì„ ë¹Œì–´ë“œë¦½ë‹ˆë‹¤!\n",
      "######################################################################\n",
      "## rejected ##\n",
      "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜· ì¶”ì²œì€ ë‹µë³€í•´ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°œì¸ì˜ ì·¨í–¥ê³¼ ìŠ¤íƒ€ì¼ì— ë”°ë¼ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ì í•©í•œ ì˜·ì„ ì¶”ì²œí•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë‹¤ìŒê³¼ ê°™ì€ ì¡°ì–¸ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "1. ìì‹ ì˜ ìŠ¤íƒ€ì¼ê³¼ ì·¨í–¥ì„ ê³ ë ¤í•˜ì—¬ ì˜·ì„ ì„ íƒí•˜ì„¸ìš”. \n",
      "2. ìì‹ ì˜ ìƒ‰ìƒê³¼ ê°€ì¥ ì˜ ì–´ìš¸ë¦¬\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print('#'*70)\n",
    "print('## prompt ##')\n",
    "print(train_data[idx]['prompt'])\n",
    "print('#'*70)\n",
    "print('## chosen ##')\n",
    "print(train_data[idx]['chosen'])\n",
    "print('#'*70)\n",
    "print('## rejected ##')\n",
    "print(train_data[idx]['rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158863cd",
   "metadata": {},
   "source": [
    "### RM í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "817eafcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=3,\n",
    "                             max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "106b018f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Train step of epoch 0:   0%|          | 0/334 [00:00<?, ?it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/334 [00:00<03:29,  1.59it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/334 [00:00<03:29,  1.59it/s, loss=0.837]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/334 [00:00<02:04,  2.66it/s, loss=0.837]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/334 [00:00<02:04,  2.66it/s, loss=0.428]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/334 [00:01<01:37,  3.38it/s, loss=0.428]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/334 [00:01<01:37,  3.38it/s, loss=1.44] \u001b[A\n",
      "Train step of epoch 0:   1%|          | 4/334 [00:01<01:24,  3.90it/s, loss=1.44]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 4/334 [00:01<01:24,  3.90it/s, loss=0.288]\u001b[A\n",
      "Train step of epoch 0:   1%|â–         | 5/334 [00:01<01:17,  4.26it/s, loss=0.288]\u001b[A\n",
      "Train step of epoch 0:   1%|â–         | 5/334 [00:01<01:17,  4.26it/s, loss=0.209]\u001b[A\n",
      "Train step of epoch 0:   2%|â–         | 6/334 [00:01<01:13,  4.49it/s, loss=0.209]\u001b[A\n",
      "Train step of epoch 0:   2%|â–         | 6/334 [00:01<01:13,  4.49it/s, loss=0.162]\u001b[A\n",
      "Train step of epoch 0:   2%|â–         | 7/334 [00:01<01:09,  4.67it/s, loss=0.162]\u001b[A\n",
      "Train step of epoch 0:   2%|â–         | 7/334 [00:01<01:09,  4.67it/s, loss=0.338]\u001b[A\n",
      "Train step of epoch 0:   2%|â–         | 8/334 [00:02<01:06,  4.87it/s, loss=0.338]\u001b[A\n",
      "Train step of epoch 0:   2%|â–         | 8/334 [00:02<01:06,  4.87it/s, loss=0.222]\u001b[A\n",
      "Train step of epoch 0:   3%|â–         | 9/334 [00:02<01:06,  4.90it/s, loss=0.222]\u001b[A\n",
      "Train step of epoch 0:   3%|â–         | 9/334 [00:02<01:06,  4.90it/s, loss=0.096]\u001b[A\n",
      "Train step of epoch 0:   3%|â–         | 10/334 [00:02<01:05,  4.94it/s, loss=0.096]\u001b[A\n",
      "Train step of epoch 0:   3%|â–         | 10/334 [00:02<01:05,  4.94it/s, loss=0.00322]\u001b[A\n",
      "Train step of epoch 0:   3%|â–         | 11/334 [00:02<01:05,  4.96it/s, loss=0.00322]\u001b[A\n",
      "Train step of epoch 0:   3%|â–         | 11/334 [00:02<01:05,  4.96it/s, loss=0.329]  \u001b[A\n",
      "Train step of epoch 0:   4%|â–         | 12/334 [00:02<01:04,  4.97it/s, loss=0.329]\u001b[A\n",
      "Train step of epoch 0:   4%|â–         | 12/334 [00:02<01:04,  4.97it/s, loss=0.00382]\u001b[A\n",
      "Train step of epoch 0:   4%|â–         | 13/334 [00:03<01:04,  5.00it/s, loss=0.00382]\u001b[A\n",
      "Train step of epoch 0:   4%|â–         | 13/334 [00:03<01:04,  5.00it/s, loss=0.000228]\u001b[A\n",
      "Train step of epoch 0:   4%|â–         | 14/334 [00:03<01:04,  4.99it/s, loss=0.000228]\u001b[A\n",
      "Train step of epoch 0:   4%|â–         | 14/334 [00:03<01:04,  4.99it/s, loss=0.00532] \u001b[A\n",
      "Train step of epoch 0:   4%|â–         | 15/334 [00:03<01:03,  4.99it/s, loss=0.00532]\u001b[A\n",
      "Train step of epoch 0:   4%|â–         | 15/334 [00:03<01:03,  4.99it/s, loss=0.0441] \u001b[A\n",
      "Train step of epoch 0:   5%|â–         | 16/334 [00:03<01:03,  5.02it/s, loss=0.0441]\u001b[A\n",
      "Train step of epoch 0:   5%|â–         | 16/334 [00:03<01:03,  5.02it/s, loss=0.357] \u001b[A\n",
      "Train step of epoch 0:   5%|â–Œ         | 17/334 [00:03<01:03,  5.00it/s, loss=0.357]\u001b[A\n",
      "Train step of epoch 0:   5%|â–Œ         | 17/334 [00:03<01:03,  5.00it/s, loss=0.105]\u001b[A\n",
      "Train step of epoch 0:   5%|â–Œ         | 18/334 [00:03<01:03,  5.01it/s, loss=0.105]\u001b[A\n",
      "Train step of epoch 0:   5%|â–Œ         | 18/334 [00:04<01:03,  5.01it/s, loss=0.00578]\u001b[A\n",
      "Train step of epoch 0:   6%|â–Œ         | 19/334 [00:04<01:02,  5.04it/s, loss=0.00578]\u001b[A\n",
      "Train step of epoch 0:   6%|â–Œ         | 19/334 [00:04<01:02,  5.04it/s, loss=0.488]  \u001b[A\n",
      "Train step of epoch 0:   6%|â–Œ         | 20/334 [00:04<01:02,  5.04it/s, loss=0.488]\u001b[A\n",
      "Train step of epoch 0:   6%|â–Œ         | 20/334 [00:04<01:02,  5.04it/s, loss=8.69e-5]\u001b[A\n",
      "Train step of epoch 0:   6%|â–‹         | 21/334 [00:04<01:02,  5.02it/s, loss=8.69e-5]\u001b[A\n",
      "Train step of epoch 0:   6%|â–‹         | 21/334 [00:04<01:02,  5.02it/s, loss=0.144]  \u001b[A\n",
      "Train step of epoch 0:   7%|â–‹         | 22/334 [00:04<01:02,  5.02it/s, loss=0.144]\u001b[A\n",
      "Train step of epoch 0:   7%|â–‹         | 22/334 [00:04<01:02,  5.02it/s, loss=0.0688]\u001b[A\n",
      "Train step of epoch 0:   7%|â–‹         | 23/334 [00:04<01:01,  5.04it/s, loss=0.0688]\u001b[A\n",
      "Train step of epoch 0:   7%|â–‹         | 23/334 [00:05<01:01,  5.04it/s, loss=0.0247]\u001b[A\n",
      "Train step of epoch 0:   7%|â–‹         | 24/334 [00:05<01:01,  5.05it/s, loss=0.0247]\u001b[A\n",
      "Train step of epoch 0:   7%|â–‹         | 24/334 [00:05<01:01,  5.05it/s, loss=0.741] \u001b[A\n",
      "Train step of epoch 0:   7%|â–‹         | 25/334 [00:05<01:01,  5.04it/s, loss=0.741]\u001b[A\n",
      "Train step of epoch 0:   7%|â–‹         | 25/334 [00:05<01:01,  5.04it/s, loss=0.0151]\u001b[A\n",
      "Train step of epoch 0:   8%|â–Š         | 26/334 [00:05<01:01,  5.03it/s, loss=0.0151]\u001b[A\n",
      "Train step of epoch 0:   8%|â–Š         | 26/334 [00:05<01:01,  5.03it/s, loss=0.157] \u001b[A\n",
      "Train step of epoch 0:   8%|â–Š         | 27/334 [00:05<01:01,  5.03it/s, loss=0.157]\u001b[A\n",
      "Train step of epoch 0:   8%|â–Š         | 27/334 [00:05<01:01,  5.03it/s, loss=0.224]\u001b[A\n",
      "Train step of epoch 0:   8%|â–Š         | 28/334 [00:05<01:00,  5.02it/s, loss=0.224]\u001b[A\n",
      "Train step of epoch 0:   8%|â–Š         | 28/334 [00:06<01:00,  5.02it/s, loss=1.01] \u001b[A\n",
      "Train step of epoch 0:   9%|â–Š         | 29/334 [00:06<01:00,  5.02it/s, loss=1.01]\u001b[A\n",
      "Train step of epoch 0:   9%|â–Š         | 29/334 [00:06<01:00,  5.02it/s, loss=0.217]\u001b[A\n",
      "Train step of epoch 0:   9%|â–‰         | 30/334 [00:06<01:00,  5.02it/s, loss=0.217]\u001b[A\n",
      "Train step of epoch 0:   9%|â–‰         | 30/334 [00:06<01:00,  5.02it/s, loss=0.401]\u001b[A\n",
      "Train step of epoch 0:   9%|â–‰         | 31/334 [00:06<01:00,  5.02it/s, loss=0.401]\u001b[A\n",
      "Train step of epoch 0:   9%|â–‰         | 31/334 [00:06<01:00,  5.02it/s, loss=0.277]\u001b[A\n",
      "Train step of epoch 0:  10%|â–‰         | 32/334 [00:06<00:59,  5.03it/s, loss=0.277]\u001b[A\n",
      "Train step of epoch 0:  10%|â–‰         | 32/334 [00:06<00:59,  5.03it/s, loss=0.37] \u001b[A\n",
      "Train step of epoch 0:  10%|â–‰         | 33/334 [00:06<00:59,  5.03it/s, loss=0.37]\u001b[A\n",
      "Train step of epoch 0:  10%|â–‰         | 33/334 [00:07<00:59,  5.03it/s, loss=0.0771]\u001b[A\n",
      "Train step of epoch 0:  10%|â–ˆ         | 34/334 [00:07<00:59,  5.01it/s, loss=0.0771]\u001b[A\n",
      "Train step of epoch 0:  10%|â–ˆ         | 34/334 [00:07<00:59,  5.01it/s, loss=1.69]  \u001b[A\n",
      "Train step of epoch 0:  10%|â–ˆ         | 35/334 [00:07<00:59,  5.00it/s, loss=1.69]\u001b[A\n",
      "Train step of epoch 0:  10%|â–ˆ         | 35/334 [00:07<00:59,  5.00it/s, loss=0.0912]\u001b[A\n",
      "Train step of epoch 0:  11%|â–ˆ         | 36/334 [00:07<00:59,  5.01it/s, loss=0.0912]\u001b[A\n",
      "Train step of epoch 0:  11%|â–ˆ         | 36/334 [00:07<00:59,  5.01it/s, loss=0.361] \u001b[A\n",
      "Train step of epoch 0:  11%|â–ˆ         | 37/334 [00:07<00:59,  5.01it/s, loss=0.361]\u001b[A\n",
      "Train step of epoch 0:  11%|â–ˆ         | 37/334 [00:07<00:59,  5.01it/s, loss=0.298]\u001b[A\n",
      "Train step of epoch 0:  11%|â–ˆâ–        | 38/334 [00:07<00:59,  5.00it/s, loss=0.298]\u001b[A\n",
      "Train step of epoch 0:  11%|â–ˆâ–        | 38/334 [00:08<00:59,  5.00it/s, loss=0.183]\u001b[A\n",
      "Train step of epoch 0:  12%|â–ˆâ–        | 39/334 [00:08<00:58,  5.01it/s, loss=0.183]\u001b[A\n",
      "Train step of epoch 0:  12%|â–ˆâ–        | 39/334 [00:08<00:58,  5.01it/s, loss=0.463]\u001b[A\n",
      "Train step of epoch 0:  12%|â–ˆâ–        | 40/334 [00:08<00:58,  5.00it/s, loss=0.463]\u001b[A\n",
      "Train step of epoch 0:  12%|â–ˆâ–        | 40/334 [00:08<00:58,  5.00it/s, loss=0.481]\u001b[A\n",
      "Train step of epoch 0:  12%|â–ˆâ–        | 41/334 [00:08<00:58,  5.00it/s, loss=0.481]\u001b[A\n",
      "Train step of epoch 0:  12%|â–ˆâ–        | 41/334 [00:08<00:58,  5.00it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  13%|â–ˆâ–        | 42/334 [00:08<00:58,  5.01it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  13%|â–ˆâ–        | 42/334 [00:08<00:58,  5.01it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  13%|â–ˆâ–        | 43/334 [00:08<00:58,  5.02it/s, loss=0.526]\u001b[A\n",
      "Train step of epoch 0:  13%|â–ˆâ–        | 43/334 [00:09<00:58,  5.02it/s, loss=0.298]\u001b[A\n",
      "Train step of epoch 0:  13%|â–ˆâ–        | 44/334 [00:09<00:57,  5.02it/s, loss=0.298]\u001b[A\n",
      "Train step of epoch 0:  13%|â–ˆâ–        | 44/334 [00:09<00:57,  5.02it/s, loss=0.0426]\u001b[A\n",
      "Train step of epoch 0:  13%|â–ˆâ–        | 45/334 [00:09<00:57,  5.02it/s, loss=0.0426]\u001b[A\n",
      "Train step of epoch 0:  13%|â–ˆâ–        | 45/334 [00:09<00:57,  5.02it/s, loss=0.238] \u001b[A\n",
      "Train step of epoch 0:  14%|â–ˆâ–        | 46/334 [00:09<00:57,  5.01it/s, loss=0.238]\u001b[A\n",
      "Train step of epoch 0:  14%|â–ˆâ–        | 46/334 [00:09<00:57,  5.01it/s, loss=0.819]\u001b[A\n",
      "Train step of epoch 0:  14%|â–ˆâ–        | 47/334 [00:09<00:57,  5.00it/s, loss=0.819]\u001b[A\n",
      "Train step of epoch 0:  14%|â–ˆâ–        | 47/334 [00:09<00:57,  5.00it/s, loss=0.0182]\u001b[A\n",
      "Train step of epoch 0:  14%|â–ˆâ–        | 48/334 [00:09<00:57,  5.01it/s, loss=0.0182]\u001b[A\n",
      "Train step of epoch 0:  14%|â–ˆâ–        | 48/334 [00:09<00:57,  5.01it/s, loss=0.387] \u001b[A\n",
      "Train step of epoch 0:  15%|â–ˆâ–        | 49/334 [00:10<00:56,  5.03it/s, loss=0.387]\u001b[A\n",
      "Train step of epoch 0:  15%|â–ˆâ–        | 49/334 [00:10<00:56,  5.03it/s, loss=0.287]\u001b[A\n",
      "Train step of epoch 0:  15%|â–ˆâ–        | 50/334 [00:10<00:56,  5.03it/s, loss=0.287]\u001b[A\n",
      "Train step of epoch 0:  15%|â–ˆâ–        | 50/334 [00:10<00:56,  5.03it/s, loss=0.221]\u001b[A\n",
      "Train step of epoch 0:  15%|â–ˆâ–Œ        | 51/334 [00:10<00:56,  5.01it/s, loss=0.221]\u001b[A\n",
      "Train step of epoch 0:  15%|â–ˆâ–Œ        | 51/334 [00:10<00:56,  5.01it/s, loss=0.328]\u001b[A\n",
      "Train step of epoch 0:  16%|â–ˆâ–Œ        | 52/334 [00:10<00:56,  4.98it/s, loss=0.328]\u001b[A\n",
      "Train step of epoch 0:  16%|â–ˆâ–Œ        | 52/334 [00:10<00:56,  4.98it/s, loss=0.112]\u001b[A\n",
      "Train step of epoch 0:  16%|â–ˆâ–Œ        | 53/334 [00:10<00:56,  4.95it/s, loss=0.112]\u001b[A\n",
      "Train step of epoch 0:  16%|â–ˆâ–Œ        | 53/334 [00:11<00:56,  4.95it/s, loss=0.582]\u001b[A\n",
      "Train step of epoch 0:  16%|â–ˆâ–Œ        | 54/334 [00:11<00:56,  4.97it/s, loss=0.582]\u001b[A\n",
      "Train step of epoch 0:  16%|â–ˆâ–Œ        | 54/334 [00:11<00:56,  4.97it/s, loss=0.0111]\u001b[A\n",
      "Train step of epoch 0:  16%|â–ˆâ–‹        | 55/334 [00:11<00:56,  4.98it/s, loss=0.0111]\u001b[A\n",
      "Train step of epoch 0:  16%|â–ˆâ–‹        | 55/334 [00:11<00:56,  4.98it/s, loss=0.13]  \u001b[A\n",
      "Train step of epoch 0:  17%|â–ˆâ–‹        | 56/334 [00:11<00:55,  4.98it/s, loss=0.13]\u001b[A\n",
      "Train step of epoch 0:  17%|â–ˆâ–‹        | 56/334 [00:11<00:55,  4.98it/s, loss=0.00433]\u001b[A\n",
      "Train step of epoch 0:  17%|â–ˆâ–‹        | 57/334 [00:11<00:55,  5.00it/s, loss=0.00433]\u001b[A\n",
      "Train step of epoch 0:  17%|â–ˆâ–‹        | 57/334 [00:11<00:55,  5.00it/s, loss=0.0248] \u001b[A\n",
      "Train step of epoch 0:  17%|â–ˆâ–‹        | 58/334 [00:11<00:55,  5.01it/s, loss=0.0248]\u001b[A\n",
      "Train step of epoch 0:  17%|â–ˆâ–‹        | 58/334 [00:12<00:55,  5.01it/s, loss=0.0932]\u001b[A\n",
      "Train step of epoch 0:  18%|â–ˆâ–Š        | 59/334 [00:12<00:54,  5.04it/s, loss=0.0932]\u001b[A\n",
      "Train step of epoch 0:  18%|â–ˆâ–Š        | 59/334 [00:12<00:54,  5.04it/s, loss=0.103] \u001b[A\n",
      "Train step of epoch 0:  18%|â–ˆâ–Š        | 60/334 [00:12<00:54,  5.04it/s, loss=0.103]\u001b[A\n",
      "Train step of epoch 0:  18%|â–ˆâ–Š        | 60/334 [00:12<00:54,  5.04it/s, loss=0.225]\u001b[A\n",
      "Train step of epoch 0:  18%|â–ˆâ–Š        | 61/334 [00:12<00:54,  5.03it/s, loss=0.225]\u001b[A\n",
      "Train step of epoch 0:  18%|â–ˆâ–Š        | 61/334 [00:12<00:54,  5.03it/s, loss=0.000114]\u001b[A\n",
      "Train step of epoch 0:  19%|â–ˆâ–Š        | 62/334 [00:12<00:54,  5.01it/s, loss=0.000114]\u001b[A\n",
      "Train step of epoch 0:  19%|â–ˆâ–Š        | 62/334 [00:12<00:54,  5.01it/s, loss=0.0297]  \u001b[A\n",
      "Train step of epoch 0:  19%|â–ˆâ–‰        | 63/334 [00:12<00:53,  5.03it/s, loss=0.0297]\u001b[A\n",
      "Train step of epoch 0:  19%|â–ˆâ–‰        | 63/334 [00:12<00:53,  5.03it/s, loss=0.148] \u001b[A\n",
      "Train step of epoch 0:  19%|â–ˆâ–‰        | 64/334 [00:13<00:53,  5.03it/s, loss=0.148]\u001b[A\n",
      "Train step of epoch 0:  19%|â–ˆâ–‰        | 64/334 [00:13<00:53,  5.03it/s, loss=0.00768]\u001b[A\n",
      "Train step of epoch 0:  19%|â–ˆâ–‰        | 65/334 [00:13<00:52,  5.08it/s, loss=0.00768]\u001b[A\n",
      "Train step of epoch 0:  19%|â–ˆâ–‰        | 65/334 [00:13<00:52,  5.08it/s, loss=0.74]   \u001b[A\n",
      "Train step of epoch 0:  20%|â–ˆâ–‰        | 66/334 [00:13<00:52,  5.08it/s, loss=0.74]\u001b[A\n",
      "Train step of epoch 0:  20%|â–ˆâ–‰        | 66/334 [00:13<00:52,  5.08it/s, loss=0.305]\u001b[A\n",
      "Train step of epoch 0:  20%|â–ˆâ–ˆ        | 67/334 [00:13<00:52,  5.04it/s, loss=0.305]\u001b[A\n",
      "Train step of epoch 0:  20%|â–ˆâ–ˆ        | 67/334 [00:13<00:52,  5.04it/s, loss=0.366]\u001b[A\n",
      "Train step of epoch 0:  20%|â–ˆâ–ˆ        | 68/334 [00:13<00:52,  5.03it/s, loss=0.366]\u001b[A\n",
      "Train step of epoch 0:  20%|â–ˆâ–ˆ        | 68/334 [00:13<00:52,  5.03it/s, loss=0.000633]\u001b[A\n",
      "Train step of epoch 0:  21%|â–ˆâ–ˆ        | 69/334 [00:14<00:52,  5.06it/s, loss=0.000633]\u001b[A\n",
      "Train step of epoch 0:  21%|â–ˆâ–ˆ        | 69/334 [00:14<00:52,  5.06it/s, loss=0.0718]  \u001b[A\n",
      "Train step of epoch 0:  21%|â–ˆâ–ˆ        | 70/334 [00:14<00:52,  5.05it/s, loss=0.0718]\u001b[A\n",
      "Train step of epoch 0:  21%|â–ˆâ–ˆ        | 70/334 [00:14<00:52,  5.05it/s, loss=0.135] \u001b[A\n",
      "Train step of epoch 0:  21%|â–ˆâ–ˆâ–       | 71/334 [00:14<00:52,  5.05it/s, loss=0.135]\u001b[A\n",
      "Train step of epoch 0:  21%|â–ˆâ–ˆâ–       | 71/334 [00:14<00:52,  5.05it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  22%|â–ˆâ–ˆâ–       | 72/334 [00:14<00:51,  5.05it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  22%|â–ˆâ–ˆâ–       | 72/334 [00:14<00:51,  5.05it/s, loss=0.0702]\u001b[A\n",
      "Train step of epoch 0:  22%|â–ˆâ–ˆâ–       | 73/334 [00:14<00:52,  5.02it/s, loss=0.0702]\u001b[A\n",
      "Train step of epoch 0:  22%|â–ˆâ–ˆâ–       | 73/334 [00:14<00:52,  5.02it/s, loss=0.201] \u001b[A\n",
      "Train step of epoch 0:  22%|â–ˆâ–ˆâ–       | 74/334 [00:15<00:52,  4.99it/s, loss=0.201]\u001b[A\n",
      "Train step of epoch 0:  22%|â–ˆâ–ˆâ–       | 74/334 [00:15<00:52,  4.99it/s, loss=0.0897]\u001b[A\n",
      "Train step of epoch 0:  22%|â–ˆâ–ˆâ–       | 75/334 [00:15<00:51,  5.01it/s, loss=0.0897]\u001b[A\n",
      "Train step of epoch 0:  22%|â–ˆâ–ˆâ–       | 75/334 [00:15<00:51,  5.01it/s, loss=0.0348]\u001b[A\n",
      "Train step of epoch 0:  23%|â–ˆâ–ˆâ–       | 76/334 [00:15<00:51,  5.01it/s, loss=0.0348]\u001b[A\n",
      "Train step of epoch 0:  23%|â–ˆâ–ˆâ–       | 76/334 [00:15<00:51,  5.01it/s, loss=0.0165]\u001b[A\n",
      "Train step of epoch 0:  23%|â–ˆâ–ˆâ–       | 77/334 [00:15<00:51,  5.01it/s, loss=0.0165]\u001b[A\n",
      "Train step of epoch 0:  23%|â–ˆâ–ˆâ–       | 77/334 [00:15<00:51,  5.01it/s, loss=5.21e-6]\u001b[A\n",
      "Train step of epoch 0:  23%|â–ˆâ–ˆâ–       | 78/334 [00:15<00:51,  5.01it/s, loss=5.21e-6]\u001b[A\n",
      "Train step of epoch 0:  23%|â–ˆâ–ˆâ–       | 78/334 [00:15<00:51,  5.01it/s, loss=0.0349] \u001b[A\n",
      "Train step of epoch 0:  24%|â–ˆâ–ˆâ–       | 79/334 [00:16<00:51,  5.00it/s, loss=0.0349]\u001b[A\n",
      "Train step of epoch 0:  24%|â–ˆâ–ˆâ–       | 79/334 [00:16<00:51,  5.00it/s, loss=0.881] \u001b[A\n",
      "Train step of epoch 0:  24%|â–ˆâ–ˆâ–       | 80/334 [00:16<00:50,  5.02it/s, loss=0.881]\u001b[A\n",
      "Train step of epoch 0:  24%|â–ˆâ–ˆâ–       | 80/334 [00:16<00:50,  5.02it/s, loss=0.00128]\u001b[A\n",
      "Train step of epoch 0:  24%|â–ˆâ–ˆâ–       | 81/334 [00:16<00:50,  5.04it/s, loss=0.00128]\u001b[A\n",
      "Train step of epoch 0:  24%|â–ˆâ–ˆâ–       | 81/334 [00:16<00:50,  5.04it/s, loss=0.208]  \u001b[A\n",
      "Train step of epoch 0:  25%|â–ˆâ–ˆâ–       | 82/334 [00:16<00:50,  5.03it/s, loss=0.208]\u001b[A\n",
      "Train step of epoch 0:  25%|â–ˆâ–ˆâ–       | 82/334 [00:16<00:50,  5.03it/s, loss=0.162]\u001b[A\n",
      "Train step of epoch 0:  25%|â–ˆâ–ˆâ–       | 83/334 [00:16<00:49,  5.03it/s, loss=0.162]\u001b[A\n",
      "Train step of epoch 0:  25%|â–ˆâ–ˆâ–       | 83/334 [00:16<00:49,  5.03it/s, loss=0.323]\u001b[A\n",
      "Train step of epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 84/334 [00:17<00:49,  5.00it/s, loss=0.323]\u001b[A\n",
      "Train step of epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 84/334 [00:17<00:49,  5.00it/s, loss=0.0991]\u001b[A\n",
      "Train step of epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 85/334 [00:17<00:49,  5.00it/s, loss=0.0991]\u001b[A\n",
      "Train step of epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 85/334 [00:17<00:49,  5.00it/s, loss=0.39]  \u001b[A\n",
      "Train step of epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 86/334 [00:17<00:49,  5.00it/s, loss=0.39]\u001b[A\n",
      "Train step of epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 86/334 [00:17<00:49,  5.00it/s, loss=0.188]\u001b[A\n",
      "Train step of epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 87/334 [00:17<00:49,  4.99it/s, loss=0.188]\u001b[A\n",
      "Train step of epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 87/334 [00:17<00:49,  4.99it/s, loss=0.0646]\u001b[A\n",
      "Train step of epoch 0:  26%|â–ˆâ–ˆâ–‹       | 88/334 [00:17<00:49,  4.98it/s, loss=0.0646]\u001b[A\n",
      "Train step of epoch 0:  26%|â–ˆâ–ˆâ–‹       | 88/334 [00:17<00:49,  4.98it/s, loss=0.219] \u001b[A\n",
      "Train step of epoch 0:  27%|â–ˆâ–ˆâ–‹       | 89/334 [00:18<00:49,  4.96it/s, loss=0.219]\u001b[A\n",
      "Train step of epoch 0:  27%|â–ˆâ–ˆâ–‹       | 89/334 [00:18<00:49,  4.96it/s, loss=0.005]\u001b[A\n",
      "Train step of epoch 0:  27%|â–ˆâ–ˆâ–‹       | 90/334 [00:18<00:49,  4.96it/s, loss=0.005]\u001b[A\n",
      "Train step of epoch 0:  27%|â–ˆâ–ˆâ–‹       | 90/334 [00:18<00:49,  4.96it/s, loss=0.0396]\u001b[A\n",
      "Train step of epoch 0:  27%|â–ˆâ–ˆâ–‹       | 91/334 [00:18<00:48,  4.96it/s, loss=0.0396]\u001b[A\n",
      "Train step of epoch 0:  27%|â–ˆâ–ˆâ–‹       | 91/334 [00:18<00:48,  4.96it/s, loss=0.00175]\u001b[A\n",
      "Train step of epoch 0:  28%|â–ˆâ–ˆâ–Š       | 92/334 [00:18<00:48,  4.97it/s, loss=0.00175]\u001b[A\n",
      "Train step of epoch 0:  28%|â–ˆâ–ˆâ–Š       | 92/334 [00:18<00:48,  4.97it/s, loss=0.0156] \u001b[A\n",
      "Train step of epoch 0:  28%|â–ˆâ–ˆâ–Š       | 93/334 [00:18<00:48,  4.97it/s, loss=0.0156]\u001b[A\n",
      "Train step of epoch 0:  28%|â–ˆâ–ˆâ–Š       | 93/334 [00:18<00:48,  4.97it/s, loss=0.117] \u001b[A\n",
      "Train step of epoch 0:  28%|â–ˆâ–ˆâ–Š       | 94/334 [00:19<00:48,  4.97it/s, loss=0.117]\u001b[A\n",
      "Train step of epoch 0:  28%|â–ˆâ–ˆâ–Š       | 94/334 [00:19<00:48,  4.97it/s, loss=0.0088]\u001b[A\n",
      "Train step of epoch 0:  28%|â–ˆâ–ˆâ–Š       | 95/334 [00:19<00:47,  4.98it/s, loss=0.0088]\u001b[A\n",
      "Train step of epoch 0:  28%|â–ˆâ–ˆâ–Š       | 95/334 [00:19<00:47,  4.98it/s, loss=0.0458]\u001b[A\n",
      "Train step of epoch 0:  29%|â–ˆâ–ˆâ–Š       | 96/334 [00:19<00:47,  4.99it/s, loss=0.0458]\u001b[A\n",
      "Train step of epoch 0:  29%|â–ˆâ–ˆâ–Š       | 96/334 [00:19<00:47,  4.99it/s, loss=0.000682]\u001b[A\n",
      "Train step of epoch 0:  29%|â–ˆâ–ˆâ–‰       | 97/334 [00:19<00:47,  4.99it/s, loss=0.000682]\u001b[A\n",
      "Train step of epoch 0:  29%|â–ˆâ–ˆâ–‰       | 97/334 [00:19<00:47,  4.99it/s, loss=0.0025]  \u001b[A\n",
      "Train step of epoch 0:  29%|â–ˆâ–ˆâ–‰       | 98/334 [00:19<00:47,  5.00it/s, loss=0.0025]\u001b[A\n",
      "Train step of epoch 0:  29%|â–ˆâ–ˆâ–‰       | 98/334 [00:19<00:47,  5.00it/s, loss=0.000158]\u001b[A\n",
      "Train step of epoch 0:  30%|â–ˆâ–ˆâ–‰       | 99/334 [00:20<00:47,  4.99it/s, loss=0.000158]\u001b[A\n",
      "Train step of epoch 0:  30%|â–ˆâ–ˆâ–‰       | 99/334 [00:20<00:47,  4.99it/s, loss=0.241]   \u001b[A\n",
      "Train step of epoch 0:  30%|â–ˆâ–ˆâ–‰       | 100/334 [00:20<00:46,  4.99it/s, loss=0.241]\u001b[A\n",
      "Train step of epoch 0:  30%|â–ˆâ–ˆâ–‰       | 100/334 [00:20<00:46,  4.99it/s, loss=0.263]\u001b[A\n",
      "Train step of epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 101/334 [00:20<00:47,  4.95it/s, loss=0.263]\u001b[A\n",
      "Train step of epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 101/334 [00:20<00:47,  4.95it/s, loss=0.297]\u001b[A\n",
      "Train step of epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 102/334 [00:20<00:46,  4.97it/s, loss=0.297]\u001b[A\n",
      "Train step of epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 102/334 [00:20<00:46,  4.97it/s, loss=1.28] \u001b[A\n",
      "Train step of epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 103/334 [00:20<00:46,  4.98it/s, loss=1.28]\u001b[A\n",
      "Train step of epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 103/334 [00:20<00:46,  4.98it/s, loss=0.14]\u001b[A\n",
      "Train step of epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 104/334 [00:21<00:46,  4.97it/s, loss=0.14]\u001b[A\n",
      "Train step of epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 104/334 [00:21<00:46,  4.97it/s, loss=0.151]\u001b[A\n",
      "Train step of epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 105/334 [00:21<00:46,  4.97it/s, loss=0.151]\u001b[A\n",
      "Train step of epoch 0:  31%|â–ˆâ–ˆâ–ˆâ–      | 105/334 [00:21<00:46,  4.97it/s, loss=0.00486]\u001b[A\n",
      "Train step of epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 106/334 [00:21<00:45,  4.98it/s, loss=0.00486]\u001b[A\n",
      "Train step of epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 106/334 [00:21<00:45,  4.98it/s, loss=0.622]  \u001b[A\n",
      "Train step of epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 107/334 [00:21<00:45,  4.97it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 107/334 [00:21<00:45,  4.97it/s, loss=0.0476]\u001b[A\n",
      "Train step of epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 108/334 [00:21<00:45,  4.97it/s, loss=0.0476]\u001b[A\n",
      "Train step of epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 108/334 [00:21<00:45,  4.97it/s, loss=0.231] \u001b[A\n",
      "Train step of epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 109/334 [00:22<00:45,  4.98it/s, loss=0.231]\u001b[A\n",
      "Train step of epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 109/334 [00:22<00:45,  4.98it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 110/334 [00:22<00:44,  4.98it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 110/334 [00:22<00:44,  4.98it/s, loss=0.208]\u001b[A\n",
      "Train step of epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 111/334 [00:22<00:44,  4.99it/s, loss=0.208]\u001b[A\n",
      "Train step of epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 111/334 [00:22<00:44,  4.99it/s, loss=0.103]\u001b[A\n",
      "Train step of epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 112/334 [00:22<00:44,  4.97it/s, loss=0.103]\u001b[A\n",
      "Train step of epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 112/334 [00:22<00:44,  4.97it/s, loss=0.435]\u001b[A\n",
      "Train step of epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 113/334 [00:22<00:44,  4.97it/s, loss=0.435]\u001b[A\n",
      "Train step of epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 113/334 [00:23<00:44,  4.97it/s, loss=0.255]\u001b[A\n",
      "Train step of epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 114/334 [00:23<00:44,  4.97it/s, loss=0.255]\u001b[A\n",
      "Train step of epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 114/334 [00:23<00:44,  4.97it/s, loss=0.15] \u001b[A\n",
      "Train step of epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 115/334 [00:23<00:44,  4.96it/s, loss=0.15]\u001b[A\n",
      "Train step of epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 115/334 [00:23<00:44,  4.96it/s, loss=0.00484]\u001b[A\n",
      "Train step of epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 116/334 [00:23<00:43,  4.97it/s, loss=0.00484]\u001b[A\n",
      "Train step of epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 116/334 [00:23<00:43,  4.97it/s, loss=0.0554] \u001b[A\n",
      "Train step of epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 117/334 [00:23<00:43,  4.97it/s, loss=0.0554]\u001b[A\n",
      "Train step of epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 117/334 [00:23<00:43,  4.97it/s, loss=0.625] \u001b[A\n",
      "Train step of epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 118/334 [00:23<00:43,  4.98it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 118/334 [00:24<00:43,  4.98it/s, loss=0.693]\u001b[A\n",
      "Train step of epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 119/334 [00:24<00:43,  4.98it/s, loss=0.693]\u001b[A\n",
      "Train step of epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 119/334 [00:24<00:43,  4.98it/s, loss=0.0856]\u001b[A\n",
      "Train step of epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 120/334 [00:24<00:42,  4.98it/s, loss=0.0856]\u001b[A\n",
      "Train step of epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 120/334 [00:24<00:42,  4.98it/s, loss=0.993] \u001b[A\n",
      "Train step of epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 121/334 [00:24<00:42,  4.98it/s, loss=0.993]\u001b[A\n",
      "Train step of epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 121/334 [00:24<00:42,  4.98it/s, loss=0.298]\u001b[A\n",
      "Train step of epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 122/334 [00:24<00:42,  4.96it/s, loss=0.298]\u001b[A\n",
      "Train step of epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 122/334 [00:24<00:42,  4.96it/s, loss=0.095]\u001b[A\n",
      "Train step of epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 123/334 [00:24<00:42,  4.97it/s, loss=0.095]\u001b[A\n",
      "Train step of epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 123/334 [00:25<00:42,  4.97it/s, loss=0.17] \u001b[A\n",
      "Train step of epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 124/334 [00:25<00:42,  4.96it/s, loss=0.17]\u001b[A\n",
      "Train step of epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 124/334 [00:25<00:42,  4.96it/s, loss=0.235]\u001b[A\n",
      "Train step of epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 125/334 [00:25<00:42,  4.97it/s, loss=0.235]\u001b[A\n",
      "Train step of epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 125/334 [00:25<00:42,  4.97it/s, loss=0.00575]\u001b[A\n",
      "Train step of epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 126/334 [00:25<00:41,  4.98it/s, loss=0.00575]\u001b[A\n",
      "Train step of epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 126/334 [00:25<00:41,  4.98it/s, loss=0.0387] \u001b[A\n",
      "Train step of epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 127/334 [00:25<00:41,  4.98it/s, loss=0.0387]\u001b[A\n",
      "Train step of epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 127/334 [00:25<00:41,  4.98it/s, loss=0.46]  \u001b[A\n",
      "Train step of epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 128/334 [00:25<00:41,  4.98it/s, loss=0.46]\u001b[A\n",
      "Train step of epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 128/334 [00:26<00:41,  4.98it/s, loss=2.59e-5]\u001b[A\n",
      "Train step of epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 129/334 [00:26<00:41,  4.97it/s, loss=2.59e-5]\u001b[A\n",
      "Train step of epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 129/334 [00:26<00:41,  4.97it/s, loss=0.167]  \u001b[A\n",
      "Train step of epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 130/334 [00:26<00:41,  4.96it/s, loss=0.167]\u001b[A\n",
      "Train step of epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 130/334 [00:26<00:41,  4.96it/s, loss=0.0014]\u001b[A\n",
      "Train step of epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 131/334 [00:26<00:40,  4.95it/s, loss=0.0014]\u001b[A\n",
      "Train step of epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 131/334 [00:26<00:40,  4.95it/s, loss=0.0345]\u001b[A\n",
      "Train step of epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 132/334 [00:26<00:40,  4.95it/s, loss=0.0345]\u001b[A\n",
      "Train step of epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 132/334 [00:26<00:40,  4.95it/s, loss=0.00332]\u001b[A\n",
      "Train step of epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 133/334 [00:27<00:40,  4.94it/s, loss=0.00332]\u001b[A\n",
      "Train step of epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 133/334 [00:27<00:40,  4.94it/s, loss=0.151]  \u001b[A\n",
      "Train step of epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 134/334 [00:27<00:40,  4.94it/s, loss=0.151]\u001b[A\n",
      "Train step of epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 134/334 [00:27<00:40,  4.94it/s, loss=0.0931]\u001b[A\n",
      "Train step of epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 135/334 [00:27<00:40,  4.96it/s, loss=0.0931]\u001b[A\n",
      "Train step of epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 135/334 [00:27<00:40,  4.96it/s, loss=1.16]  \u001b[A\n",
      "Train step of epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 136/334 [00:27<00:39,  4.97it/s, loss=1.16]\u001b[A\n",
      "Train step of epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 136/334 [00:27<00:39,  4.97it/s, loss=0.0172]\u001b[A\n",
      "Train step of epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 137/334 [00:27<00:39,  4.97it/s, loss=0.0172]\u001b[A\n",
      "Train step of epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 137/334 [00:27<00:39,  4.97it/s, loss=0.0267]\u001b[A\n",
      "Train step of epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 138/334 [00:28<00:39,  4.95it/s, loss=0.0267]\u001b[A\n",
      "Train step of epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 138/334 [00:28<00:39,  4.95it/s, loss=0.402] \u001b[A\n",
      "Train step of epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 139/334 [00:28<00:39,  4.96it/s, loss=0.402]\u001b[A\n",
      "Train step of epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 139/334 [00:28<00:39,  4.96it/s, loss=0.56] \u001b[A\n",
      "Train step of epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 140/334 [00:28<00:39,  4.96it/s, loss=0.56]\u001b[A\n",
      "Train step of epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 140/334 [00:28<00:39,  4.96it/s, loss=0.285]\u001b[A\n",
      "Train step of epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 141/334 [00:28<00:38,  4.96it/s, loss=0.285]\u001b[A\n",
      "Train step of epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 141/334 [00:28<00:38,  4.96it/s, loss=0.0286]\u001b[A\n",
      "Train step of epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 142/334 [00:28<00:38,  4.96it/s, loss=0.0286]\u001b[A\n",
      "Train step of epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 142/334 [00:28<00:38,  4.96it/s, loss=0.581] \u001b[A\n",
      "Train step of epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 143/334 [00:29<00:38,  4.96it/s, loss=0.581]\u001b[A\n",
      "Train step of epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 143/334 [00:29<00:38,  4.96it/s, loss=0.148]\u001b[A\n",
      "Train step of epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 144/334 [00:29<00:37,  5.01it/s, loss=0.148]\u001b[A\n",
      "Train step of epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 144/334 [00:29<00:37,  5.01it/s, loss=0.0291]\u001b[A\n",
      "Train step of epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 145/334 [00:29<00:38,  4.96it/s, loss=0.0291]\u001b[A\n",
      "Train step of epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 145/334 [00:29<00:38,  4.96it/s, loss=0.169] \u001b[A\n",
      "Train step of epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 146/334 [00:29<00:37,  4.95it/s, loss=0.169]\u001b[A\n",
      "Train step of epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 146/334 [00:29<00:37,  4.95it/s, loss=0.126]\u001b[A\n",
      "Train step of epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 147/334 [00:29<00:37,  4.95it/s, loss=0.126]\u001b[A\n",
      "Train step of epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 147/334 [00:29<00:37,  4.95it/s, loss=0.104]\u001b[A\n",
      "Train step of epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 148/334 [00:30<00:37,  4.95it/s, loss=0.104]\u001b[A\n",
      "Train step of epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 148/334 [00:30<00:37,  4.95it/s, loss=0.0752]\u001b[A\n",
      "Train step of epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 149/334 [00:30<00:37,  4.96it/s, loss=0.0752]\u001b[A\n",
      "Train step of epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 149/334 [00:30<00:37,  4.96it/s, loss=0.277] \u001b[A\n",
      "Train step of epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 150/334 [00:30<00:37,  4.97it/s, loss=0.277]\u001b[A\n",
      "Train step of epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 150/334 [00:30<00:37,  4.97it/s, loss=0.184]\u001b[A\n",
      "Train step of epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 151/334 [00:30<00:36,  5.00it/s, loss=0.184]\u001b[A\n",
      "Train step of epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 151/334 [00:30<00:36,  5.00it/s, loss=0.895]\u001b[A\n",
      "Train step of epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 152/334 [00:30<00:36,  4.97it/s, loss=0.895]\u001b[A\n",
      "Train step of epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 152/334 [00:30<00:36,  4.97it/s, loss=0.012]\u001b[A\n",
      "Train step of epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 153/334 [00:31<00:36,  4.96it/s, loss=0.012]\u001b[A\n",
      "Train step of epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 153/334 [00:31<00:36,  4.96it/s, loss=0.127]\u001b[A\n",
      "Train step of epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 154/334 [00:31<00:36,  4.96it/s, loss=0.127]\u001b[A\n",
      "Train step of epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 154/334 [00:31<00:36,  4.96it/s, loss=0.529]\u001b[A\n",
      "Train step of epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 155/334 [00:31<00:36,  4.96it/s, loss=0.529]\u001b[A\n",
      "Train step of epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 155/334 [00:31<00:36,  4.96it/s, loss=0.225]\u001b[A\n",
      "Train step of epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 156/334 [00:31<00:35,  4.95it/s, loss=0.225]\u001b[A\n",
      "Train step of epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 156/334 [00:31<00:35,  4.95it/s, loss=0.297]\u001b[A\n",
      "Train step of epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 157/334 [00:31<00:35,  4.94it/s, loss=0.297]\u001b[A\n",
      "Train step of epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 157/334 [00:31<00:35,  4.94it/s, loss=0.153]\u001b[A\n",
      "Train step of epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 158/334 [00:32<00:35,  4.93it/s, loss=0.153]\u001b[A\n",
      "Train step of epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 158/334 [00:32<00:35,  4.93it/s, loss=0.178]\u001b[A\n",
      "Train step of epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 159/334 [00:32<00:35,  4.93it/s, loss=0.178]\u001b[A\n",
      "Train step of epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 159/334 [00:32<00:35,  4.93it/s, loss=0.00121]\u001b[A\n",
      "Train step of epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 160/334 [00:32<00:35,  4.92it/s, loss=0.00121]\u001b[A\n",
      "Train step of epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 160/334 [00:32<00:35,  4.92it/s, loss=0.0217] \u001b[A\n",
      "Train step of epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 161/334 [00:32<00:35,  4.94it/s, loss=0.0217]\u001b[A\n",
      "Train step of epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 161/334 [00:32<00:35,  4.94it/s, loss=0.431] \u001b[A\n",
      "Train step of epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 162/334 [00:32<00:34,  4.94it/s, loss=0.431]\u001b[A\n",
      "Train step of epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 162/334 [00:32<00:34,  4.94it/s, loss=0.00235]\u001b[A\n",
      "Train step of epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 163/334 [00:33<00:34,  4.94it/s, loss=0.00235]\u001b[A\n",
      "Train step of epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 163/334 [00:33<00:34,  4.94it/s, loss=0.0437] \u001b[A\n",
      "Train step of epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 164/334 [00:33<00:34,  4.94it/s, loss=0.0437]\u001b[A\n",
      "Train step of epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 164/334 [00:33<00:34,  4.94it/s, loss=0.246] \u001b[A\n",
      "Train step of epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 165/334 [00:33<00:34,  4.94it/s, loss=0.246]\u001b[A\n",
      "Train step of epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 165/334 [00:33<00:34,  4.94it/s, loss=0.126]\u001b[A\n",
      "Train step of epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 166/334 [00:33<00:33,  4.95it/s, loss=0.126]\u001b[A\n",
      "Train step of epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 166/334 [00:33<00:33,  4.95it/s, loss=0.223]\u001b[A\n",
      "Train step of epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 167/334 [00:33<00:33,  4.96it/s, loss=0.223]\u001b[A\n",
      "Train step of epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 167/334 [00:33<00:33,  4.96it/s, loss=0.00187]\u001b[A\n",
      "Train step of epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 168/334 [00:34<00:33,  4.95it/s, loss=0.00187]\u001b[A\n",
      "Train step of epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 168/334 [00:34<00:33,  4.95it/s, loss=0.00359]\u001b[A\n",
      "Train step of epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 169/334 [00:34<00:33,  4.94it/s, loss=0.00359]\u001b[A\n",
      "Train step of epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 169/334 [00:34<00:33,  4.94it/s, loss=0.442]  \u001b[A\n",
      "Train step of epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 170/334 [00:34<00:33,  4.94it/s, loss=0.442]\u001b[A\n",
      "Train step of epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 170/334 [00:34<00:33,  4.94it/s, loss=2.08] \u001b[A\n",
      "Train step of epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 171/334 [00:34<00:33,  4.93it/s, loss=2.08]\u001b[A\n",
      "Train step of epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 171/334 [00:34<00:33,  4.93it/s, loss=0.0139]\u001b[A\n",
      "Train step of epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 172/334 [00:34<00:32,  4.93it/s, loss=0.0139]\u001b[A\n",
      "Train step of epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 172/334 [00:34<00:32,  4.93it/s, loss=0.00113]\u001b[A\n",
      "Train step of epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 173/334 [00:35<00:32,  4.93it/s, loss=0.00113]\u001b[A\n",
      "Train step of epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 173/334 [00:35<00:32,  4.93it/s, loss=0.148]  \u001b[A\n",
      "Train step of epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 174/334 [00:35<00:32,  4.93it/s, loss=0.148]\u001b[A\n",
      "Train step of epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 174/334 [00:35<00:32,  4.93it/s, loss=0.00808]\u001b[A\n",
      "Train step of epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 175/334 [00:35<00:32,  4.93it/s, loss=0.00808]\u001b[A\n",
      "Train step of epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 175/334 [00:35<00:32,  4.93it/s, loss=0.233]  \u001b[A\n",
      "Train step of epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 176/334 [00:35<00:31,  4.95it/s, loss=0.233]\u001b[A\n",
      "Train step of epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 176/334 [00:35<00:31,  4.95it/s, loss=0.0414]\u001b[A\n",
      "Train step of epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 177/334 [00:35<00:31,  4.95it/s, loss=0.0414]\u001b[A\n",
      "Train step of epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 177/334 [00:35<00:31,  4.95it/s, loss=0.094] \u001b[A\n",
      "Train step of epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 178/334 [00:36<00:31,  4.94it/s, loss=0.094]\u001b[A\n",
      "Train step of epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 178/334 [00:36<00:31,  4.94it/s, loss=0.341]\u001b[A\n",
      "Train step of epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 179/334 [00:36<00:31,  4.96it/s, loss=0.341]\u001b[A\n",
      "Train step of epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 179/334 [00:36<00:31,  4.96it/s, loss=0.265]\u001b[A\n",
      "Train step of epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 180/334 [00:36<00:31,  4.94it/s, loss=0.265]\u001b[A\n",
      "Train step of epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 180/334 [00:36<00:31,  4.94it/s, loss=0.562]\u001b[A\n",
      "Train step of epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 181/334 [00:36<00:30,  4.95it/s, loss=0.562]\u001b[A\n",
      "Train step of epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 181/334 [00:36<00:30,  4.95it/s, loss=0.611]\u001b[A\n",
      "Train step of epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 182/334 [00:36<00:30,  4.95it/s, loss=0.611]\u001b[A\n",
      "Train step of epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 182/334 [00:36<00:30,  4.95it/s, loss=0.086]\u001b[A\n",
      "Train step of epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 183/334 [00:37<00:30,  4.94it/s, loss=0.086]\u001b[A\n",
      "Train step of epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 183/334 [00:37<00:30,  4.94it/s, loss=0.116]\u001b[A\n",
      "Train step of epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 184/334 [00:37<00:30,  4.94it/s, loss=0.116]\u001b[A\n",
      "Train step of epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 184/334 [00:37<00:30,  4.94it/s, loss=0.228]\u001b[A\n",
      "Train step of epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 185/334 [00:37<00:30,  4.95it/s, loss=0.228]\u001b[A\n",
      "Train step of epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 185/334 [00:37<00:30,  4.95it/s, loss=0.0922]\u001b[A\n",
      "Train step of epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 186/334 [00:37<00:30,  4.93it/s, loss=0.0922]\u001b[A\n",
      "Train step of epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 186/334 [00:37<00:30,  4.93it/s, loss=0.171] \u001b[A\n",
      "Train step of epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 187/334 [00:37<00:29,  4.92it/s, loss=0.171]\u001b[A\n",
      "Train step of epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 187/334 [00:37<00:29,  4.92it/s, loss=0.342]\u001b[A\n",
      "Train step of epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 188/334 [00:38<00:29,  4.91it/s, loss=0.342]\u001b[A\n",
      "Train step of epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 188/334 [00:38<00:29,  4.91it/s, loss=0.15] \u001b[A\n",
      "Train step of epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 189/334 [00:38<00:29,  4.92it/s, loss=0.15]\u001b[A\n",
      "Train step of epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 189/334 [00:38<00:29,  4.92it/s, loss=0.248]\u001b[A\n",
      "Train step of epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 190/334 [00:38<00:29,  4.93it/s, loss=0.248]\u001b[A\n",
      "Train step of epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 190/334 [00:38<00:29,  4.93it/s, loss=0.606]\u001b[A\n",
      "Train step of epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 191/334 [00:38<00:28,  4.94it/s, loss=0.606]\u001b[A\n",
      "Train step of epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 191/334 [00:38<00:28,  4.94it/s, loss=0.0189]\u001b[A\n",
      "Train step of epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 192/334 [00:38<00:28,  4.94it/s, loss=0.0189]\u001b[A\n",
      "Train step of epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 192/334 [00:38<00:28,  4.94it/s, loss=0.000332]\u001b[A\n",
      "Train step of epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 193/334 [00:39<00:28,  4.93it/s, loss=0.000332]\u001b[A\n",
      "Train step of epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 193/334 [00:39<00:28,  4.93it/s, loss=0.0045]  \u001b[A\n",
      "Train step of epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 194/334 [00:39<00:28,  4.94it/s, loss=0.0045]\u001b[A\n",
      "Train step of epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 194/334 [00:39<00:28,  4.94it/s, loss=0.307] \u001b[A\n",
      "Train step of epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 195/334 [00:39<00:28,  4.95it/s, loss=0.307]\u001b[A\n",
      "Train step of epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 195/334 [00:39<00:28,  4.95it/s, loss=0.264]\u001b[A\n",
      "Train step of epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 196/334 [00:39<00:27,  4.95it/s, loss=0.264]\u001b[A\n",
      "Train step of epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 196/334 [00:39<00:27,  4.95it/s, loss=0.242]\u001b[A\n",
      "Train step of epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 197/334 [00:39<00:27,  4.94it/s, loss=0.242]\u001b[A\n",
      "Train step of epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 197/334 [00:39<00:27,  4.94it/s, loss=0.0275]\u001b[A\n",
      "Train step of epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 198/334 [00:40<00:27,  4.93it/s, loss=0.0275]\u001b[A\n",
      "Train step of epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 198/334 [00:40<00:27,  4.93it/s, loss=0.466] \u001b[A\n",
      "Train step of epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 199/334 [00:40<00:27,  4.93it/s, loss=0.466]\u001b[A\n",
      "Train step of epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 199/334 [00:40<00:27,  4.93it/s, loss=0.0266]\u001b[A\n",
      "Train step of epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 200/334 [00:40<00:27,  4.93it/s, loss=0.0266]\u001b[A\n",
      "Train step of epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 200/334 [00:40<00:27,  4.93it/s, loss=0.14]  \u001b[A\n",
      "Train step of epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 201/334 [00:40<00:26,  4.95it/s, loss=0.14]\u001b[A\n",
      "Train step of epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 201/334 [00:40<00:26,  4.95it/s, loss=0.262]\u001b[A\n",
      "Train step of epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 202/334 [00:40<00:26,  4.93it/s, loss=0.262]\u001b[A\n",
      "Train step of epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 202/334 [00:40<00:26,  4.93it/s, loss=0.00612]\u001b[A\n",
      "Train step of epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 203/334 [00:41<00:26,  4.94it/s, loss=0.00612]\u001b[A\n",
      "Train step of epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 203/334 [00:41<00:26,  4.94it/s, loss=0.0991] \u001b[A\n",
      "Train step of epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 204/334 [00:41<00:26,  4.95it/s, loss=0.0991]\u001b[A\n",
      "Train step of epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 204/334 [00:41<00:26,  4.95it/s, loss=0.0165]\u001b[A\n",
      "Train step of epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 205/334 [00:41<00:25,  4.97it/s, loss=0.0165]\u001b[A\n",
      "Train step of epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 205/334 [00:41<00:25,  4.97it/s, loss=1.15e-6]\u001b[A\n",
      "Train step of epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 206/334 [00:41<00:25,  4.95it/s, loss=1.15e-6]\u001b[A\n",
      "Train step of epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 206/334 [00:41<00:25,  4.95it/s, loss=0.0653] \u001b[A\n",
      "Train step of epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 207/334 [00:41<00:25,  4.94it/s, loss=0.0653]\u001b[A\n",
      "Train step of epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 207/334 [00:41<00:25,  4.94it/s, loss=1.02]  \u001b[A\n",
      "Train step of epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 208/334 [00:42<00:25,  4.94it/s, loss=1.02]\u001b[A\n",
      "Train step of epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 208/334 [00:42<00:25,  4.94it/s, loss=0.0243]\u001b[A\n",
      "Train step of epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 209/334 [00:42<00:25,  4.95it/s, loss=0.0243]\u001b[A\n",
      "Train step of epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 209/334 [00:42<00:25,  4.95it/s, loss=0.000211]\u001b[A\n",
      "Train step of epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 210/334 [00:42<00:25,  4.94it/s, loss=0.000211]\u001b[A\n",
      "Train step of epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 210/334 [00:42<00:25,  4.94it/s, loss=0.275]   \u001b[A\n",
      "Train step of epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 211/334 [00:42<00:24,  4.95it/s, loss=0.275]\u001b[A\n",
      "Train step of epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 211/334 [00:42<00:24,  4.95it/s, loss=0.00309]\u001b[A\n",
      "Train step of epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 212/334 [00:42<00:24,  4.95it/s, loss=0.00309]\u001b[A\n",
      "Train step of epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 212/334 [00:42<00:24,  4.95it/s, loss=0.0453] \u001b[A\n",
      "Train step of epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 213/334 [00:43<00:24,  4.94it/s, loss=0.0453]\u001b[A\n",
      "Train step of epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 213/334 [00:43<00:24,  4.94it/s, loss=0.00797]\u001b[A\n",
      "Train step of epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 214/334 [00:43<00:24,  4.95it/s, loss=0.00797]\u001b[A\n",
      "Train step of epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 214/334 [00:43<00:24,  4.95it/s, loss=0.101]  \u001b[A\n",
      "Train step of epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 215/334 [00:43<00:24,  4.94it/s, loss=0.101]\u001b[A\n",
      "Train step of epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 215/334 [00:43<00:24,  4.94it/s, loss=0.000645]\u001b[A\n",
      "Train step of epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 216/334 [00:43<00:23,  4.99it/s, loss=0.000645]\u001b[A\n",
      "Train step of epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 216/334 [00:43<00:23,  4.99it/s, loss=7.83e-6] \u001b[A\n",
      "Train step of epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 217/334 [00:43<00:23,  4.96it/s, loss=7.83e-6]\u001b[A\n",
      "Train step of epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 217/334 [00:44<00:23,  4.96it/s, loss=0.0409] \u001b[A\n",
      "Train step of epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 218/334 [00:44<00:23,  4.97it/s, loss=0.0409]\u001b[A\n",
      "Train step of epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 218/334 [00:44<00:23,  4.97it/s, loss=5.13e-6]\u001b[A\n",
      "Train step of epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 219/334 [00:44<00:23,  4.95it/s, loss=5.13e-6]\u001b[A\n",
      "Train step of epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 219/334 [00:44<00:23,  4.95it/s, loss=0.000684]\u001b[A\n",
      "Train step of epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 220/334 [00:44<00:23,  4.93it/s, loss=0.000684]\u001b[A\n",
      "Train step of epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 220/334 [00:44<00:23,  4.93it/s, loss=0.531]   \u001b[A\n",
      "Train step of epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 221/334 [00:44<00:23,  4.91it/s, loss=0.531]\u001b[A\n",
      "Train step of epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 221/334 [00:44<00:23,  4.91it/s, loss=0.0146]\u001b[A\n",
      "Train step of epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 222/334 [00:45<00:22,  4.91it/s, loss=0.0146]\u001b[A\n",
      "Train step of epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 222/334 [00:45<00:22,  4.91it/s, loss=0.0141]\u001b[A\n",
      "Train step of epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 223/334 [00:45<00:22,  4.93it/s, loss=0.0141]\u001b[A\n",
      "Train step of epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 223/334 [00:45<00:22,  4.93it/s, loss=7.51e-5]\u001b[A\n",
      "Train step of epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 224/334 [00:45<00:22,  4.95it/s, loss=7.51e-5]\u001b[A\n",
      "Train step of epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 224/334 [00:45<00:22,  4.95it/s, loss=1.99e-7]\u001b[A\n",
      "Train step of epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 225/334 [00:45<00:21,  4.95it/s, loss=1.99e-7]\u001b[A\n",
      "Train step of epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 225/334 [00:45<00:21,  4.95it/s, loss=0.022]  \u001b[A\n",
      "Train step of epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 226/334 [00:45<00:21,  4.93it/s, loss=0.022]\u001b[A\n",
      "Train step of epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 226/334 [00:45<00:21,  4.93it/s, loss=0.000299]\u001b[A\n",
      "Train step of epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 227/334 [00:46<00:21,  4.92it/s, loss=0.000299]\u001b[A\n",
      "Train step of epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 227/334 [00:46<00:21,  4.92it/s, loss=0.0358]  \u001b[A\n",
      "Train step of epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 228/334 [00:46<00:21,  4.92it/s, loss=0.0358]\u001b[A\n",
      "Train step of epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 228/334 [00:46<00:21,  4.92it/s, loss=0.543] \u001b[A\n",
      "Train step of epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 229/334 [00:46<00:21,  4.90it/s, loss=0.543]\u001b[A\n",
      "Train step of epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 229/334 [00:46<00:21,  4.90it/s, loss=0.00011]\u001b[A\n",
      "Train step of epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 230/334 [00:46<00:21,  4.93it/s, loss=0.00011]\u001b[A\n",
      "Train step of epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 230/334 [00:46<00:21,  4.93it/s, loss=0.0079] \u001b[A\n",
      "Train step of epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 231/334 [00:46<00:21,  4.90it/s, loss=0.0079]\u001b[A\n",
      "Train step of epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 231/334 [00:46<00:21,  4.90it/s, loss=0.00115]\u001b[A\n",
      "Train step of epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 232/334 [00:47<00:20,  4.92it/s, loss=0.00115]\u001b[A\n",
      "Train step of epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 232/334 [00:47<00:20,  4.92it/s, loss=0.29]   \u001b[A\n",
      "Train step of epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 233/334 [00:47<00:20,  4.94it/s, loss=0.29]\u001b[A\n",
      "Train step of epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 233/334 [00:47<00:20,  4.94it/s, loss=0.0196]\u001b[A\n",
      "Train step of epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 234/334 [00:47<00:20,  4.94it/s, loss=0.0196]\u001b[A\n",
      "Train step of epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 234/334 [00:47<00:20,  4.94it/s, loss=0.505] \u001b[A\n",
      "Train step of epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 235/334 [00:47<00:20,  4.93it/s, loss=0.505]\u001b[A\n",
      "Train step of epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 235/334 [00:47<00:20,  4.93it/s, loss=0.000536]\u001b[A\n",
      "Train step of epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 236/334 [00:47<00:19,  4.90it/s, loss=0.000536]\u001b[A\n",
      "Train step of epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 236/334 [00:47<00:19,  4.90it/s, loss=0.000313]\u001b[A\n",
      "Train step of epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 237/334 [00:48<00:19,  4.91it/s, loss=0.000313]\u001b[A\n",
      "Train step of epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 237/334 [00:48<00:19,  4.91it/s, loss=0.039]   \u001b[A\n",
      "Train step of epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 238/334 [00:48<00:19,  4.90it/s, loss=0.039]\u001b[A\n",
      "Train step of epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 238/334 [00:48<00:19,  4.90it/s, loss=0.115]\u001b[A\n",
      "Train step of epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 239/334 [00:48<00:19,  4.92it/s, loss=0.115]\u001b[A\n",
      "Train step of epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 239/334 [00:48<00:19,  4.92it/s, loss=2.11e-6]\u001b[A\n",
      "Train step of epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 240/334 [00:48<00:19,  4.92it/s, loss=2.11e-6]\u001b[A\n",
      "Train step of epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 240/334 [00:48<00:19,  4.92it/s, loss=0.235]  \u001b[A\n",
      "Train step of epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 241/334 [00:48<00:18,  4.91it/s, loss=0.235]\u001b[A\n",
      "Train step of epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 241/334 [00:48<00:18,  4.91it/s, loss=0.17] \u001b[A\n",
      "Train step of epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 242/334 [00:49<00:18,  4.93it/s, loss=0.17]\u001b[A\n",
      "Train step of epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 242/334 [00:49<00:18,  4.93it/s, loss=0.00533]\u001b[A\n",
      "Train step of epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 243/334 [00:49<00:18,  4.92it/s, loss=0.00533]\u001b[A\n",
      "Train step of epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 243/334 [00:49<00:18,  4.92it/s, loss=0.000284]\u001b[A\n",
      "Train step of epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 244/334 [00:49<00:18,  4.91it/s, loss=0.000284]\u001b[A\n",
      "Train step of epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 244/334 [00:49<00:18,  4.91it/s, loss=0.00156] \u001b[A\n",
      "Train step of epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 245/334 [00:49<00:18,  4.93it/s, loss=0.00156]\u001b[A\n",
      "Train step of epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 245/334 [00:49<00:18,  4.93it/s, loss=0.000505]\u001b[A\n",
      "Train step of epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 246/334 [00:49<00:17,  4.92it/s, loss=0.000505]\u001b[A\n",
      "Train step of epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 246/334 [00:49<00:17,  4.92it/s, loss=0.0207]  \u001b[A\n",
      "Train step of epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 247/334 [00:50<00:17,  4.93it/s, loss=0.0207]\u001b[A\n",
      "Train step of epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 247/334 [00:50<00:17,  4.93it/s, loss=1.17]  \u001b[A\n",
      "Train step of epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 248/334 [00:50<00:17,  4.93it/s, loss=1.17]\u001b[A\n",
      "Train step of epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 248/334 [00:50<00:17,  4.93it/s, loss=0.0519]\u001b[A\n",
      "Train step of epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 249/334 [00:50<00:17,  4.91it/s, loss=0.0519]\u001b[A\n",
      "Train step of epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 249/334 [00:50<00:17,  4.91it/s, loss=0.155] \u001b[A\n",
      "Train step of epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 250/334 [00:50<00:17,  4.90it/s, loss=0.155]\u001b[A\n",
      "Train step of epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 250/334 [00:50<00:17,  4.90it/s, loss=0.406]\u001b[A\n",
      "Train step of epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 251/334 [00:50<00:16,  4.90it/s, loss=0.406]\u001b[A\n",
      "Train step of epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 251/334 [00:50<00:16,  4.90it/s, loss=0.00199]\u001b[A\n",
      "Train step of epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 252/334 [00:51<00:16,  4.91it/s, loss=0.00199]\u001b[A\n",
      "Train step of epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 252/334 [00:51<00:16,  4.91it/s, loss=0.986]  \u001b[A\n",
      "Train step of epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 253/334 [00:51<00:16,  4.90it/s, loss=0.986]\u001b[A\n",
      "Train step of epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 253/334 [00:51<00:16,  4.90it/s, loss=0.00223]\u001b[A\n",
      "Train step of epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 254/334 [00:51<00:16,  4.90it/s, loss=0.00223]\u001b[A\n",
      "Train step of epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 254/334 [00:51<00:16,  4.90it/s, loss=0.0387] \u001b[A\n",
      "Train step of epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 255/334 [00:51<00:16,  4.91it/s, loss=0.0387]\u001b[A\n",
      "Train step of epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 255/334 [00:51<00:16,  4.91it/s, loss=0.187] \u001b[A\n",
      "Train step of epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 256/334 [00:51<00:15,  4.91it/s, loss=0.187]\u001b[A\n",
      "Train step of epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 256/334 [00:51<00:15,  4.91it/s, loss=0.00575]\u001b[A\n",
      "Train step of epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 257/334 [00:52<00:15,  4.91it/s, loss=0.00575]\u001b[A\n",
      "Train step of epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 257/334 [00:52<00:15,  4.91it/s, loss=0.0665] \u001b[A\n",
      "Train step of epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 258/334 [00:52<00:15,  4.91it/s, loss=0.0665]\u001b[A\n",
      "Train step of epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 258/334 [00:52<00:15,  4.91it/s, loss=0.284] \u001b[A\n",
      "Train step of epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 259/334 [00:52<00:15,  4.91it/s, loss=0.284]\u001b[A\n",
      "Train step of epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 259/334 [00:52<00:15,  4.91it/s, loss=0.339]\u001b[A\n",
      "Train step of epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 260/334 [00:52<00:15,  4.92it/s, loss=0.339]\u001b[A\n",
      "Train step of epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 260/334 [00:52<00:15,  4.92it/s, loss=0.225]\u001b[A\n",
      "Train step of epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 261/334 [00:52<00:14,  4.92it/s, loss=0.225]\u001b[A\n",
      "Train step of epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 261/334 [00:52<00:14,  4.92it/s, loss=0.0183]\u001b[A\n",
      "Train step of epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 262/334 [00:53<00:14,  4.88it/s, loss=0.0183]\u001b[A\n",
      "Train step of epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 262/334 [00:53<00:14,  4.88it/s, loss=0.518] \u001b[A\n",
      "Train step of epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 263/334 [00:53<00:14,  4.86it/s, loss=0.518]\u001b[A\n",
      "Train step of epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 263/334 [00:53<00:14,  4.86it/s, loss=0.189]\u001b[A\n",
      "Train step of epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 264/334 [00:53<00:14,  4.87it/s, loss=0.189]\u001b[A\n",
      "Train step of epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 264/334 [00:53<00:14,  4.87it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 265/334 [00:53<00:14,  4.88it/s, loss=0.278]\u001b[A\n",
      "Train step of epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 265/334 [00:53<00:14,  4.88it/s, loss=0.122]\u001b[A\n",
      "Train step of epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 266/334 [00:53<00:13,  4.89it/s, loss=0.122]\u001b[A\n",
      "Train step of epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 266/334 [00:53<00:13,  4.89it/s, loss=0.00701]\u001b[A\n",
      "Train step of epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 267/334 [00:54<00:13,  4.89it/s, loss=0.00701]\u001b[A\n",
      "Train step of epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 267/334 [00:54<00:13,  4.89it/s, loss=0.378]  \u001b[A\n",
      "Train step of epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 268/334 [00:54<00:13,  4.89it/s, loss=0.378]\u001b[A\n",
      "Train step of epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 268/334 [00:54<00:13,  4.89it/s, loss=0.142]\u001b[A\n",
      "Train step of epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 269/334 [00:54<00:13,  4.90it/s, loss=0.142]\u001b[A\n",
      "Train step of epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 269/334 [00:54<00:13,  4.90it/s, loss=0.111]\u001b[A\n",
      "Train step of epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 270/334 [00:54<00:13,  4.89it/s, loss=0.111]\u001b[A\n",
      "Train step of epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 270/334 [00:54<00:13,  4.89it/s, loss=0.124]\u001b[A\n",
      "Train step of epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 271/334 [00:54<00:12,  4.91it/s, loss=0.124]\u001b[A\n",
      "Train step of epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 271/334 [00:55<00:12,  4.91it/s, loss=0.00767]\u001b[A\n",
      "Train step of epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 272/334 [00:55<00:12,  4.89it/s, loss=0.00767]\u001b[A\n",
      "Train step of epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 272/334 [00:55<00:12,  4.89it/s, loss=0.000359]\u001b[A\n",
      "Train step of epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 273/334 [00:55<00:12,  4.90it/s, loss=0.000359]\u001b[A\n",
      "Train step of epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 273/334 [00:55<00:12,  4.90it/s, loss=0.391]   \u001b[A\n",
      "Train step of epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 274/334 [00:55<00:12,  4.90it/s, loss=0.391]\u001b[A\n",
      "Train step of epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 274/334 [00:55<00:12,  4.90it/s, loss=0.0831]\u001b[A\n",
      "Train step of epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 275/334 [00:55<00:12,  4.92it/s, loss=0.0831]\u001b[A\n",
      "Train step of epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 275/334 [00:55<00:12,  4.92it/s, loss=0.346] \u001b[A\n",
      "Train step of epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 276/334 [00:55<00:11,  4.90it/s, loss=0.346]\u001b[A\n",
      "Train step of epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 276/334 [00:56<00:11,  4.90it/s, loss=0.0865]\u001b[A\n",
      "Train step of epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 277/334 [00:56<00:11,  4.89it/s, loss=0.0865]\u001b[A\n",
      "Train step of epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 277/334 [00:56<00:11,  4.89it/s, loss=4.99e-5]\u001b[A\n",
      "Train step of epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 278/334 [00:56<00:11,  4.89it/s, loss=4.99e-5]\u001b[A\n",
      "Train step of epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 278/334 [00:56<00:11,  4.89it/s, loss=0.0066] \u001b[A\n",
      "Train step of epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 279/334 [00:56<00:11,  4.90it/s, loss=0.0066]\u001b[A\n",
      "Train step of epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 279/334 [00:56<00:11,  4.90it/s, loss=0.000211]\u001b[A\n",
      "Train step of epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 280/334 [00:56<00:11,  4.91it/s, loss=0.000211]\u001b[A\n",
      "Train step of epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 280/334 [00:56<00:11,  4.91it/s, loss=0.19]    \u001b[A\n",
      "Train step of epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 281/334 [00:57<00:10,  4.90it/s, loss=0.19]\u001b[A\n",
      "Train step of epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 281/334 [00:57<00:10,  4.90it/s, loss=0.188]\u001b[A\n",
      "Train step of epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 282/334 [00:57<00:10,  4.92it/s, loss=0.188]\u001b[A\n",
      "Train step of epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 282/334 [00:57<00:10,  4.92it/s, loss=0.204]\u001b[A\n",
      "Train step of epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 283/334 [00:57<00:10,  4.91it/s, loss=0.204]\u001b[A\n",
      "Train step of epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 283/334 [00:57<00:10,  4.91it/s, loss=0.00194]\u001b[A\n",
      "Train step of epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 284/334 [00:57<00:10,  4.89it/s, loss=0.00194]\u001b[A\n",
      "Train step of epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 284/334 [00:57<00:10,  4.89it/s, loss=0.00441]\u001b[A\n",
      "Train step of epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 285/334 [00:57<00:09,  4.90it/s, loss=0.00441]\u001b[A\n",
      "Train step of epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 285/334 [00:57<00:09,  4.90it/s, loss=3.97e-8]\u001b[A\n",
      "Train step of epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 286/334 [00:58<00:09,  4.88it/s, loss=3.97e-8]\u001b[A\n",
      "Train step of epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 286/334 [00:58<00:09,  4.88it/s, loss=0.00013]\u001b[A\n",
      "Train step of epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 287/334 [00:58<00:09,  4.88it/s, loss=0.00013]\u001b[A\n",
      "Train step of epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 287/334 [00:58<00:09,  4.88it/s, loss=0.00466]\u001b[A\n",
      "Train step of epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 288/334 [00:58<00:09,  4.89it/s, loss=0.00466]\u001b[A\n",
      "Train step of epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 288/334 [00:58<00:09,  4.89it/s, loss=0.693]  \u001b[A\n",
      "Train step of epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 289/334 [00:58<00:09,  4.89it/s, loss=0.693]\u001b[A\n",
      "Train step of epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 289/334 [00:58<00:09,  4.89it/s, loss=0.0588]\u001b[A\n",
      "Train step of epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 290/334 [00:58<00:08,  4.92it/s, loss=0.0588]\u001b[A\n",
      "Train step of epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 290/334 [00:58<00:08,  4.92it/s, loss=0.0099]\u001b[A\n",
      "Train step of epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 291/334 [00:59<00:08,  4.91it/s, loss=0.0099]\u001b[A\n",
      "Train step of epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 291/334 [00:59<00:08,  4.91it/s, loss=1.56]  \u001b[A\n",
      "Train step of epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 292/334 [00:59<00:08,  4.91it/s, loss=1.56]\u001b[A\n",
      "Train step of epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 292/334 [00:59<00:08,  4.91it/s, loss=0.788]\u001b[A\n",
      "Train step of epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 293/334 [00:59<00:08,  4.92it/s, loss=0.788]\u001b[A\n",
      "Train step of epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 293/334 [00:59<00:08,  4.92it/s, loss=0.00112]\u001b[A\n",
      "Train step of epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 294/334 [00:59<00:08,  4.92it/s, loss=0.00112]\u001b[A\n",
      "Train step of epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 294/334 [00:59<00:08,  4.92it/s, loss=0.0375] \u001b[A\n",
      "Train step of epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 295/334 [00:59<00:07,  4.90it/s, loss=0.0375]\u001b[A\n",
      "Train step of epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 295/334 [00:59<00:07,  4.90it/s, loss=0.337] \u001b[A\n",
      "Train step of epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 296/334 [01:00<00:07,  4.90it/s, loss=0.337]\u001b[A\n",
      "Train step of epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 296/334 [01:00<00:07,  4.90it/s, loss=0.461]\u001b[A\n",
      "Train step of epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 297/334 [01:00<00:07,  4.91it/s, loss=0.461]\u001b[A\n",
      "Train step of epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 297/334 [01:00<00:07,  4.91it/s, loss=0.221]\u001b[A\n",
      "Train step of epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 298/334 [01:00<00:07,  4.89it/s, loss=0.221]\u001b[A\n",
      "Train step of epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 298/334 [01:00<00:07,  4.89it/s, loss=0.12] \u001b[A\n",
      "Train step of epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 299/334 [01:00<00:07,  4.89it/s, loss=0.12]\u001b[A\n",
      "Train step of epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 299/334 [01:00<00:07,  4.89it/s, loss=0.711]\u001b[A\n",
      "Train step of epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 300/334 [01:00<00:06,  4.87it/s, loss=0.711]\u001b[A\n",
      "Train step of epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 300/334 [01:00<00:06,  4.87it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 301/334 [01:01<00:06,  4.86it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 301/334 [01:01<00:06,  4.86it/s, loss=0.0667]\u001b[A\n",
      "Train step of epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 302/334 [01:01<00:06,  4.86it/s, loss=0.0667]\u001b[A\n",
      "Train step of epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 302/334 [01:01<00:06,  4.86it/s, loss=0.324] \u001b[A\n",
      "Train step of epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 303/334 [01:01<00:06,  4.84it/s, loss=0.324]\u001b[A\n",
      "Train step of epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 303/334 [01:01<00:06,  4.84it/s, loss=0.00591]\u001b[A\n",
      "Train step of epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 304/334 [01:01<00:06,  4.86it/s, loss=0.00591]\u001b[A\n",
      "Train step of epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 304/334 [01:01<00:06,  4.86it/s, loss=0.143]  \u001b[A\n",
      "Train step of epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 305/334 [01:01<00:05,  4.86it/s, loss=0.143]\u001b[A\n",
      "Train step of epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 305/334 [01:01<00:05,  4.86it/s, loss=0.462]\u001b[A\n",
      "Train step of epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 306/334 [01:02<00:05,  4.85it/s, loss=0.462]\u001b[A\n",
      "Train step of epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 306/334 [01:02<00:05,  4.85it/s, loss=0.456]\u001b[A\n",
      "Train step of epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 307/334 [01:02<00:05,  4.86it/s, loss=0.456]\u001b[A\n",
      "Train step of epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 307/334 [01:02<00:05,  4.86it/s, loss=0.0478]\u001b[A\n",
      "Train step of epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 308/334 [01:02<00:05,  4.85it/s, loss=0.0478]\u001b[A\n",
      "Train step of epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 308/334 [01:02<00:05,  4.85it/s, loss=0.347] \u001b[A\n",
      "Train step of epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 309/334 [01:02<00:05,  4.85it/s, loss=0.347]\u001b[A\n",
      "Train step of epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 309/334 [01:02<00:05,  4.85it/s, loss=0.0757]\u001b[A\n",
      "Train step of epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 310/334 [01:02<00:04,  4.86it/s, loss=0.0757]\u001b[A\n",
      "Train step of epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 310/334 [01:02<00:04,  4.86it/s, loss=0.0336]\u001b[A\n",
      "Train step of epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 311/334 [01:03<00:04,  4.86it/s, loss=0.0336]\u001b[A\n",
      "Train step of epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 311/334 [01:03<00:04,  4.86it/s, loss=0.0691]\u001b[A\n",
      "Train step of epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 312/334 [01:03<00:04,  4.87it/s, loss=0.0691]\u001b[A\n",
      "Train step of epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 312/334 [01:03<00:04,  4.87it/s, loss=0.153] \u001b[A\n",
      "Train step of epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 313/334 [01:03<00:04,  4.87it/s, loss=0.153]\u001b[A\n",
      "Train step of epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 313/334 [01:03<00:04,  4.87it/s, loss=0.125]\u001b[A\n",
      "Train step of epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 314/334 [01:03<00:04,  4.86it/s, loss=0.125]\u001b[A\n",
      "Train step of epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 314/334 [01:03<00:04,  4.86it/s, loss=0.19] \u001b[A\n",
      "Train step of epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 315/334 [01:03<00:03,  4.87it/s, loss=0.19]\u001b[A\n",
      "Train step of epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 315/334 [01:04<00:03,  4.87it/s, loss=0.0525]\u001b[A\n",
      "Train step of epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 316/334 [01:04<00:03,  4.87it/s, loss=0.0525]\u001b[A\n",
      "Train step of epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 316/334 [01:04<00:03,  4.87it/s, loss=0.305] \u001b[A\n",
      "Train step of epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 317/334 [01:04<00:03,  4.86it/s, loss=0.305]\u001b[A\n",
      "Train step of epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 317/334 [01:04<00:03,  4.86it/s, loss=0.113]\u001b[A\n",
      "Train step of epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 318/334 [01:04<00:03,  4.86it/s, loss=0.113]\u001b[A\n",
      "Train step of epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 318/334 [01:04<00:03,  4.86it/s, loss=0.000604]\u001b[A\n",
      "Train step of epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 319/334 [01:04<00:03,  4.84it/s, loss=0.000604]\u001b[A\n",
      "Train step of epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 319/334 [01:04<00:03,  4.84it/s, loss=0.000174]\u001b[A\n",
      "Train step of epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 320/334 [01:05<00:02,  4.85it/s, loss=0.000174]\u001b[A\n",
      "Train step of epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 320/334 [01:05<00:02,  4.85it/s, loss=0.525]   \u001b[A\n",
      "Train step of epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 321/334 [01:05<00:02,  4.84it/s, loss=0.525]\u001b[A\n",
      "Train step of epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 321/334 [01:05<00:02,  4.84it/s, loss=0.0543]\u001b[A\n",
      "Train step of epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 322/334 [01:05<00:02,  4.86it/s, loss=0.0543]\u001b[A\n",
      "Train step of epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 322/334 [01:05<00:02,  4.86it/s, loss=0.0643]\u001b[A\n",
      "Train step of epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 323/334 [01:05<00:02,  4.88it/s, loss=0.0643]\u001b[A\n",
      "Train step of epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 323/334 [01:05<00:02,  4.88it/s, loss=0.0133]\u001b[A\n",
      "Train step of epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 324/334 [01:05<00:02,  4.89it/s, loss=0.0133]\u001b[A\n",
      "Train step of epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 324/334 [01:05<00:02,  4.89it/s, loss=0.0451]\u001b[A\n",
      "Train step of epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 325/334 [01:06<00:01,  4.88it/s, loss=0.0451]\u001b[A\n",
      "Train step of epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 325/334 [01:06<00:01,  4.88it/s, loss=0.00628]\u001b[A\n",
      "Train step of epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 326/334 [01:06<00:01,  4.88it/s, loss=0.00628]\u001b[A\n",
      "Train step of epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 326/334 [01:06<00:01,  4.88it/s, loss=0.00387]\u001b[A\n",
      "Train step of epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 327/334 [01:06<00:01,  4.90it/s, loss=0.00387]\u001b[A\n",
      "Train step of epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 327/334 [01:06<00:01,  4.90it/s, loss=0.0854] \u001b[A\n",
      "Train step of epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 328/334 [01:06<00:01,  4.91it/s, loss=0.0854]\u001b[A\n",
      "Train step of epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 328/334 [01:06<00:01,  4.91it/s, loss=0.0269]\u001b[A\n",
      "Train step of epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 329/334 [01:06<00:01,  4.95it/s, loss=0.0269]\u001b[A\n",
      "Train step of epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 329/334 [01:06<00:01,  4.95it/s, loss=0.013] \u001b[A\n",
      "Train step of epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 330/334 [01:07<00:00,  4.92it/s, loss=0.013]\u001b[A\n",
      "Train step of epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 330/334 [01:07<00:00,  4.92it/s, loss=0.184]\u001b[A\n",
      "Train step of epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 331/334 [01:07<00:00,  4.90it/s, loss=0.184]\u001b[A\n",
      "Train step of epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 331/334 [01:07<00:00,  4.90it/s, loss=0.0971]\u001b[A\n",
      "Train step of epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 332/334 [01:07<00:00,  4.89it/s, loss=0.0971]\u001b[A\n",
      "Train step of epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 332/334 [01:07<00:00,  4.89it/s, loss=0.0274]\u001b[A\n",
      "Train step of epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 333/334 [01:07<00:00,  4.88it/s, loss=0.0274]\u001b[A\n",
      "Train step of epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 333/334 [01:07<00:00,  4.88it/s, loss=0.246] \u001b[A\n",
      "Train step of epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 334/334 [01:07<00:00,  5.40it/s, loss=0.246]\u001b[A\n",
      "Train epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:11<00:00, 71.26s/it]00,  5.40it/s, loss=0.000697]\u001b[A\n",
      "Train step of epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 334/334 [01:11<00:00,  4.69it/s, loss=0.174, dist_mean=11.5]\u001b[A\n",
      "Train epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:11<00:00, 71.26s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(use_lora=0)\n",
    "\n",
    "model.save_pretrained('/output_2_RM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f148f410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: ì¸ê³µì§€ëŠ¥ì€ ë˜¥ë©ì²­ì´ ì…ë‹ˆë‹¤\n",
      "reward score: -0.7\n"
     ]
    }
   ],
   "source": [
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward\n",
    "\n",
    "input_text = 'ì¸ê³µì§€ëŠ¥ì€ ë˜¥ë©ì²­ì´ ì…ë‹ˆë‹¤'\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f186d",
   "metadata": {},
   "source": [
    "## PPO ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71cbb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d7a73e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained='/output_1_SFT', lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained='aiffel/KoChatGPT/output_2_RM', lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=128\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2f8d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)\n",
    "\n",
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2abb58b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize\n",
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9dc86921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=5,  \n",
    "                     train_batch_size=16, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80ea4f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:11<00:05,  5.87s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.00612]\u001b[A\n",
      "Train epoch [1/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.09it/s, actor_loss=0, critic_loss=0.00612]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.378]\u001b[A\n",
      "Train epoch [2/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.12it/s, actor_loss=0, critic_loss=0.378]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.0616]\u001b[A\n",
      "Train epoch [3/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.12it/s, actor_loss=0, critic_loss=0.0616]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.235]\u001b[A\n",
      "Train epoch [4/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.12it/s, actor_loss=0, critic_loss=0.235]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.258]\u001b[A\n",
      "Train epoch [5/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.12it/s, actor_loss=0, critic_loss=0.258]\u001b[A\n",
      "Episode [1/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.30s/it]\n",
      "Episode [2/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:11<00:05,  5.80s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.306, critic_loss=0.115]\u001b[A\n",
      "Train epoch [1/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.306, critic_loss=0.115]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.318, critic_loss=0.0159]\u001b[A\n",
      "Train epoch [2/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s, actor_loss=0.318, critic_loss=0.0159]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.319, critic_loss=0.0466]\u001b[A\n",
      "Train epoch [3/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s, actor_loss=0.319, critic_loss=0.0466]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.296, critic_loss=0.148]\u001b[A\n",
      "Train epoch [4/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s, actor_loss=0.296, critic_loss=0.148]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.296, critic_loss=0.118]\u001b[A\n",
      "Train epoch [5/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.296, critic_loss=0.118]\u001b[A\n",
      "Episode [2/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.42s/it]\n",
      "Episode [3/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:11<00:05,  5.84s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.216, critic_loss=0.0717]\u001b[A\n",
      "Train epoch [1/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s, actor_loss=-.216, critic_loss=0.0717]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.22, critic_loss=0.0204]\u001b[A\n",
      "Train epoch [2/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s, actor_loss=-.22, critic_loss=0.0204]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.221, critic_loss=0.018]\u001b[A\n",
      "Train epoch [3/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s, actor_loss=-.221, critic_loss=0.018]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.206, critic_loss=0.0538]\u001b[A\n",
      "Train epoch [4/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.206, critic_loss=0.0538]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.229, critic_loss=0.0757]\u001b[A\n",
      "Train epoch [5/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s, actor_loss=-.229, critic_loss=0.0757]\u001b[A\n",
      "Episode [3/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.45s/it]\n",
      "Episode [4/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:10<00:05,  5.16s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.227, critic_loss=0.0565]\u001b[A\n",
      "Train epoch [1/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s, actor_loss=0.227, critic_loss=0.0565]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.221, critic_loss=0.0282]\u001b[A\n",
      "Train epoch [2/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.221, critic_loss=0.0282]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.235, critic_loss=0.0129]\u001b[A\n",
      "Train epoch [3/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.235, critic_loss=0.0129]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.263, critic_loss=0.0183]\u001b[A\n",
      "Train epoch [4/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s, actor_loss=0.263, critic_loss=0.0183]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.229, critic_loss=0.0337]\u001b[A\n",
      "Train epoch [5/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.229, critic_loss=0.0337]\u001b[A\n",
      "Episode [4/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.08s/it]\n",
      "Episode [5/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:10<00:04,  4.98s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0672, critic_loss=0.0553]\u001b[A\n",
      "Train epoch [1/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.0672, critic_loss=0.0553]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.116, critic_loss=0.035]\u001b[A\n",
      "Train epoch [2/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.116, critic_loss=0.035]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0724, critic_loss=0.0306]\u001b[A\n",
      "Train epoch [3/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s, actor_loss=-.0724, critic_loss=0.0306]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.112, critic_loss=0.0145]\u001b[A\n",
      "Train epoch [4/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.112, critic_loss=0.0145]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0812, critic_loss=0.00753]\u001b[A\n",
      "Train epoch [5/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s, actor_loss=-.0812, critic_loss=0.00753]\u001b[A\n",
      "Episode [5/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:20<00:00,  6.93s/it]\n",
      "Episode [6/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:11<00:05,  5.93s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.177, critic_loss=0.182]\u001b[A\n",
      "Train epoch [1/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.177, critic_loss=0.182]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0927, critic_loss=0.118]\u001b[A\n",
      "Train epoch [2/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.0927, critic_loss=0.118]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.00528, critic_loss=0.00769]\u001b[A\n",
      "Train epoch [3/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.00528, critic_loss=0.00769]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0937, critic_loss=0.0631]\u001b[A\n",
      "Train epoch [4/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.0937, critic_loss=0.0631]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0654, critic_loss=0.0556]\u001b[A\n",
      "Train epoch [5/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.0654, critic_loss=0.0556]\u001b[A\n",
      "Episode [6/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.50s/it]\n",
      "Episode [7/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:11<00:05,  5.83s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0763, critic_loss=0.0196]\u001b[A\n",
      "Train epoch [1/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s, actor_loss=-.0763, critic_loss=0.0196]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0846, critic_loss=0.0197]\u001b[A\n",
      "Train epoch [2/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.0846, critic_loss=0.0197]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0868, critic_loss=0.0119]\u001b[A\n",
      "Train epoch [3/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s, actor_loss=-.0868, critic_loss=0.0119]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0778, critic_loss=0.00926]\u001b[A\n",
      "Train epoch [4/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.0778, critic_loss=0.00926]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0788, critic_loss=0.025]\u001b[A\n",
      "Train epoch [5/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s, actor_loss=-.0788, critic_loss=0.025]\u001b[A\n",
      "Episode [7/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.44s/it]\n",
      "Episode [8/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:11<00:05,  5.95s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0661, critic_loss=0.0316]\u001b[A\n",
      "Train epoch [1/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.0661, critic_loss=0.0316]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0343, critic_loss=0.025]\u001b[A\n",
      "Train epoch [2/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.0343, critic_loss=0.025]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0778, critic_loss=0.0258]\u001b[A\n",
      "Train epoch [3/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s, actor_loss=0.0778, critic_loss=0.0258]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0294, critic_loss=0.014]\u001b[A\n",
      "Train epoch [4/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s, actor_loss=0.0294, critic_loss=0.014]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0684, critic_loss=0.00989]\u001b[A\n",
      "Train epoch [5/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s, actor_loss=0.0684, critic_loss=0.00989]\u001b[A\n",
      "Episode [8/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.50s/it]\n",
      "Episode [9/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:11<00:05,  5.90s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0328, critic_loss=0.0248]\u001b[A\n",
      "Train epoch [1/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.0328, critic_loss=0.0248]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0394, critic_loss=0.0152]\u001b[A\n",
      "Train epoch [2/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s, actor_loss=-.0394, critic_loss=0.0152]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0301, critic_loss=0.0129]\u001b[A\n",
      "Train epoch [3/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s, actor_loss=-.0301, critic_loss=0.0129]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0227, critic_loss=0.00416]\u001b[A\n",
      "Train epoch [4/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.08it/s, actor_loss=-.0227, critic_loss=0.00416]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0294, critic_loss=0.00774]\u001b[A\n",
      "Train epoch [5/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.0294, critic_loss=0.00774]\u001b[A\n",
      "Episode [9/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.47s/it]\n",
      "Episode [10/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:11<00:05,  5.87s/it]\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.00604, critic_loss=0.00962]\u001b[A\n",
      "Train epoch [1/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s, actor_loss=-.00604, critic_loss=0.00962]\u001b[A\n",
      "\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [2/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.00377, critic_loss=0.0178]\u001b[A\n",
      "Train epoch [2/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.06it/s, actor_loss=-.00377, critic_loss=0.0178]\u001b[A\n",
      "\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [3/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.000281, critic_loss=0.0179]\u001b[A\n",
      "Train epoch [3/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.000281, critic_loss=0.0179]\u001b[A\n",
      "\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [4/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.00343, critic_loss=0.0143]\u001b[A\n",
      "Train epoch [4/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=-.00343, critic_loss=0.0143]\u001b[A\n",
      "\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [5/5]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.00325, critic_loss=0.00834]\u001b[A\n",
      "Train epoch [5/5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s, actor_loss=0.00325, critic_loss=0.00834]\u001b[A\n",
      "Episode [10/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.47s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1633ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('/output_3_PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bf92c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=128,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.50,\n",
    "                             no_repeat_ngram_size=4, \n",
    "                             early_stopping=True,\n",
    "                             repetition_penalty=2.0,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6ac4cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "RLHF_output = []\n",
    "for input_text in input_prompt:\n",
    "    new_output.append(generation(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1de07f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2325450947266871"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate BLEU score\n",
    "RLHF_bleu_score = []\n",
    "for output, target in zip(RLHF_output, labeled_completion):\n",
    "    RLHF_bleu_score.append(calculate_bleu_score([output], [target])['score'])\n",
    "\n",
    "sum(RLHF_bleu_score)/len(RLHF_bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0e066",
   "metadata": {},
   "source": [
    "## RLHF ëª¨ë¸ bleu score : 0.232"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf02e20",
   "metadata": {},
   "source": [
    "### ë‹µë³€ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c00c43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì–´ë””ì— ê¹€ì˜ì‚¼ì˜ ì„œìš¸ëŒ€í•™êµ ì…í•™ ë° ì¡¸ì—… ì¦ëª…ì„œê°€ ì „ì‹œë˜ì–´ ìˆëŠ”ê°€?'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_prompt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7fc303a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì–´ë””ì— ê¹€ì˜ì‚¼ì˜ ì„œìš¸ëŒ€í•™êµ ì…í•™ ë° ì¡¸ì—… ì¦ëª…ì„œê°€ ì „ì‹œë˜ì–´ ìˆëŠ”ê°€? ëš±ëš± ì„¸ì¸íŠ¸ ìš¸í”„ [UNK]í© ì§„ è¨Ÿ ì¡°êµ9 æº– æ·® ê¸°ì—… é³© æ·® ê¸°ì—… é³© é³©ì«Œ äºº [UNK] ì§„ è¨Ÿ æº– ê±°ë˜ é³© æ·® ê¸°ì—… é³© íš¨ê³¼ æ·®! é³©ì«Œ äºº [UNK] ì‡ ì„ íš¨ê³¼ æ·®!! é³©ì«Œ é³© íš¨ê³¼ äºº [UNK] é³© íš¨ê³¼ æ·®!ë™‡ì„ë™‡ë¥´ é³© íš¨ê³¼ äºº [UNK] íš¨ê³¼ ä»² å­«! ìƒˆë¡œìš´ å­« é³© íš¨ê³¼ æ·®! é³© íš¨ê³¼! äº¦! ìƒˆë¡œìš´ å­« é³© íš¨ê³¼ äº¨ [UNK] é³© íš¨ê³¼ äºº [UNK] íš¨ê³¼ ä»² å­« å­«! ìƒˆë¡œìš´ å­« é³© íš¨ê³¼ æ·®! é³©ì«Œ äºº [UNK] ë‹ ìˆ± å­«! ìˆ± å­« å­«!'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RLHF_output[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24cfc50",
   "metadata": {},
   "source": [
    "## 2. SFTë¥¼ ì ìš©í•œ ëª¨ë¸ê³¼ RLHFë¥¼ ì ìš©í•œ ëª¨ë¸ì˜ ê²°ê³¼ë¬¼ì„ ì •ëŸ‰/ì •ì„±ì ìœ¼ë¡œ ë¹„êµ/ë¶„ì„\n",
    "- ì •ëŸ‰ì  í‰ê°€\n",
    "    \n",
    "    SFT ì ìš© ëª¨ë¸ì˜ bleu score : 0.137\n",
    "    \n",
    "    RLHF ëª¨ë¸ì˜ bleu score : 0.232\n",
    "\n",
    "    \n",
    "    * í˜„ì¬ ë‘ ëª¨ë¸ ëª¨ë‘ outputì— inputì˜ promptê°€ í¬í•¨ë˜ì—ˆê¸° ë•Œë¬¸ì— ì‹¤ì œë³´ë‹¤ ë” ë†’ì€ scoreê°€ ë‚˜ì˜¬ ê°€ëŠ¥ì„±ì´ ìˆë‹¤. RLHF ëª¨ë¸ì˜ bleu scoreê°€ ë” ë‚®ê²Œ ë‚˜ì™”ì§€ë§Œ, ì´ëŠ” ì •í™•í•˜ì§€ ì•Šì€ ì§€í‘œë¼ëŠ” ì˜ë¬¸ì´ ë“ ë‹¤. \n",
    "        \n",
    "        \n",
    "- ì •ì„±ì  í‰ê°€\n",
    "    \n",
    "    SFT ëª¨ë¸ì˜ í‰ê°€ : ì§ˆë¬¸ìì˜ ì§ˆë¬¸ì— ê´€ë ¨ì„± ìˆê²Œ ë‹µë³€ì„ í•˜ì˜€ë‹¤. ì§ˆë¬¸ìì˜ ì§ˆë¬¸ì„ ì •í™•íˆ ì´í•´í•˜ê³  ë§¥ë½ì— ë§ê²Œ ë‹µë³€í•˜ì˜€ë‹¤. ë‹¤ë§Œ, ëŒ€ë¶€ë¶„ ì§ˆë¬¸ì— ëŒ€í•´ì„œ ì •í™•í•˜ê²Œ ë‹µë³€ì„ ì œì•ˆí•˜ì§€ ëª»í–ˆë‹¤.\n",
    "    \n",
    "    \n",
    "    RLHF ëª¨ë¸ì˜ í‰ê°€ : RLHFì˜ ëª¨ë¸ì€ ì§ˆë¬¸ìì˜ ì§ˆë¬¸ê³¼ ë‹µë³€ ê°„ì˜ ê´€ê³„ê°€ ê±°ì˜ ì—†ë‹¤. ë˜í•œ ë°˜ë³µëœ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ bleu scoreëŠ” ë†’ì€ ê°’ì´ ë‚˜ì™”ì§€ë§Œ, ì§ˆë¬¸ê³¼ ê´€ê³„ì—†ëŠ” ë‹µë³€ì´ ë°˜ë³µë˜ì–´ ì±—ë´‡ì˜ ê¸°ëŠ¥ìœ¼ë¡œì„œ ë„ì›€ì´ ë˜ì§€ ì•ŠëŠ”ë‹¤. ë‹¨ì–´ë¥¼ ë‚˜ì—´í•˜ëŠ” ìˆœì„œë‚˜ ë¬¸ì¥ì˜ ì™„ì„±ë„ ë˜í•œ ì˜¬ë°”ë¥´ì§€ ëª»í–ˆë‹¤.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d1ad23",
   "metadata": {},
   "source": [
    "# 3. Foundation Model êµì²´ë¥¼ í†µí•œ ì •ëŸ‰ì  ì„±ëŠ¥í–¥ìƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6b3cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "972903c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f346d0907a4d2bae4716b3813ac071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/591 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3f0b3336d64d7a82a83d53daea40b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/449M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `ElectraForCausalLM` as a standalone, add `is_decoder=True.`\n",
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-finetuned-korquad were not used when initializing ElectraForCausalLM: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing ElectraForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForCausalLM were not initialized from the model checkpoint at monologg/koelectra-base-v3-finetuned-korquad and are newly initialized: ['generator_predictions.dense.bias', 'generator_predictions.LayerNorm.bias', 'generator_lm_head.bias', 'generator_predictions.dense.weight', 'generator_predictions.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b57ecacb2724307af4faa4268707b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf20572e1c64db28dfe8ef865665ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/263k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d55affbae984e61a56b27e8267e1b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = 'monologg/koelectra-base-v3-finetuned-korquad'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "                                           bos_token='</s>', \n",
    "                                           eos_token='</s>', \n",
    "                                           unk_token='</s>', \n",
    "                                           pad_token='</s>',\n",
    "                                           padding_side=\"right\",\n",
    "                                           model_max_length=128,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f326d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_output = []\n",
    "max_length = 128\n",
    "\n",
    "for input_txt in input_prompt:\n",
    "    input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "    output= model.generate(input_ids, max_length=max_length, num_beams=4, no_repeat_ngram_size=4, early_stopping=True,\n",
    "                                 eos_token_id=375, do_sample=True, top_k=50, repetition_penalty=2.0)\n",
    "    new_output.append(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5e22a24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (130 > 128). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2331180272431364"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate BLEU score\n",
    "new_bleu_score = []\n",
    "for output, target in zip(new_output, labeled_completion):\n",
    "    new_bleu_score.append(calculate_bleu_score([output], [target])['score'])\n",
    "    \n",
    "sum(new_bleu_score)/len(new_bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f270e461",
   "metadata": {},
   "source": [
    "### monologg/koelectra-base-v3-finetuned-korquadì„ ì ìš©í•œ ëª¨ë¸ì˜ bleu score : 0.233"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc91506",
   "metadata": {},
   "source": [
    "## ë¶„ì„ : \n",
    " monologg/koelectra-base-v3-finetuned-korquad ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ bleu scoreë¥¼ 0.227ì—ì„œ 0.233ê¹Œì§€ í–¥ìƒì‹œì¼°ë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a625f10",
   "metadata": {},
   "source": [
    "# íšŒê³ \n",
    "ì˜í•œ ì  : ì½”ë“œì— ëŒ€í•œ ì„¤ëª…ì´ ê±°ì˜ ì—†ì—ˆìŒì—ë„ ë‹¤ë¥¸ ìë£Œë“¤ì„ í™œìš©í•˜ì—¬ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³  ì£¼ì–´ì§„ ë¯¸ì…˜ì— ë§ê²Œ ê³ ì³ ì‚¬ìš©í•˜ì˜€ë‹¤.\n",
    "    \n",
    "ëª»í•œ ì  : ì‹œê°„ì´ ë¶€ì¡±í•˜ì—¬ ë‹¤ì–‘í•œ ì „ëµì„ ì‚¬ìš©í•´ë³´ì§€ ëª»í•˜ê³  ê°„ë‹¨í•œ ê²ƒë§Œ ì‹œë„í•´ë³¸ê²ƒì´ ì•„ì‰½ë‹¤.\n",
    "    \n",
    "ë…¸ë ¥í•  ì  : bleu score ì´ì™¸ì—ë„ ì •ëŸ‰ì  í‰ê°€ë¥¼ í•  ìˆ˜ ìˆëŠ” metrixë¥¼ ì‚¬ìš©í•´ë³´ë©´ ë” ì¢‹ì„ê²ƒ ê°™ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97531038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
